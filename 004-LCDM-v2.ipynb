{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9bf681",
   "metadata": {
    "id": "0d9bf681"
   },
   "source": [
    "# Cosmological Structure Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34cd6a3",
   "metadata": {
    "cellView": "form",
    "id": "c34cd6a3"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "\"\"\" VERSION HISTORY\n",
    "LCDM-v2\n",
    "2025-12-16 Converted to Colab compatible Jupyter notebook\n",
    "DFS-v11-1\n",
    "2025-11-02 Transformation to individual masses for particles. Use of grad_phi5 module\n",
    "DFS-v11-0\n",
    "2025-10-31 Integrated deposit and gather functions from grad_phi-v4 module\n",
    "2025-10-28 Integrated grad_phi-v3.cpp, leading to performance improvements in combined_step, cooling_heating_step and\n",
    "           refine_potential_cpp functions\n",
    "2025-10-23 Introduced refine_subgrid function from grad_phi module, parallelizing the DST calculation, leadimng to\n",
    "           performance improvements\n",
    "2025-10-22 Introduced time subcycling in fine grid. Consolidated everything in combined_step_subcycling function\n",
    "2025-10-18 Introduced thermo mesh refinement\n",
    "2025-10-14 Introduced self shielding in cooling_heating_step and restructured that function fundamentally\n",
    "           Moved calculation of max_tot_od from cooling_heating_step to pm_acceleration (that is where it naturally belongs)\n",
    "2025-10-11 Re-integrated Python version of cooling_heating_step to prepare for integration of thermo mesh refinement\n",
    "2025-10-09 Added gravity mesh refinement to leapfrog_step_py\n",
    "           Re-integrated Python version of leapfrog_step to prepare for integration of gravity mesh refinement\n",
    "2025-10-02 Introduced Tinker benchmark for number density per halo weight class, replacing Press-Schechter\n",
    "2025-09-30 Fully integrated use_TSC\n",
    "2025-09-29 Integrated combined_step function, leading to massive performance improvement\n",
    "2025-09-25 Started use of CODEX\n",
    "           Turned cooling_heating_step from Python to C++ using CODDEX. Some performance improvement, but not stellar\n",
    "DFS-v10-comoving\n",
    "2025-09-24 Extended Artificial Viscosity function to better preserve angular momentum in disk midplanes\n",
    "           Fixed critical error in Artificial Viscosity function (use of dx_phys where necessary)\n",
    "2025-09-21 Fixed Layzer-Irvine energy equation\n",
    "2025-09-17 Introduced Wiersma collision tables for z > 8.989. This leads to realistic temperatures for pre-reionization epoch\n",
    "2025-09-11 Introduced exponential update of u_grid\n",
    "2025-08-30 Integrated Wiersma cooling tables. More realistic temperature evolment.\n",
    "2025-08-28 Accelerated thermo calculations\n",
    "2025-08-25 Animation and illustration of Thermodynamic processes\n",
    "2025-08-24 First realistic results of Themodynamic processes (heating, colling, pressure forces).\n",
    "2025-08-22 Early steps integrating Thermodynamics\n",
    "DFS-v9-comoving\n",
    "2025-08-19 Corrected error in initialization of M_total\n",
    "2025-08-15 Weak-lensing convergence kappa analysis added\n",
    "2025-08-12 First run with 256**3 = 16'777k particles and cells. Time ca 42min.\n",
    "2025-08-12 Transformed pm_acceleration function to cpp, including parallel FFT processing. Factor 2 performance gain on 2097 kBodies.\n",
    "           Almost identical results\n",
    "2025-08-11 Implemented TSC approach to density calculation. Minimal changes to results, but lower performance (timewise)\n",
    "           Further improved variable consistency\n",
    "2025-08-07 Added html summary report\n",
    "2025-08-06 Adopted simple cooling model for baryons, only dependent on the local overdensity. Shows concentration of baryons in halo centers\n",
    "2025-08-05 Integrated calculation of all LCDM key quantities\n",
    "2025-08-04 Changed resampling approach for animation to one rate qq applying to each of the 3 space dimensions\n",
    "2025-08-02 Consolidated code. Focused Halo Analysis on full set of bodies. First simulation of 128**3 bodies and cells in ca. 4 mins.\n",
    "           Fixed spin calculation in halo analysis. Now realistic spins are produced (around 0.05)\n",
    "           Added halo statistic (halo count by weight classes, compared to theoretical expectations based on Press-Schechter) and halo visualization\n",
    "2025-08-01 Added Energy Analysis based on phi\n",
    "2025-07-31 Optimized PM by migrating delta field calculation (CIC) and mesh interpolation to C++. 64**3 bodies run in 21s.\n",
    "           Animation changed to show a fraction of the bodies simulated. Calculation of energies disabled as too slow (PE based on body-body interactions)\n",
    "2025-07-30 Implemented accelerations based on Particle-Mash Method. Results roughly consistent with earlier body-to-body approaches\n",
    "           A factor of 2**2 when calculating acc and a factor of 2 when calculating potential energy remains unexplained\n",
    "           PM-Method now considers periodic boundary conditions\n",
    "2025-07-28 Copy created\n",
    "DFS-v8-10Mpc-comoving\n",
    "2025-07-27 Corrected scaling of s2 contribution to displacement and velocity (previously too low by factor 1/D_init)\n",
    "2025-07-26 Improved charts and code readability\n",
    "2025-07-24 Extended grad_phi module to calculate energies.\n",
    "2025-07-23 Introduced C++ based force calculation based on parallel processing. import grad_phi provides the respective functions\n",
    "           Massive performance improvement\n",
    "           Enabled the use of compression factors q that do not divide N. Broader ranges of compression possible\n",
    "           Introduced Barnes Hat force calculation in Python. Too slow to provide practical advantage over brute force\n",
    "2025-07-22 Background acceleration now determined based on critical mass.\n",
    "2025-07-22 Migration to comoving coordinates. Run with 17000 bodies\n",
    "DFS-v7-20Mpc-exp5\n",
    "2025-07-12 Delta field created directly for a=a_init, via power spectrum matching a_init\n",
    "           Added tidal tensor velocities to spark spin. No effect\n",
    "           Extended halo analysis to initial conditions\n",
    "2025-07-12 Made eps dependent on scale factor\n",
    "2025-07-10 Eliminated averaging bodies after 2LPT\n",
    "           Eliminated all filtering of delta field used for 2LPT Initial Conditions\n",
    "           Time steps dt chosen so that delta_a/a is constant and simulation ends at a=1\n",
    "           q_rot set to zero\n",
    "           Full 20Mpc box taken as IC\n",
    "Delta field simulation-v6\n",
    "2025-07-09 Further speeding up through parallelization using joblib\n",
    "Delta field simulation-v5\n",
    "2025-07-08 Speeding up n-body simulation through parallelization of compute_accelerations method\n",
    "           Added 2LPT (on top of Zeldovich)\n",
    "Delta field simulation-v4\n",
    "2025-07-07 Added halo identification\n",
    "2025-07-06 Added a gray reference sphere to the animation illustrating the hubble flow\n",
    "           Corrected the cooling mechanism (only peculiar velocities are cooled)\n",
    "2025-07-05 Creation of delta field now calibrated to length L today (a=1) instead of a=a_init. This allows choice of different a_init without affecting\n",
    "           the initial delta field. Previous versions were inconsistent (grid scale inconsistent with displacement field scale). Now a_init=0.05 is a reasonable\n",
    "           choice (earlier versions were at a_init=0.2 which is too late)\n",
    "           Volume of initial spherical n-body system now determined as a sphere (was determined as a box initially)\n",
    "Delta field simulation-v3\n",
    "2025-07-01 Initial n-body system constrained to a sphere (previously a box). Integrated Zeldovich consistemcy check (density contrast field regression)\n",
    "2025-06-31 Choosing an excerpt of the density field with mean delta > 0\n",
    "Delta field simulation-v2\n",
    "2025-06-30 Integrated Zeldovich consistemcy check (density contrast field regression)\n",
    "2025-06-29 Added separate treatment for baryons (red dots)\n",
    "Delta field simulation-v1\n",
    "2025-06-26 Added div s = -delta test\n",
    "2025-06-25 Integrated density field calculation with n-body simulation\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb975b8",
   "metadata": {
    "id": "0eb975b8"
   },
   "source": [
    "__Parametrization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lbcvloOhQ3PW",
   "metadata": {
    "cellView": "form",
    "id": "lbcvloOhQ3PW"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import os, sys, importlib.util, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "GITHUB_USER = \"JoOechslin\"\n",
    "GITHUB_REPO = \"Cosmology-Hackathon\"\n",
    "GITHUB_BRANCH = \"main\"   # or \"master\"\n",
    "\n",
    "BASE_URL = f\"https://raw.githubusercontent.com/{GITHUB_USER}/{GITHUB_REPO}/{GITHUB_BRANCH}\"\n",
    "\n",
    "FILES = [\n",
    "    \"grad_phi5.cpython-310-x86_64-linux-gnu.so\",\n",
    "    \"cooling_table_collis_v1.npz\",\n",
    "    \"cooling_table_v1.npz\"\n",
    "]\n",
    "\n",
    "def fetch_from_github(filename):\n",
    "    if not Path(filename).exists():\n",
    "        url = f\"{BASE_URL}/{filename}\"\n",
    "        print(f\"â¬‡ï¸ Downloading {filename}\")\n",
    "        subprocess.run([\"wget\", \"-q\", url, \"-O\", filename], check=True)\n",
    "    else:\n",
    "        print(f\"âœ… {filename} already present\")\n",
    "\n",
    "for f in FILES:\n",
    "    fetch_from_github(f)\n",
    "\n",
    "print(\"ðŸ“ Current directory:\", os.listdir())\n",
    "\n",
    "!apt install libfftw3-dev libfftw3-threads3 libomp-dev\n",
    "!pip install pybind11\n",
    "!apt-get update\n",
    "!apt-get install -y libfftw3-dev\n",
    "\n",
    "# Load compiled extension\n",
    "so_file = next(\n",
    "    f for f in os.listdir()\n",
    "    if f.startswith(\"grad_phi5\") and f.endswith(\".so\")\n",
    ")\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"grad_phi5\", so_file)\n",
    "grad_phi5 = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(grad_phi5)\n",
    "\n",
    "print(\"âœ… grad_phi5 loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc78ce",
   "metadata": {
    "id": "ffdc78ce"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cosmology\n",
    "h = 0.7 # unitless\n",
    "Î©_r = 8.4e-5 # Radiation density (photons and relativistic neutrinos), unitless\n",
    "Î©_Î³ = 2.47e-5 / h**2 # photons only (part of Î©_r)\n",
    "Î©_m = 0.315 # Matter density, unitless\n",
    "Î©_b = 0.048 # baryons only (part of Î©_m)\n",
    "Î©_Î› = 1.0 - Î©_r - Î©_m # # Dark energy density, unitless\n",
    "Î©_k = 1.0 - Î©_m - Î©_Î› - Î©_r   # Omega for curvature (should be zero for LCDM)\n",
    "H0 = 100 * h  # H0 in km/s/Mpc\n",
    "\n",
    "# Box and sampling\n",
    "L = 20   # box size in Mpc\n",
    "N = 256  # grid size for creation of the initial delta field\n",
    "qp = 2    # Resampling factor N_bodies (N/qp)**3\n",
    "qpa = 4   # Resampling for animation: number of bodies in animation = (N/qg/qpa)**3\n",
    "qg = 2    # Resampling factor N_cells = (N/qg)**3\n",
    "\n",
    "# Simulation\n",
    "a_init = 0.01   # initial scale factor\n",
    "a_final = 1.0 # final scale factor\n",
    "steps = 600 # number of time steps\n",
    "steps_fine = 1200\n",
    "seed = 141 # Drives the random selection of the initial delta field\n",
    "use_TSC = True\n",
    "use_Python = False # True=Python functions for Leapfrog and Cooling/Heating (experimental), False means corresponding cpp function are used (speed)\n",
    "n_threads = 8 # Number of threads for parallel processing in cpp functions\n",
    "\n",
    "# Mesh refinement\n",
    "# For 20Mpc, seed=141, Halo 0\n",
    "cube_fine = 1.2 # Mpc\n",
    "center_fine = np.array([6.442, 7.726, 5.769]) #Mpc\n",
    "\n",
    "# For 20Mpc, seed=99, Halo 0\n",
    "#cube_fine = 1.2 # Mpc\n",
    "#center_fine = np.array([1.0, 9.5, 18.3]) #Mpc\n",
    "\n",
    "# For 10Mpc, seed=141, Halo 0\n",
    "#cube_fine = 0.6 # Mpc\n",
    "#center_fine = np.array([3.523,3.528,2.833]) #Mpc\n",
    "\n",
    "# For 30Mpc, seed=141, Halo 0\n",
    "#cube_fine = 3.2 # Mpc\n",
    "#center_fine = np.array([9.140,12.260,8.193]) #Mpc\n",
    "\n",
    "cube_fine = None # No mesh refinement (performance)\n",
    "refinement = 16 # Factor\n",
    "f_smooth = 3 # Smoothing of refined rho grid\n",
    "od_threshold = 100 # Overdensity at which grid refinement kicks in\n",
    "subcycles = 8 # Number of time subcycles in fine box\n",
    "n_jeans = 0.5 # Jeans factor (normally 2-4)\n",
    "margin = 3.5 # Margin in fine grid cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582a553",
   "metadata": {
    "id": "6582a553"
   },
   "source": [
    "__Î›-CDM cosmology__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d4379",
   "metadata": {
    "cellView": "form",
    "id": "c52d4379"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import quad\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import quad\n",
    "from numba import njit, prange\n",
    "\n",
    "# Physical constants\n",
    "m_sun = 1.989e30 # kg\n",
    "Mpc_m = 3.085677581e22 # m/Mpc\n",
    "Mpc_km = Mpc_m/1000 # km/Mpc\n",
    "Myr_s = 1e6 * 365 * 24 * 3600 # s/Myr\n",
    "c = 3e8  # m/s\n",
    "c_cos = c * Myr_s / Mpc_m # speed of light in pc/yr\n",
    "G = 6.67430e-11 * m_sun / Mpc_m**3 * Myr_s**2 # MpcÂ²â‹…(Mpc/MyrÂ²) / M_sun\n",
    "H0_cos = H0/Mpc_km*Myr_s # 1/Myr\n",
    "rho_crit0 = 3*H0_cos**2/8/np.pi/G # M_sun / MpcÂ³\n",
    "Gly_Mpc = 306.3915347309086 # in Mpc\n",
    "\n",
    "def E(a): # dimensionless Hubble parameter\n",
    "    return np.sqrt(Î©_r / a**4 + Î©_m / a**3 + Î©_k / a**2 + Î©_Î›)\n",
    "\n",
    "def D(a): # Linear Growth parameter\n",
    "    integrand = lambda a_: (a_ * E(a_))**-3\n",
    "    integral, _ = quad(integrand, 0, a, epsabs=1e-6)\n",
    "    integral_norm, _ = quad(integrand, 0, 1, epsabs=1e-6)\n",
    "    D_unnorm = (5/2) * Î©_m * E(a) * integral\n",
    "    D_norm = (5/2) * Î©_m * E(1) * integral_norm\n",
    "    return D_unnorm / D_norm\n",
    "\n",
    "def dLogD_dLoga(a):\n",
    "    da = 1e-4\n",
    "    return (np.log(D(a + da)) - np.log(D(a - da))) / (np.log(a + da) - np.log(a - da))\n",
    "\n",
    "def dD_dt(a):\n",
    "    da = 1e-4\n",
    "    return (D(a + da) - D(a - da)) / (2*da) * H_init * a_init\n",
    "\n",
    "def friedmann(t, y): # Friedmann equation (differential form)\n",
    "    a = y[0]\n",
    "    return H0_cos * a * np.sqrt(Î©_r / a**4 + Î©_m / a**3 + Î©_k / a**2 + Î©_Î›)\n",
    "\n",
    "def reach_today(t, y): # Event: stop when a(t) = 1\n",
    "    a = y[0]\n",
    "    return a - 1.0\n",
    "reach_today.terminal = True  # Stop integration\n",
    "reach_today.direction = 1    # Only trigger when increasing\n",
    "\n",
    "# Solve Friedman until a = 1 gives age of observable universe\n",
    "a0 = 1e-8 # Initial condition: tiny scale factor after Big Bang\n",
    "t_span = [0, 31000]  # Initial conditions: 0 to ~31 Gyr\n",
    "sol = solve_ivp(friedmann, t_span, [a0], events=reach_today, max_step=31, rtol=1e-12, atol=1e-12)\n",
    "t = sol.t     # Extract results\n",
    "a = sol.y[0]\n",
    "t_universe = sol.t_events[0][0] # Time at which a = 1\n",
    "\n",
    "# Compute comoving horizon distance (size of observable universe): d_H(t) = c * âˆ« (dt / a) and associated speed\n",
    "integrand = 1 / a\n",
    "integrand[0] = integrand[1] # the first value distorts the integration\n",
    "d_H = c_cos * cumulative_trapezoid(integrand, t, initial=0) # Mpc\n",
    "v_expansion = H0_cos * d_H[-1] # Expansion speed of observable universe today, Mpc/Myr\n",
    "\n",
    "# Interpolation of a(t) to find time of decoupling\n",
    "z_dec = 1089.0 # redshift (1089) is determined by detailed modelling of hydrogen recombination\n",
    "a_dec = 1 / (1 + z_dec)\n",
    "a_interp = interp1d(a, t)\n",
    "t_dec = a_interp(a_dec) #Myr\n",
    "\n",
    "# Determine sound horizon at decoupling\n",
    "def c_s(a): # Define sound speed c_s(a) in m/s\n",
    "    R = (3 * Î©_b) / (4 * Î©_Î³) * a\n",
    "    return c / np.sqrt(3 * (1 + R))\n",
    "cs_over_a = c_s(a) / a # Evaluate c_s(t) / a(t)\n",
    "i_dec = np.argmax(a >= a_dec)\n",
    "r_s = cumulative_trapezoid(cs_over_a[:i_dec+1], t[:i_dec+1] * Myr_s, initial=0)\n",
    "r_s_dec_m = r_s[-1] # Final sound horizon in meters (comoving distance)\n",
    "r_s_dec = r_s_dec_m / Mpc_m # in Mpc\n",
    "\n",
    "# Determine angular scale\n",
    "def H_z(z):  # Proper H(z)\n",
    "    return H0_cos * E(1 / (1 + z)) # 1/Myr\n",
    "def integrand(z):  # c / H(z)\n",
    "    return c_cos / H_z(z) # Mpc\n",
    "chi, _ = quad(integrand, 0, z_dec) # comoving distance\n",
    "theta_s_rad = r_s_dec / chi  # in radians\n",
    "ell_s = np.pi / theta_s_rad\n",
    "theta_s_deg = np.degrees(theta_s_rad) # Convert angle to degrees if desired\n",
    "\n",
    "# Determine Event horizon\n",
    "def integrand(a):\n",
    "    return c_cos / (a**2 * H0_cos * E(a)) # Mpc\n",
    "chi_event, _ = quad(integrand, 1, np.inf) # Integrate from now to z â†’ âˆž, Mpc\n",
    "\n",
    "print(f\"Computed age of the universe: {t_universe / 1e3:.1f} Gyr\") # should be ca. 13.8 Gyr\n",
    "print(f\"Observable universe radius today (particle horizon): {d_H[-1]/c_cos/1e3:.1f} Gly\") # should be ca. 46 Gly\n",
    "print(f\"Event horizon today: {chi_event/c_cos/1e3:.1f} Gly\") #should be 16.4 Gly\n",
    "print(f\"Hubble sphere today: {1/H0_cos/1e3:.1f} Gly\") #\n",
    "print(f\"Expansion speed of observable universe: {v_expansion/c_cos:.1f} c\") # should be ca. 900'000 km/s (3 c)\n",
    "print(f\"Time of CMB decoupling: {t_dec * 1e6:.0f} yr\") # should be 380'000 yr\n",
    "print(f\"Sound horizon at decoupling (comoving dist):  {r_s_dec / Gly_Mpc:.3f} Gly ({r_s_dec:.1f} Mpc)\") # should be 144.6 Mpc\n",
    "print(f\"Angular size of sound horizon: {theta_s_deg:.2f} degrees\")\n",
    "print()\n",
    "\n",
    "# Cosmological parameters at initial situation\n",
    "D_init = D(a_init)\n",
    "f_init = dLogD_dLoga(a_init)\n",
    "H_init = H0 * E(a_init)  # in km/s/Mpc\n",
    "dD_dt_init = dD_dt(a_init)\n",
    "\n",
    "print(\"Cosmological parameters at initialization:\")\n",
    "print(f\"a_init =     {a_init:.3f} (t={a_interp(a_init):.1f} Myr)\")\n",
    "print(f\"D_init =     {D_init:.3f}\")\n",
    "print(f\"f_init =     {f_init:.3f}\")\n",
    "print(f\"dD_dt_init = {dD_dt_init:.3f}\")\n",
    "print(f\"H_init =     {H_init:.3f} km/s/Mpc\")\n",
    "\n",
    "# Plot scale factor and acceleration\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.subplots_adjust(wspace=0.4)  # Increase horizontal space between subplots\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(t / 1e3, a, label='a(t)')\n",
    "ax1.set_xlabel(\"Time (Gyr)\")\n",
    "ax1.set_ylabel(\"Scale Factor a(t)\")\n",
    "ax1.set_title(\"Expansion of the Universe\")\n",
    "ax1.grid(True)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(t / 1e3, H0*E(a), color='orange', linestyle='--', label='H(t)')\n",
    "ax2.set_ylabel(\"H(t) [km/s/Mpc]\")\n",
    "ax2.set_ylim(top=1000)\n",
    "ax2.set_ylim(bottom=0)\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "# Plot comoving horizon distance\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(t/1e3, d_H/c_cos/1e3)\n",
    "plt.xlabel(\"Time (Gyr)\")\n",
    "plt.ylabel(\"Comoving Horizon (Gly)\")\n",
    "plt.title(\"Observable Universe Radius Over Time\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c765880",
   "metadata": {
    "id": "0c765880"
   },
   "source": [
    "__Create power spectrum__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee202a",
   "metadata": {
    "cellView": "form",
    "id": "f2ee202a"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "try:\n",
    "    import camb\n",
    "except ImportError:\n",
    "    !pip install camb\n",
    "    import camb\n",
    "from camb import model\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CAMB setup for ICs at z=32 (a=0.03)\n",
    "pars = camb.CAMBparams()\n",
    "pars.set_cosmology(H0=H0, ombh2=0.022, omch2=0.122)\n",
    "pars.InitPower.set_params(As=2e-9, ns=0.965)\n",
    "pars.set_matter_power(redshifts=[1/a_init-1], kmax=10.0)  # Key: z=32, not z=0!\n",
    "pars.NonLinear = model.NonLinear_none  # Linear power spectrum\n",
    "\n",
    "results = camb.get_results(pars)\n",
    "kh, z_pk, pk = results.get_matter_power_spectrum(minkh=1e-4, maxkh=10.0, npoints=1000)\n",
    "P_lin = interp1d(kh, pk[0], bounds_error=False, fill_value=0.0)\n",
    "\n",
    "# 2. Direct power spectrum through Cosmological parameters for comparison model\n",
    "A_s = 2.1e-9 # unitless\n",
    "n_s = 0.965 # unitless\n",
    "k_pivot = 0.05  # 1/Mpc\n",
    "c_km_s = 300000  # speed of light in km/s\n",
    "\n",
    "def T(k): # Eisenstein & Hu transfer function (no baryons)\n",
    "    q = k / (Î©_m * h**2)\n",
    "    L0 = np.log(2*np.e + 1.8*q)\n",
    "    C0 = 14.2 + 731.0 / (1 + 62.5*q)\n",
    "    return L0 / (L0 + C0 * q**2) # unitless\n",
    "\n",
    "def P_3D(k): # 3D power spectrum P(k) from analytical model. k in 1/Mpc\n",
    "    P_zeta = A_s * (k / k_pivot)**(n_s - 1) # unitless\n",
    "    T2 = T(k)**2 # unitless\n",
    "    factor = (c_km_s * k / H0)**2 # unitless\n",
    "    return 0.25 * (2 * np.pi**2 / k**3) * P_zeta * T2 * factor**2 # Mpc^-3, unexplained factor 0.25 to match CAMB power spectrum\n",
    "\n",
    "def get_analytic_power_interp(kmin=1e-4, kmax=10.0, num=1000):\n",
    "    ks = np.logspace(np.log10(kmin), np.log10(kmax), num)\n",
    "    pk = P_3D(ks) * D_init**2\n",
    "    return interp1d(ks, pk, bounds_error=False, fill_value=0.0)\n",
    "\n",
    "P_direct = get_analytic_power_interp()\n",
    "\n",
    "def ratio_func(k): # ratio b/w direct and CAMB power spectrum\n",
    "    return P_direct(k)/P_lin(k)\n",
    "\n",
    "# 3. Plot the power spectrum\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.loglog(kh, P_lin(kh), label=\"CAMB\")\n",
    "plt.loglog(kh, P_direct(kh), label=\"Direct\", linestyle='--')\n",
    "plt.loglog(kh, ratio_func(kh), label=\"Direct/CAMB\", linestyle='--')\n",
    "plt.xlabel(\"k [1/Mpc]\")\n",
    "plt.ylabel(\"P(k) [Mpc$^3$]\")\n",
    "plt.title(f\"Linear Matter Power Spectrum at z={1/a_init-1:.0f}\")\n",
    "plt.grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59c980",
   "metadata": {
    "id": "8e59c980"
   },
   "source": [
    "__Create delta field__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda26e08",
   "metadata": {
    "cellView": "form",
    "id": "fda26e08"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# 4. Build the k-grid and field generator\n",
    "def make_kgrid(N, L):\n",
    "    kf = np.fft.fftfreq(N, d=L/N) * 2*np.pi\n",
    "    kx = kf[:, None, None]\n",
    "    ky = kf[None, :, None]\n",
    "    kz = kf[None, None, :]\n",
    "    return np.sqrt(kx**2 + ky**2 + kz**2), kx, ky, kz # 1/Mpc\n",
    "\n",
    "def generate_gaussian_field(P_fn, N, L, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    kgrid, kx, ky, kz = make_kgrid(N, L) # 1/Mpc\n",
    "    Pk = P_fn(kgrid) # Mpc^-3\n",
    "    volume = L**3 # Mpc^3\n",
    "    dx = L/N\n",
    "    noise = np.random.normal(size=(N,N,N)) + 1j * np.random.normal(size=(N,N,N))\n",
    "    delta_k = noise * np.sqrt(Pk * volume / 2.0) #unitless\n",
    "    dx = L/N # unitless, since N is taken as Mpc in this context\n",
    "    delta = np.fft.ifftn(delta_k).real / dx**3 # unitless\n",
    "\n",
    "    return delta, delta_k, kgrid, kx, ky, kz\n",
    "\n",
    "# 5. Top-hat filter in k-space\n",
    "def W_tophat(k, R):\n",
    "    x = np.where(k*R==0, 1e-30, k*R) # unitless\n",
    "    return 3*(np.sin(x) - x*np.cos(x)) / x**3 # unitless\n",
    "\n",
    "def generate_smoothed_field(R, delta_k, kgrid):\n",
    "        W_R = W_tophat(kgrid, R) # unitless\n",
    "        if R == 0:\n",
    "            delta_k_R = delta_k # unitless\n",
    "        else:\n",
    "            delta_k_R = delta_k * W_R # unitless\n",
    "        dx = L/N # unitless, since N is taken as Mpc in this context\n",
    "        return delta_k_R, np.fft.ifftn(delta_k_R).real / dx**3  # unitless, smoothed real-space field\n",
    "\n",
    "# 6. Compute sigma_R from delta_k\n",
    "def compute_sigma_R(delta_k, kgrid, L, R):\n",
    "    Volume = L**3 # Mpc^3\n",
    "    W = W_tophat(kgrid, R) # unitless\n",
    "    delta_k_filt = delta_k * W # unitless\n",
    "    power = np.abs(delta_k_filt/Volume)**2 # ???\n",
    "    var = np.sum(power) # ???\n",
    "    return np.sqrt(var) # ???\n",
    "\n",
    "# 7. Theoretical sigma_R by direct integral\n",
    "def sigma_R_theory(P_fn, R):\n",
    "    ks = np.logspace(-4, 1.5, 2000)\n",
    "    Wks = W_tophat(ks, R)\n",
    "    integrand = ks**2 * P_fn(ks) * Wks**2 / (2*np.pi**2)\n",
    "    return np.sqrt(np.trapz(integrand, ks))\n",
    "\n",
    "# 8. Run everything\n",
    "R8 = 8.0 # Mpc\n",
    "delta_c = 1.686 # Define the collapse threshold\n",
    "dx = L / N\n",
    "delta, delta_k, kgrid, kx, ky, kz = generate_gaussian_field(P_lin, N, L, seed)\n",
    "sigma_sim = compute_sigma_R(delta_k, kgrid, L, R8)\n",
    "sigma_th  = sigma_R_theory(P_lin, R8)\n",
    "print(f\"Simulated Ïƒâ‚ˆ = {sigma_sim:.4f}\")\n",
    "print(f\"Theoretical Ïƒâ‚ˆ = {sigma_th:.4f}\")\n",
    "\n",
    "# Apply top-hat smoothing in Fourier space\n",
    "slice_index = N // 2\n",
    "_, delta_R8 = generate_smoothed_field(R8, delta_k, kgrid)\n",
    "print(f\"np.std(delta_R8) = {np.std(delta_R8):.4f}\")\n",
    "delta_R8_2D = delta_R8[:, :, slice_index]\n",
    "print(f\"np.std(delta_R8_2D) = {np.std(delta_R8_2D):.4f}\")\n",
    "print(f\"np.std(delta) = {np.std(delta):.4f}\")\n",
    "print(f\"np.mean(delta) = {np.mean(delta):.4f}\")\n",
    "\"\"\"\n",
    "# Plot 2D slice of the smoothed field, including contour at delta_crit\n",
    "plt.figure(figsize=(6, 5))\n",
    "im = plt.imshow(delta_R8_2D.T, origin='lower', extent=[0, L, 0, L], cmap='RdBu_r')\n",
    "plt.colorbar(im, label='Î´ (smoothed to Râ‚ˆ)')\n",
    "cs = plt.contour(delta_R8_2D.T, levels=[delta_c], colors='k', linewidths=1.0, extent=[0, L, 0, L]) # Add contour at Î´_c\n",
    "plt.clabel(cs, fmt={delta_c: 'Î´â‚›'}, inline=True, fontsize=10)\n",
    "plt.title(f\"2D Slice of Î´ Field Smoothed at R=8 Mpc (slice {slice_index})\") # Labels and title\n",
    "plt.xlabel(\"x [Mpc]\")\n",
    "plt.ylabel(\"y [Mpc]\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a506c9",
   "metadata": {
    "id": "63a506c9"
   },
   "source": [
    "__Collapsing regions (projected based on linear perturbation theory)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d695bc2",
   "metadata": {
    "cellView": "form",
    "id": "6d695bc2"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "slice_index = N // 2\n",
    "delta_2D = delta[:, :, slice_index] / D_init\n",
    "print(\"All values scaled up to a=1:\")\n",
    "print(f\"np.std(delta) = {np.std(delta/D_init):.4f}\")\n",
    "print(f\"np.mean(delta) = {np.mean(delta/D_init):.4f}\")\n",
    "print(f\"delta.shape = {delta.shape}\")\n",
    "print(f\"np.std(delta_2D) = {np.std(delta_2D):.4f}\")\n",
    "\n",
    "# Plot 2D slice of the field, including contour at delta_crit\n",
    "plt.figure(figsize=(6, 5))\n",
    "im = plt.imshow(delta_2D.T, origin='lower', extent=[0, L, 0, L], cmap='RdBu_r')\n",
    "plt.colorbar(im, label='Î´ (today)')\n",
    "cs = plt.contour(delta_2D.T, levels=[delta_c], colors='k', linewidths=1.0, extent=[0, L, 0, L]) # Add contour at Î´_c\n",
    "plt.clabel(cs, fmt={delta_c: 'Î´â‚›'}, inline=True, fontsize=10)\n",
    "plt.title(f\"Î´ Field (projected to today)\") # Labels and title\n",
    "plt.xlabel(\"x [Mpc]\")\n",
    "plt.ylabel(\"y [Mpc]\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c379e44",
   "metadata": {
    "id": "4c379e44"
   },
   "source": [
    "__Resample delta field__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b96454",
   "metadata": {
    "cellView": "form",
    "id": "46b96454"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "delta_excerpt = delta[0:N:qg, 0:N:qg, 0:N:qg]\n",
    "mean_delta_excerpt = np.mean(delta_excerpt)\n",
    "print(f\"np.std(delta_excerpt) = {np.std(delta_excerpt):.4f}\")\n",
    "print(f\"np.mean(delta_excerpt) = {mean_delta_excerpt:.4f}\")\n",
    "\n",
    "# Plot 2D slice of the smoothed field, including contour at delta_crit\n",
    "slice_excerpt = (N // 2) // qg\n",
    "plt.figure(figsize=(6, 5))\n",
    "im = plt.imshow(delta_excerpt[:,:,slice_excerpt].T, origin='lower', extent=[0, L, 0, L], cmap='RdBu_r')\n",
    "plt.colorbar(im, label='Î´ (initial)')\n",
    "cs = plt.contour(delta_excerpt[:,:,slice_excerpt].T, levels=[delta_c], colors='k', linewidths=1.0, extent=[0, L, 0, L]) # Add contour at Î´_c\n",
    "plt.clabel(cs, fmt={delta_c: 'Î´â‚›'}, inline=True, fontsize=10)\n",
    "plt.title(f\"Î´ Field (initial) resampled for simulation\") # Labels and title\n",
    "plt.xlabel(\"x [Mpc]\")\n",
    "plt.ylabel(\"y [Mpc]\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(delta[N//2,N//2,N//2], delta_excerpt[(N//2)//qg,(N//2)//qg,(N//2)//qg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193504e",
   "metadata": {
    "id": "f193504e"
   },
   "source": [
    "__Create body grid and apply Zeldovich__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15245349",
   "metadata": {
    "cellView": "form",
    "id": "15245349"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from scipy.fft import fftn, ifftn, fftfreq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Solve Poisson equation for potential\n",
    "k2 = kgrid**2\n",
    "k2[0, 0, 0] = 1e-20  # zero mean potential\n",
    "phi1_k = -delta_k / k2\n",
    "phi1_k[0, 0, 0] = 0.0  # zero mean potential\n",
    "dx_init = dx\n",
    "\n",
    "# Compute Zel'dovich displacements and velocities\n",
    "grad_phi1_x = np.fft.ifftn(-1j * kx * phi1_k).real / dx**3\n",
    "grad_phi1_y = np.fft.ifftn(-1j * ky * phi1_k).real / dx**3\n",
    "grad_phi1_z = np.fft.ifftn(-1j * kz * phi1_k).real / dx**3\n",
    "s1 = np.stack([grad_phi1_x, grad_phi1_y, grad_phi1_z], axis=-1)  # displacement field\n",
    "\n",
    "# --- Second-order source term: s2_k = âˆ‡Â²(Î¦_2) ---\n",
    "# Compute second derivatives of Î¦â‚\n",
    "phi1_xx = np.fft.ifftn(-(kx**2) * phi1_k).real\n",
    "phi1_yy = np.fft.ifftn(-(ky**2) * phi1_k).real\n",
    "phi1_zz = np.fft.ifftn(-(kz**2) * phi1_k).real\n",
    "phi1_xy = np.fft.ifftn(-kx * ky * phi1_k).real\n",
    "phi1_xz = np.fft.ifftn(-kx * kz * phi1_k).real\n",
    "phi1_yz = np.fft.ifftn(-ky * kz * phi1_k).real\n",
    "\n",
    "# Compute second-order source term S(x)\n",
    "S = ( phi1_xx * phi1_yy + phi1_xx * phi1_zz + phi1_yy * phi1_zz - phi1_xy**2 - phi1_xz**2 - phi1_yz**2 )\n",
    "\n",
    "# FFT of second-order source\n",
    "S_k = np.fft.fftn(S)\n",
    "phi2_k = -S_k / k2\n",
    "phi2_k[0, 0, 0] = 0.0\n",
    "\n",
    "# Second-order displacement field\n",
    "grad_phi2_x = np.fft.ifftn(-1j * kx * phi2_k).real / dx**6\n",
    "grad_phi2_y = np.fft.ifftn(-1j * ky * phi2_k).real / dx**6\n",
    "grad_phi2_z = np.fft.ifftn(-1j * kz * phi2_k).real / dx**6\n",
    "s2 = np.stack([grad_phi2_x, grad_phi2_y, grad_phi2_z], axis=-1)\n",
    "spacial_ratio = np.mean(np.linalg.norm(s2, axis=1)) / np.mean(np.linalg.norm(s1, axis=1))\n",
    "\n",
    "# Crop s1 and s2\n",
    "s1_crop = s1[0:N:qp, 0:N:qp, 0:N:qp].reshape(-1, 3)\n",
    "s1_crop -= np.mean(s1_crop, axis=0)\n",
    "s2_crop = s2[0:N:qp, 0:N:qp, 0:N:qp].reshape(-1, 3)\n",
    "s2_crop -= np.mean(s2_crop, axis=0)\n",
    "s1_max = np.max(np.linalg.norm(s1_crop, axis=1))\n",
    "s2_max = np.max(np.linalg.norm(s2_crop, axis=1))\n",
    "D2_init = -3/7 * Î©_m**(-1/143)\n",
    "f2_init = 2*f_init\n",
    "\n",
    "# Particle positions and velocities\n",
    "grid = np.indices((int(np.ceil(N/qp)), int(np.ceil(N/qp)), int(np.ceil(N/qp)))).reshape(3, -1).T #\n",
    "grid_downsampled = np.all(grid % qpa == 0, axis=1) # This is for later use in resampling for animation\n",
    "positions_unperturbed = grid * dx_init * qp  # unperturbed positions\n",
    "test_factor = 1.0\n",
    "positions = positions_unperturbed + test_factor*s1_crop  # displaced\n",
    "positions += test_factor*D2_init * s2_crop # 2nd order term\n",
    "velocities = test_factor*H_init * f_init * s1_crop  # in km/s\n",
    "velocities += test_factor*H_init * f2_init * D2_init * s2_crop # 2nd order term\n",
    "v_max = np.max(np.linalg.norm(velocities, axis=1))\n",
    "v_mean = np.mean(velocities, axis=0)\n",
    "velocities -= v_mean\n",
    "\n",
    "# Display summary\n",
    "print(f\"Generated {positions.shape} particles\")\n",
    "print(f\"displace.shape = {s1_crop.shape}\")\n",
    "print(f\"positions.shape = {positions.shape}\")\n",
    "print(f\"Initial scale factor a = {a_init:.4f}, H(a) = {H_init:.2f} km/s/Mpc\")\n",
    "print(f\"Growth factor  D(a) = {D_init:.4f},  f(a) = {f_init:.4f}\")\n",
    "print(f\"Max s1 dis = {s1_max:.4f} Mpc\")\n",
    "print(f\"Max s2 dis = {D2_init * s2_max:.4f} Mpc\")\n",
    "print(f\"Max s1 vel = {H_init * f_init * s1_max:.1f} km/s\")\n",
    "print(f\"Max s2 vel = {H_init * f2_init * D2_init * s2_max:.1f} km/s\")\n",
    "print(f\"Spacial ratio = {spacial_ratio:.3f}\")\n",
    "print(f\"Max velocity = {v_max:.1f} km/s\")\n",
    "print(f\"Mean velocity = {v_mean} km/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0111f5b3",
   "metadata": {
    "id": "0111f5b3"
   },
   "source": [
    "__Displacement and velocity consistency check__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a170cf3",
   "metadata": {
    "cellView": "form",
    "id": "9a170cf3"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#s1old = s1_crop # Mpc\n",
    "#s2old = s2_crop\n",
    "#deltatime = (0.033/0.03-1)/(H0_cos*E(0.03)) # Myr\n",
    "#deltas1 = s1_crop-s1old # Mpc\n",
    "#deltas2 = (s2_crop-s2old) * D2_init/D_init\n",
    "#vpec1 = deltas1/deltatime*Mpc_km/Myr_s # km/s\n",
    "#vpec2 = deltas2/deltatime*Mpc_km/Myr_s # km/s\n",
    "#vpec1_comp = H_init * f_init * s1_crop\n",
    "#vpec2_comp = H_init * f2_init * D2_init/D_init * s2_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e9e78",
   "metadata": {
    "id": "7c9e9e78"
   },
   "source": [
    "__Test of div s = -delta__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85252ae3",
   "metadata": {
    "cellView": "form",
    "id": "85252ae3"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def divergence_real_space(s, dx):\n",
    "    \"\"\"\n",
    "    Compute divergence of a vector field s on a grid using central differences.\n",
    "    s shape: (N, N, N, 3)\n",
    "    dx: grid spacing (scalar)\n",
    "    \"\"\"\n",
    "    div = np.zeros(s.shape[:-1])\n",
    "    for i in range(3):  # x, y, z components\n",
    "        ds_i = np.gradient(s[..., i], dx, axis=i)\n",
    "        div += ds_i\n",
    "    return div\n",
    "\n",
    "div_s1 = divergence_real_space(s1, dx=dx)\n",
    "error = div_s1 + delta\n",
    "\n",
    "max_error = np.max(np.abs(error))\n",
    "rms_error = np.sqrt(np.mean(error**2))\n",
    "\n",
    "print(f\"Max error (real-space): {max_error:.3e}\")\n",
    "print(f\"RMS error (real-space): {rms_error:.3e}\")\n",
    "print(f\"Max delta (real-space): {np.max(np.abs(delta)):.3e}\")\n",
    "print(f\"RMS delta (real-space): {np.std(delta):.3e}\")\n",
    "print(f\"Max div_s (real-space): {np.max(np.abs(div_s1)):.3e}\")\n",
    "print(f\"RMS div_s (real-space): {np.std(div_s1):.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde313e",
   "metadata": {
    "id": "5dde313e"
   },
   "source": [
    "__Grid properties for use by n-body simulation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ecef45",
   "metadata": {
    "cellView": "form",
    "id": "26ecef45"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "Ng = int(np.ceil(N/qg))  # grid size\n",
    "Np = int(np.ceil(N/qp))  # body resolution in 1D\n",
    "epsilon = (a_final/a_init)**(1/(steps+1))-1 # growth rate for scale factor (by iteration)\n",
    "epsilon_fine = (a_final/a_init)**(1/(steps_fine+1))-1 # growth rate for scale factor (by iteration)\n",
    "M_total = Î©_m * rho_crit0 * L**3  # M_sun\n",
    "\n",
    "# Two identical regular grids for baryons and dark matter\n",
    "body_positions = np.vstack([positions, positions])  # duplicate positions for baryons and dark matter\n",
    "body_positions_unperturbed = np.vstack([positions_unperturbed, positions_unperturbed])\n",
    "body_velocities = np.vstack([velocities, velocities])  # duplicate velocities for baryons and dark matter\n",
    "grid_downsampled = np.hstack([grid_downsampled, grid_downsampled])  # duplicate for baryons and dark matter\n",
    "N_bodies = body_positions.shape[0] # Number of particles\n",
    "N_baryon = positions.shape[0] # TESTING\n",
    "masses_baryon = np.full(N_baryon, Î©_b / Î©_m * M_total / N_baryon)\n",
    "masses_dark = np.full(N_bodies - N_baryon, (Î©_m - Î©_b) / Î©_m * M_total / (N_bodies - N_baryon))\n",
    "masses = np.hstack([masses_baryon, masses_dark])  # mass per particle in M_sun\n",
    "baryon_set = np.hstack([np.ones(N_baryon, dtype=bool), np.zeros(N_bodies - N_baryon, dtype=bool)])\n",
    "baryon_indices = np.where(baryon_set)[0]\n",
    "\n",
    "print(f\"body_positions.shape = {body_positions.shape}\")\n",
    "print(f\"body_velocities.shape = {body_velocities.shape}\")\n",
    "print(f\"Mean body position = {np.mean(body_positions, axis=0)} Mpc\")\n",
    "print(f\"Mean velocity = {np.mean(body_velocities, axis=0)} km/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30eaf87",
   "metadata": {
    "id": "d30eaf87"
   },
   "source": [
    "__Zeldovich Consistency Check__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc3151",
   "metadata": {
    "cellView": "form",
    "id": "1ffc3151"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Zeldovich consistency check\n",
    "def show_zeldovich_consistency(delta_input, delta_measured): # Scatter plot\n",
    "    correlation = np.corrcoef(delta_input, delta_measured)[0, 1]\n",
    "    print(f\"Correlation coefficient: {correlation:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(delta_input, delta_measured, s=1, alpha=0.2)\n",
    "    plt.xlabel(\"Input Î´ (from field)\")\n",
    "    plt.ylabel(\"Measured Î´ (from displaced particles)\")\n",
    "    plt.title(\"Zeldovich Consistency Test\")\n",
    "    plt.plot([-1, 1], [-1, 1], 'r--')  # identity line\n",
    "    plt.grid(True)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4bd5f",
   "metadata": {
    "cellView": "form",
    "id": "2bd4bd5f"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Produce Zeldovich Consistency Chart\n",
    "dm = np.mean(delta_excerpt)\n",
    "delta_input = delta_excerpt.flatten() - dm\n",
    "delta_measured = grad_phi5.deposit_delta(positions=body_positions, masses=masses, Ngrid=Ng, L=L, use_TSC=use_TSC, n_threads=n_threads).flatten()\n",
    "show_zeldovich_consistency(delta_input, delta_measured) # Scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b111d8",
   "metadata": {
    "id": "01b111d8"
   },
   "source": [
    "__Plot initial positions and velocities__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa402f60",
   "metadata": {
    "cellView": "form",
    "id": "aa402f60"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Plot initial positions and velocities\n",
    "body_z = body_positions[:, 2]\n",
    "body_mask = (body_z > L/2 - qp*dx_init/2) & (body_z < L/2 + qp*dx_init/2)\n",
    "vx = body_velocities[body_mask, 0]\n",
    "vy = body_velocities[body_mask, 1]\n",
    "x_pos = body_positions[body_mask, 0]\n",
    "y_pos = body_positions[body_mask, 1]\n",
    "\n",
    "step = 1\n",
    "x_plot = x_pos[::step]\n",
    "y_plot = y_pos[::step]\n",
    "vx_plot = vx[::step]\n",
    "vy_plot = vy[::step]\n",
    "\n",
    "print(f\"body_positions.shape = {body_positions.shape}\")\n",
    "print(f\"body_velocities.shape = {body_velocities.shape}\")\n",
    "print(f\"Mean body position = {np.mean(body_positions, axis=0)} Mpc\")\n",
    "print(f\"Mean velocity = {np.mean(body_velocities, axis=0)} km/s\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(body_positions[body_mask, 0], body_positions[body_mask, 1], s=1, alpha=0.5)\n",
    "plt.title(f\"Particle Distribution (z={int(1/a_init)-1}, Slice {qp*dx:.3e} Mpc)\")\n",
    "plt.xlabel(\"x [Mpc]\")\n",
    "plt.ylabel(\"y [Mpc]\")\n",
    "plt.xlim(0, L)\n",
    "plt.ylim(0, L)\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.quiver(x_plot, y_plot, vx_plot, vy_plot, scale=v_max*2, width=0.002, color='darkblue')\n",
    "plt.title(\"Velocity Field (2D slice)\")\n",
    "plt.xlabel(\"x [Mpc]\")\n",
    "plt.ylabel(\"y [Mpc]\")\n",
    "plt.xlim(0, L)\n",
    "plt.ylim(0, L)\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b2895",
   "metadata": {
    "id": "c88b2895"
   },
   "source": [
    "# n-body simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf22be3",
   "metadata": {
    "cellView": "form",
    "id": "bdf22be3"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Lambda tables and constants\n",
    "\n",
    "# --- units & constants ---\n",
    "Mpc_to_cm = 3.085677581e24\n",
    "Myr_to_s  = 3.15576e13\n",
    "Msun_to_g = 1.98847e33\n",
    "m_p       = 1.6726219e-24      # g\n",
    "k_B       = 1.380649e-16       # erg/K\n",
    "gamma_ad  = 5.0/3.0\n",
    "mu_ion    = 0.59               # fully ionized mean molecular weight\n",
    "mu_neutral= 1.22               # pre-reionization\n",
    "X_H       = 0.76               # H mass fraction\n",
    "G_cgs     = 6.67430e-8         # cm^3 g^-1 s^-2\n",
    "sigma_T   = 6.6524587158e-25     # cm^2\n",
    "m_e     = 9.10938356e-28       # g\n",
    "c_light = 2.99792458e10        # cm/s\n",
    "a_rad   = 7.5657e-15           # erg cm^-3 K^-4\n",
    "\n",
    "# https://local.strw.leidenuniv.nl/WSS08/\n",
    "# This website hosts the Wiersma tables\n",
    "\n",
    "# https://myhdf5.hdfgroup.org/\n",
    "# This is a website that can display and manage .hdf5 files\n",
    "\n",
    "data = np.load(\"cooling_table_v1.npz\")\n",
    "grad_phi5.set_lambda_table(data[\"z_grid\"], data[\"Z_grid\"], data[\"nH_grid\"], data[\"T_grid\"], data[\"Lambda\"])\n",
    "collis = np.load(\"cooling_table_collis_v1.npz\")\n",
    "grad_phi5.set_lambda_collis(collis[\"T_grid\"], collis[\"Lambda\"])\n",
    "\n",
    "# Tiny smoke test\n",
    "print(\"Lambda_T_nH_Z_z:\")\n",
    "print(\"Î› ~\", grad_phi5.Lambda_T_nH_Z_z(1e6, 1e-3, 1.0, 0.0), \"erg cm^3 s^-1\") # MW-like halo gas: T~1e6 K, nH~1e-3 cm^-3, Z~1 Zsun, z=0\n",
    "print(\"Î› ~\", grad_phi5.Lambda_T_nH_Z_z(1e4, 1e-5, 0.1, 3.0), \"erg cm^3 s^-1\") # IGM-like: T~1e4 K, nH~1e-5 cm^-3, Z~0.1, z=3\n",
    "print(\"Î› ~\", grad_phi5.Lambda_T_nH_Z_z(1000, 1e-8, 0.0, 0.0), \"erg cm^3 s^-1 (should be -6.47933756005432e-23)\")\n",
    "\n",
    "print(\"Lambda_collis:\")\n",
    "print(\"Î› ~\", grad_phi5.Lambda_collis(1e6), \"erg cm^3 s^-1\")\n",
    "print(\"Î› ~\", grad_phi5.Lambda_collis(1e4), \"erg cm^3 s^-1\")\n",
    "print(\"Î› ~\", grad_phi5.Lambda_collis(100), \"erg cm^3 s^-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108920e5",
   "metadata": {
    "cellView": "form",
    "id": "108920e5"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Main thermodynamic module\n",
    "from scipy.ndimage import uniform_filter\n",
    "#--- density-dependent metallicity proxy: Z/Z_sun as function of (nH, z) ---\n",
    "@njit\n",
    "def T_CMB_of_z(z):  # K\n",
    "    return 2.7255 * (1.0 + z)\n",
    "\n",
    "@njit\n",
    "def u_CMB(z, mu):\n",
    "    \"\"\"Specific internal energy corresponding to T_CMB(z) [erg g^-1].\"\"\"\n",
    "    return 1.5 * k_B * T_CMB_of_z(z) / (mu * m_p)\n",
    "\n",
    "@njit\n",
    "def lambda_S_Compton(z, x_e=2e-4, mu=0.59, fHe=0.079, w=1.0):\n",
    "    # Return (lambda, S) for the affine update du/dt = -lambda*u + S\n",
    "    # representing Compton coupling. Optional weight w scales the rate.\n",
    "    Tcmb = T_CMB_of_z(z)\n",
    "    A = (8.0 * sigma_T * a_rad * Tcmb**4) / (3.0 * m_e * c_light)  # [s^-1]\n",
    "    lam = w * A * (x_e / (1.0 + x_e + fHe))                        # [s^-1]\n",
    "    S   = lam * u_CMB(z, mu)                                       # [erg g^-1 s^-1]\n",
    "    return lam, S\n",
    "\n",
    "@njit\n",
    "def Zsolar_of_nH_z(\n",
    "    nH,\n",
    "    z,\n",
    "    n0=7e-4,\n",
    "    alpha=1.1,\n",
    "    Z_cap=1.0,\n",
    "    n_dense=1e-2,\n",
    "    Z_cap_dense=3.0,\n",
    "    beta_dense=0.25\n",
    "):\n",
    "    # nH: hydrogen number density [cm^-3]\n",
    "    # z : redshift\n",
    "    # returns: Z/Z_sun (dimensionless)\n",
    "\n",
    "    # baseline redshift evolution of global metals\n",
    "    Z_floor = 0.05  * 10**(-0.15 * z)   # diffuse IGM-like lower envelope\n",
    "    Z_max_base   = Z_cap * 10**(-0.15 * z)   # enriched gas upper envelope\n",
    "    s = (np.maximum(nH, 1e-12) / n0)**alpha\n",
    "\n",
    "    # dense, shielded material can self-enrich beyond the diffuse cap\n",
    "    dense_ratio = np.maximum(nH / np.maximum(n_dense, 1e-30), 1.0)\n",
    "    dense_boost = np.minimum(dense_ratio**beta_dense, Z_cap_dense / np.maximum(Z_cap, 1e-30))\n",
    "    Z_max_dense = Z_max_base * dense_boost\n",
    "\n",
    "    Z_target = np.minimum(Z_max_dense, Z_cap_dense * 10**(-0.1 * z))\n",
    "    return Z_floor + (Z_target - Z_floor) * (s / (1.0 + s))\n",
    "\n",
    "def x_e_residual(z):\n",
    "    # Residual free electron fraction (very approximate; clamp to sane bounds)\n",
    "    # ~2e-4 at z~100 with mild z dependence\n",
    "    xe = 2.0e-4 * ((1.0 + z)/100.0)**0.5\n",
    "    return np.clip(xe, 1e-5, 3e-4)\n",
    "\n",
    "# temperature/internal-energy conversions ----\n",
    "@njit\n",
    "def u_from_T(T, mu=mu_ion, gamma=gamma_ad):\n",
    "    return (k_B * T) / ((gamma - 1.0) * mu * m_p) # erg/g\n",
    "\n",
    "@njit\n",
    "def T_from_u(u, mu=mu_ion, gamma=gamma_ad):\n",
    "    return (gamma - 1.0) * u * mu * m_p / k_B # K\n",
    "\n",
    "@njit\n",
    "def shielding_factor_totalH(\n",
    "    nH,                 # hydrogen number density [cm^-3]\n",
    "    rho_b_phys,         # total physical mass density in the cell [g cm^-3]\n",
    "    dx_phys_cm,         # physical cell size [cm]\n",
    "    mean_baryon_mass,   # mean baryon mass [g]\n",
    "    Zsol,               # metallicity relative to solar\n",
    "    alpha_len=2.0,      # multiplier for safety margin on L_sh\n",
    "    sigma_eff=2.0e-18,  # effective gas cross section [cm^2]\n",
    "    sigma_d=1.0e-21     # dust cross section per H per Z' [cm^2]\n",
    "):\n",
    "    # Computes a per-cell total self-shielding factor f_sh (0â€“1)\n",
    "    # using total hydrogen and a characteristic local shielding length.\n",
    "\n",
    "    tiny = 1e-40 #    Avoid division by zero where rho = 0\n",
    "    ell_p = np.power(np.maximum(mean_baryon_mass / np.maximum(rho_b_phys, tiny), 0.0), 1.0/3.0) # Inter-particle spacing per cell (in cm)\n",
    "    L_sh = alpha_len * np.maximum(dx_phys_cm, ell_p) # Local shielding length\n",
    "    NH = nH * L_sh # Total hydrogen column [cm^-2]\n",
    "    f_gas  = np.exp(-sigma_eff * NH) # Gas and dust attenuation\n",
    "    f_dust = np.exp(-sigma_d * Zsol * NH)\n",
    "    f_sh = f_gas * f_dust # Combined self-shielding factor\n",
    "    return f_sh\n",
    "\n",
    "@njit\n",
    "def jeans_temperature_floor(rho_phys, dx_phys_cm, mu, n_jeans, gamma=gamma_ad, G_cgs=G_cgs):\n",
    "    \"\"\"Return a temperature floor so the Jeans length â‰¥ n_jeans * Î”x.\"\"\"\n",
    "    if n_jeans <= 0: return np.zeros_like(rho_phys)\n",
    "    coeff = (mu * m_p) / (gamma * k_B)\n",
    "    factor = (n_jeans**2 * G_cgs) / np.pi\n",
    "    return coeff * factor * rho_phys * (dx_phys_cm**2)\n",
    "\n",
    "@njit\n",
    "def binned_means(values, bins, bin_values):\n",
    "    # Compute the mean of 'values' in bins defined by 'bins', based on 'bin_values'.\n",
    "    means = []\n",
    "    for i in range(len(bins) - 1):\n",
    "        mask = (bin_values >= bins[i]) & (bin_values < bins[i + 1])\n",
    "        if np.any(mask): means.append(float(np.mean(values[mask])))\n",
    "        else: means.append(np.nan)\n",
    "    return means\n",
    "\n",
    "def cooling_heating_step_baryons_py(\n",
    "    pos_baryon, vel_baryon, masses_baryon, rho_b_coarse_com_mean,\n",
    "    U_baryon, Lbox_Mpc, Ng, dt_Myr, a,\n",
    "    use_TSC = False, n_threads=8, z_reion=8.0, dz_trans=0.5, C_cfl=0.2, smooth = 1\n",
    "):\n",
    "    global n_jeans\n",
    "    # Mesh-based thermochemistry:\n",
    "    #  1) deposit baryon mass -> rho_b_com_grid\n",
    "    #  2) deposit particle u -> u_grid (mass-weighted == number-weighted for equal-mass)\n",
    "    #  3) compute cell-wise nH, T, rates; update u_grid with limiter\n",
    "    #  4) gather updated u back to baryon particles\n",
    "    # Returns: u_new (N,), T_part (on baryons), diag dict\n",
    "\n",
    "    z_now = 1.0/np.maximum(a, 1e-6) - 1.0\n",
    "    dt_s  = dt_Myr * Myr_to_s # s\n",
    "\n",
    "    # Densities on grid: comoving, then physical, then nH\n",
    "    rho_b_com_grid, dx = grad_phi5.deposit_density(pos_Mpc=pos_baryon, masses=masses_baryon, Lbox_Mpc=Lbox_Mpc, Ng=Ng, use_TSC=use_TSC) # Mpc^-3\n",
    "    if smooth > 1: rho_b_com_grid = uniform_filter(rho_b_com_grid, size=smooth, mode='nearest')\n",
    "    od_b_grid = rho_b_com_grid / rho_b_coarse_com_mean # unitless\n",
    "    max_b_od = np.max(od_b_grid) # unitless\n",
    "    rho_b_com_grid *=  Msun_to_g / Mpc_to_cm**3 # g/cm^3\n",
    "    rho_b_phys_grid = rho_b_com_grid / a**3 # g/cm^3\n",
    "    nH_grid       = (X_H * rho_b_phys_grid) / m_p # cm^-3\n",
    "    nH_mean   = float(np.mean(nH_grid)) # for UV calibration\n",
    "    nH_max    = float(np.max(nH_grid)) # for UV calibration\n",
    "    w_hi = 1.0 / (1.0 + np.exp(-(z_now - z_reion)/dz_trans)) # unitless\n",
    "    w_reion = 1.0 - w_hi\n",
    "\n",
    "    Z_sol = Zsolar_of_nH_z(nH_grid, z_now)\n",
    "    mean_baryon_mass = np.mean(masses_baryon) # Msun\n",
    "\n",
    "    f_sh = shielding_factor_totalH(\n",
    "        nH=nH_grid,\n",
    "        rho_b_phys=rho_b_phys_grid,\n",
    "        dx_phys_cm=dx * a * Mpc_to_cm,\n",
    "        mean_baryon_mass=mean_baryon_mass * Msun_to_g,\n",
    "        Zsol=Z_sol\n",
    "    )\n",
    "    shield_weight = np.minimum(np.maximum(1.0 - f_sh, 0.0), 1.0)\n",
    "    mu_grid = (\n",
    "        mu_neutral * (w_hi + shield_weight * w_reion) +\n",
    "        mu_ion * ((1.0 - shield_weight) * w_reion)\n",
    "    )\n",
    "\n",
    "    # Deposit u to grid (erg/g), compute T on grid with Î¼(a)\n",
    "    U_grid, _ = grad_phi5.deposit_scalar(pos_Mpc=pos_baryon, masses=masses_baryon, scalar=U_baryon, Lbox_Mpc=Lbox_Mpc, Ng=Ng, use_TSC=use_TSC) # erg/g\n",
    "    if smooth > 1: U_grid = uniform_filter(U_grid, size=smooth, mode='nearest')\n",
    "    T_jeans = jeans_temperature_floor(rho_b_phys_grid, dx*a*Mpc_to_cm, mu_grid, n_jeans=n_jeans, gamma=gamma_ad, G_cgs=G_cgs)\n",
    "    T_grid = np.clip(T_from_u(U_grid, mu_grid), np.maximum(T_CMB_of_z(z_now), T_jeans), 1e9) # K\n",
    "    U_grid = u_from_T(T_grid, mu_grid) # re-apply clipped T_grid to derive U_grid, erg g^-1\n",
    "\n",
    "    T_jeans_min = np.min(T_jeans)\n",
    "    T_jeans_max = np.max(T_jeans)\n",
    "    T_jeans_mean = np.mean(T_jeans)\n",
    "    T_jeans_mwm = np.mean(T_jeans*rho_b_phys_grid)/np.mean(rho_b_phys_grid)\n",
    "\n",
    "    # Pressure term, including artificial viscosity\n",
    "    vx, vy, vz = grad_phi5.deposit_vector(pos_Mpc=pos_baryon, masses=masses_baryon, vec=vel_baryon, Lbox_Mpc=Lbox_Mpc, Ng=Ng, use_TSC=use_TSC) # Mpc/Myr\n",
    "    vx *= Mpc_to_cm / Myr_to_s; vy *= Mpc_to_cm / Myr_to_s; vz *= Mpc_to_cm / Myr_to_s # cm/s\n",
    "    P_phys_grid = (gamma_ad - 1.0) * rho_b_phys_grid * U_grid # erg/cm^3\n",
    "    q_visc, div_v_s, S_min = grad_phi5.artificial_viscosity_q_cgs( # erg/cm^3, 1/s, unitless\n",
    "        rho_b_phys_grid,\n",
    "        U_grid,\n",
    "        vx,\n",
    "        vy,\n",
    "        vz,\n",
    "        dx*Mpc_to_cm,\n",
    "        a,\n",
    "        C2=0.5,\n",
    "        C1=0.0,\n",
    "        Ctheta = 5.0\n",
    "    )\n",
    "    q_visc = np.where(div_v_s < 0.0, q_visc, 0.0)\n",
    "    P_phys_grid += q_visc  # use effective pressure everywhere, erg/cm^3\n",
    "\n",
    "    # pressure acceleration on mesh, then gather to baryons ---\n",
    "    aPx, aPy, aPz    = grad_phi5.pressure_acceleration_grid(rho_b_com_grid=rho_b_com_grid, P_phys=P_phys_grid, a=a, dx=dx*Mpc_to_cm) # erg cm^-1 g^-1 = cm s^-2\n",
    "    aPx *= Myr_to_s**2 / Mpc_to_cm # Mpc/Myr^2\n",
    "    aPy *= Myr_to_s**2 / Mpc_to_cm\n",
    "    aPz *= Myr_to_s**2 / Mpc_to_cm\n",
    "    aP_new = grad_phi5.gather_vector(ax=aPx, ay=aPy, az=aPz, pos_Mpc=pos_baryon, Ngrid=Ng, Lbox_Mpc=Lbox_Mpc, use_TSC=use_TSC, n_threads=n_threads) # Mpc/Myr^2\n",
    "\n",
    "    # CFL (Courantâ€“Friedrichsâ€“Lewy) timestep ---\n",
    "    # Sound speed from u: c_s^2 = Î³(Î³-1) u  (u in erg/g => cm^2/s^2)\n",
    "    c_s_cms_grid = np.sqrt(np.maximum(gamma_ad * (gamma_ad - 1.0) * U_grid, 0.0))\n",
    "    c_s_max_cms  = float(np.max(c_s_cms_grid))\n",
    "    v_max_Mpc_Myr = float(np.max(np.linalg.norm(vel_baryon, axis=1))) # Combine with max baryon speed (particles)\n",
    "    c_s_max_Mpc_Myr = c_s_max_cms * (Myr_to_s / Mpc_to_cm) / max(a, 1e-12)\n",
    "    dt_cfl = C_cfl * dx / max(c_s_max_Mpc_Myr + v_max_Mpc_Myr, 1e-20)\n",
    "\n",
    "    # Transition weight (scalar): 1 at high-z (primordial branch), 0 at low-z\n",
    "    w_thres = 1e-5 # unitless\n",
    "    epochs = [w_hi > w_thres, 1.0 - w_hi > w_thres] # boolean\n",
    "\n",
    "    lam_shielded = np.zeros_like(U_grid)\n",
    "    S_shielded   =  np.zeros_like(U_grid)\n",
    "    lam_unshielded = np.zeros_like(U_grid)\n",
    "    S_unshielded   =  np.zeros_like(U_grid)\n",
    "\n",
    "    x_e_floor = x_e_residual(z_now)\n",
    "    x_e_grid = x_e_floor + (1.0 - x_e_floor) * (1.0 - shield_weight) * w_reion\n",
    "    x_e_grid = np.minimum(np.maximum(x_e_grid, x_e_floor), 1.0)\n",
    "\n",
    "    Zsol_min = np.min(Z_sol)\n",
    "    Zsol_max = np.max(Z_sol)\n",
    "    Zsol_mean = np.mean(Z_sol)\n",
    "\n",
    "    C_CIE = (nH_grid**2) * grad_phi5.Lambda_collis(T=T_grid, n_threads=n_threads) # erg cm^-3 s^-1\n",
    "    C_PIE = (nH_grid**2) * grad_phi5.Lambda_T_nH_Z_z(T=T_grid, nH=nH_grid, Z_solar=Z_sol, z=z_now, n_threads=n_threads) # erg cm^-3 s^-1\n",
    "    lam_comp, S_comp = lambda_S_Compton(z_now, x_e=x_e_grid, mu=mu_grid) # s^-1, erg g^-1 s^-1\n",
    "\n",
    "    # Cell-wise cooling/heating rates\n",
    "    if epochs[0]: # --- High-z: primordial, Unshielded = Total = CIE+Compton, Shielded = 0\n",
    "        du_dt_cool_grid = C_CIE / np.maximum(rho_b_phys_grid, 1e-32) # erg g^-1 s^-1\n",
    "        lam_unshielded += w_hi / U_grid * du_dt_cool_grid # Net Cooling/Heating, s^-1\n",
    "        lam_unshielded += w_hi * lam_comp # s^-1\n",
    "        S_unshielded   += w_hi * S_comp # Compton, erg g^-1 s^-1\n",
    "\n",
    "    if epochs[1]: # --- Low-z: Shielded = PIE-CIE-Compton, Unshielded = +CIE+Compton, Total = Unshielded + f_sh * Shielded\n",
    "        du_dt_cool_grid = (C_PIE - C_CIE) / np.maximum(rho_b_phys_grid, 1e-32) # erg g^-1 s^-1\n",
    "        lam_shielded += (1.0 - w_hi) / U_grid * du_dt_cool_grid # Heating only, s^-1\n",
    "        lam_shielded -= (1.0 - w_hi) * lam_comp # s^-1\n",
    "        S_shielded   -= (1.0 - w_hi) * S_comp # Compton, erg g^-1 s^-1\n",
    "\n",
    "        du_dt_cool_grid = (C_CIE) / np.maximum(rho_b_phys_grid, 1e-32) # erg g^-1 s^-1\n",
    "        lam_unshielded += (1.0 - w_hi) / U_grid * du_dt_cool_grid # Cooling only, s^-1\n",
    "        lam_unshielded += (1.0 - w_hi) * lam_comp # s^-1\n",
    "        S_unshielded   += (1.0 - w_hi) * S_comp # Compton, erg g^-1 s^-1\n",
    "\n",
    "    lam_unshielded += (gamma_ad - 1.0) * (div_v_s / a) # pdv, s^-1\n",
    "    S_unshielded   += -q_visc / np.maximum(rho_b_phys_grid, 1e-40) * (div_v_s / a) # Artificial Viscosity, erg g^-1 s^-1\n",
    "\n",
    "    f_sh_min = np.min(f_sh)\n",
    "    f_sh_max = np.max(f_sh)\n",
    "    f_sh_mean = np.mean(f_sh)\n",
    "    f_sh_mwm = np.mean(f_sh*rho_b_phys_grid)/np.mean(rho_b_phys_grid)\n",
    "\n",
    "    lam = lam_unshielded + f_sh * lam_shielded\n",
    "    S = S_unshielded + f_sh * S_shielded\n",
    "\n",
    "    # Solve: du/dt = -Î» u + S\n",
    "    mask = np.abs(lam*dt_s) > 1e-10 # Thats when exponential update works\n",
    "    e = np.exp(-lam * dt_s) # unitless\n",
    "    U_grid_new = np.zeros_like(U_grid)\n",
    "    U_grid_new[mask] = U_grid[mask] * e[mask] + (S[mask] / lam[mask]) * (1.0 - e[mask]) # exponential update, erg g^-1\n",
    "    U_grid_new[~mask] = U_grid[~mask] + S[~mask]*dt_s # linear update, erg g^-1\n",
    "    H_a = H0_cos * E(a) # 1/Myr\n",
    "    U_grid_new += -2.0 * dt_Myr * H_a * U_grid # Hubble component, # erg g^-1\n",
    "    T_grid_new = np.clip(T_from_u(U_grid_new, mu_grid), np.maximum(T_CMB_of_z(z_now), T_jeans), 1e9) # K\n",
    "    U_grid_new = u_from_T(T_grid_new, mu_grid) # re-apply clipped T_grid_new to derive U_grid, erg g^-1\n",
    "\n",
    "    # Gather updated u back to particles; also return particle T and P for convenience\n",
    "    U_new = grad_phi5.gather_scalar(grid=U_grid_new, pos_Mpc=pos_baryon, Lbox_Mpc=Lbox_Mpc, dx=dx, use_TSC=use_TSC, n_threads=n_threads) # erg g^-1\n",
    "    T_new = grad_phi5.gather_scalar(grid=T_grid_new, pos_Mpc=pos_baryon, Lbox_Mpc=Lbox_Mpc, dx=dx, use_TSC=use_TSC, n_threads=n_threads) # K\n",
    "    P_new = grad_phi5.gather_scalar(grid=P_phys_grid, pos_Mpc=pos_baryon, Lbox_Mpc=Lbox_Mpc, dx=dx, use_TSC=use_TSC, n_threads=n_threads)\n",
    "\n",
    "    od_bins = [0.0, 1.0, 10.0, 100.0, 1000.0, np.inf] # Overdensity bins: [0â€“1), [1â€“10), [10â€“100), [100â€“1000), [1000+)\n",
    "    temp_by_b_od = binned_means(T_grid.ravel(), od_bins, od_b_grid.ravel() ) # Compute the mean temperatures in each overdensity bin\n",
    "\n",
    "    diagnosis = dict(\n",
    "        nH_mean = nH_mean,\n",
    "        nH_max = nH_max,\n",
    "        Zsol_min = Zsol_min,\n",
    "        Zsol_max = Zsol_max,\n",
    "        Zsol_mean = Zsol_mean,\n",
    "        f_sh_min = f_sh_min,\n",
    "        f_sh_max = f_sh_max,\n",
    "        f_sh_mean = f_sh_mean,\n",
    "        f_sh_mwm = f_sh_mwm,\n",
    "        T_jeans_min = T_jeans_min,\n",
    "        T_jeans_max = T_jeans_max,\n",
    "        T_jeans_mean = T_jeans_mean,\n",
    "        T_jeans_mwm = T_jeans_mwm\n",
    "    )\n",
    "    return U_new, T_new, aP_new, P_new, diagnosis, epochs, dt_cfl, max_b_od, np.nan, temp_by_b_od, S_min\n",
    "\n",
    "# Initialize internal energy u at a_init (z_init)\n",
    "def init_internal_energy(pos_Mpc, baryon_mask, masses, Lbox_Mpc, Ng, a_init,\n",
    "                         model=\"pre_reion_adiabatic\", T_floor=50.0,\n",
    "                         z_dec=150.0, n_threads=8):\n",
    "    # Initialize u [erg/g] at a_init.\n",
    "    # - pre_reion_adiabatic: T starts from T_CMB(z_dec) and scales âˆ (1+z)^2, with optional mild density boost.\n",
    "    # - post_reion_uniform : T = 1e4 K everywhere.\n",
    "\n",
    "    # baryon density field (for optional compressional boost)\n",
    "    z_init = 1.0/np.maximum(a_init, 1e-6) - 1.0\n",
    "    rho_b_com_grid, dx = grad_phi5.deposit_density(pos_Mpc=pos_Mpc[baryon_mask], masses=masses[baryon_mask], Lbox_Mpc=Lbox_Mpc, Ng=Ng, use_TSC=use_TSC) # Mpc^-3\n",
    "    rho_b_com_grid *= Msun_to_g / Mpc_to_cm**3\n",
    "    rho_phys_part = grad_phi5.gather_scalar(grid=rho_b_com_grid / a_init**3, pos_Mpc=pos_Mpc[baryon_mask], Lbox_Mpc=Lbox_Mpc, dx=dx, use_TSC=use_TSC, n_threads=n_threads)\n",
    "    rho_phys_mean = np.mean(rho_phys_part)\n",
    "\n",
    "    if model == \"pre_reion_adiabatic\":\n",
    "        # Start from CMB at decoupling, then adiabatic T âˆ a^-2\n",
    "        T_dec = T_CMB_of_z(z_dec)\n",
    "        T_ad  = T_dec * ((1.0 + z_init) / (1.0 + z_dec))**2\n",
    "        # Never below CMB at the start\n",
    "        T_gas = np.maximum(T_ad, T_CMB_of_z(z_init))\n",
    "        # Optional mild compressional boost (use small exponent to avoid bias from particle sampling)\n",
    "        beta = (gamma_ad - 1.0) * 0.3  # e.g. 30% of the full exponent\n",
    "        T_gas *= np.power(np.maximum(rho_phys_part / np.maximum(rho_phys_mean, 1e-99), 1e-3), beta)\n",
    "        T_gas = np.maximum(T_gas, T_floor)\n",
    "        mu = mu_neutral  # neutral before reionization\n",
    "    elif model == \"post_reion_uniform\":\n",
    "        T_gas = np.full(np.count_nonzero(baryon_mask), 1.0e4)\n",
    "        mu = mu_ion\n",
    "    else:\n",
    "        raise ValueError(\"Unknown init model\")\n",
    "\n",
    "    return u_from_T(T_gas, mu=mu, gamma=gamma_ad)\n",
    "\n",
    "\n",
    "def temp_pressure_py(\n",
    "    pos_baryon, vel_baryon, masses_baryon, rho_b_coarse_com_mean,\n",
    "    U_baryon, Lbox_Mpc, Ng, a,\n",
    "    use_TSC = False, n_threads=8, z_reion=8.0, dz_trans=0.5, smooth = 1\n",
    "):\n",
    "    z_now = 1.0/np.maximum(a, 1e-6) - 1.0\n",
    "\n",
    "    # Densities on grid: comoving, then physical, then nH\n",
    "    rho_b_com_grid, dx = grad_phi5.deposit_density(pos_Mpc=pos_baryon, masses=masses_baryon, Lbox_Mpc=Lbox_Mpc, Ng=Ng, use_TSC=use_TSC) # Mpc^-3\n",
    "    if smooth > 1: rho_b_com_grid = uniform_filter(rho_b_com_grid, size=smooth, mode='nearest')\n",
    "    od_b_grid = rho_b_com_grid / rho_b_coarse_com_mean # unitless\n",
    "    rho_b_com_grid *=  Msun_to_g / Mpc_to_cm**3 # g/cm^3\n",
    "    rho_b_phys_grid = rho_b_com_grid / a**3 # g/cm^3\n",
    "    nH_grid       = (X_H * rho_b_phys_grid) / m_p # cm^-3\n",
    "    w_hi = 1.0 / (1.0 + np.exp(-(z_now - z_reion)/dz_trans)) # unitless\n",
    "    w_reion = 1.0 - w_hi\n",
    "\n",
    "    Z_sol = Zsolar_of_nH_z(nH_grid, z_now)\n",
    "    mean_baryon_mass = np.mean(masses_baryon) # Msun\n",
    "\n",
    "    f_sh = shielding_factor_totalH(\n",
    "        nH=nH_grid,\n",
    "        rho_b_phys=rho_b_phys_grid,\n",
    "        dx_phys_cm=dx * a * Mpc_to_cm,\n",
    "        m_particle=mean_baryon_mass * Msun_to_g,\n",
    "        Zsol=Z_sol\n",
    "    )\n",
    "    shield_weight = np.minimum(np.maximum(1.0 - f_sh, 0.0), 1.0)\n",
    "    mu_grid = (\n",
    "        mu_neutral * (w_hi + shield_weight * w_reion) +\n",
    "        mu_ion * ((1.0 - shield_weight) * w_reion)\n",
    "    )\n",
    "\n",
    "    # Deposit u to grid (erg/g), compute T on grid with Î¼(a)\n",
    "    U_grid, _ = grad_phi5.deposit_scalar(pos_Mpc=pos_baryon, masses=masses_baryon, scalar=U_baryon, Lbox_Mpc=Lbox_Mpc, Ng=Ng, use_TSC=use_TSC) # erg/g\n",
    "    if smooth > 1: U_grid = uniform_filter(U_grid, size=smooth, mode='nearest')\n",
    "    T_grid = T_from_u(U_grid, mu_grid) # K\n",
    "\n",
    "    # Pressure term, including artificial viscosity\n",
    "    vx, vy, vz = grad_phi5.deposit_vector(pos_Mpc=pos_baryon, masses=masses_baryon, vec=vel_baryon, Lbox_Mpc=Lbox_Mpc, Ng=Ng, use_TSC=use_TSC) # Mpc/Myr\n",
    "    vx *= Mpc_to_cm / Myr_to_s; vy *= Mpc_to_cm / Myr_to_s; vz *= Mpc_to_cm / Myr_to_s # cm/s\n",
    "    P_phys_grid = (gamma_ad - 1.0) * rho_b_phys_grid * U_grid # erg/cm^3\n",
    "    q_visc, div_v_s, S_min = grad_phi5.artificial_viscosity_q_cgs( # erg/cm^3, 1/s, unitless\n",
    "        rho_b_phys_grid,\n",
    "        U_grid,\n",
    "        vx,\n",
    "        vy,\n",
    "        vz,\n",
    "        dx*Mpc_to_cm,\n",
    "        a,\n",
    "        C2=0.5,\n",
    "        C1=0.0,\n",
    "        Ctheta = 5.0\n",
    "    )\n",
    "    q_visc = np.where(div_v_s < 0.0, q_visc, 0.0)\n",
    "    P_phys_grid += q_visc  # use effective pressure everywhere, erg/cm^3\n",
    "\n",
    "    # Gather updated u back to particles; also return particle T and P for convenience\n",
    "    T_new = grad_phi5.gather_scalar(grid=T_grid, pos_Mpc=pos_baryon, Lbox_Mpc=Lbox_Mpc, dx=dx, use_TSC=use_TSC, n_threads=n_threads) # K\n",
    "    P_new = grad_phi5.gather_scalar(grid=P_phys_grid, pos_Mpc=pos_baryon, Lbox_Mpc=Lbox_Mpc, dx=dx, use_TSC=use_TSC, n_threads=n_threads)\n",
    "\n",
    "    od_bins = [0.0, 1.0, 10.0, 100.0, 1000.0, np.inf] # Overdensity bins: [0â€“1), [1â€“10), [10â€“100), [100â€“1000), [1000+)\n",
    "    temp_by_b_od = binned_means(T_grid.ravel(), od_bins, od_b_grid.ravel() ) # Compute the mean temperatures in each overdensity bin\n",
    "\n",
    "    return T_new, P_new, temp_by_b_od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e16df4",
   "metadata": {
    "cellView": "form",
    "id": "84e16df4"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Gravity mesh refinement\n",
    "from numpy.fft import fftn, ifftn\n",
    "from scipy.fftpack import dst, idst   # dst/type=1 diagonalizes Dirichlet Laplacian\n",
    "import math\n",
    "\n",
    "offset = 0.5\n",
    "\n",
    "@njit\n",
    "def laplace(phi, dx):\n",
    "    return (phi[2:  ,1:-1,1:-1] - 2.0*phi[1:-1,1:-1,1:-1] + phi[0:-2,1:-1,1:-1]) / dx**2 + (phi[1:-1,2:  ,1:-1] - 2.0*phi[1:-1,1:-1,1:-1] + phi[1:-1,0:-2,1:-1]) / dx**2 + (phi[1:-1,1:-1,2:  ] - 2.0*phi[1:-1,1:-1,1:-1] + phi[1:-1,1:-1,0:-2]) / dx**2\n",
    "\n",
    "# --- Solve Poisson on fine grid using Discrete Sine Transform\n",
    "def refine_subgrid(phi_fine, rho_fine_com_interior, rho_bar, Nf, dx_fine, a, G, eps_eig=1e-15):\n",
    "    # Safe wrapper around DST-based fine-grid Poisson solve.\n",
    "    # - phi_fine: full array including ghost cells (so laplace(phi_fine,dx_fine) returns shape (Nf,Nf,Nf))\n",
    "    # - rho_fine_com_interior: shape (Nf,Nf,Nf) (rho per cell)\n",
    "    # - rho_bar: mean density of entire grid (not just the fine box). Usually matches cosmic mean\n",
    "    # - Nf: interior size per axis\n",
    "    # - dx_fine: fine grid spacing (scalar > 0)\n",
    "    # - G: gravitational constant in code units\n",
    "    # - eps_eig: tiny threshold to detect tiny eigenvalues\n",
    "    # Returns psi_interior (shape (Nf,Nf,Nf)) solving Î”Ïˆ = rhs with Ïˆ=0 on boundary (you must add phi back)\n",
    "\n",
    "    # basic checks\n",
    "    if dx_fine <= 0.0: raise ValueError(\"dx_fine must be positive\")\n",
    "    if not isinstance(Nf, int) or Nf <= 0: raise ValueError(\"Nf must be a positive integer\")\n",
    "    if rho_fine_com_interior.shape != (Nf, Nf, Nf): raise ValueError(f\"rho_fine_com_interior shape {rho_fine_com_interior.shape} does not match (Nf,Nf,Nf)=({Nf},{Nf},{Nf})\")\n",
    "    # compute Lap(P)\n",
    "    lapP_full = laplace(phi_fine, dx_fine)    # MUST return (Nf,Nf,Nf) interior\n",
    "\n",
    "    if lapP_full.shape != (Nf, Nf, Nf): raise ValueError(\"laplace(...) did not return expected interior shape (Nf,Nf,Nf)\")\n",
    "    # build rhs and check finiteness\n",
    "    rhs = 4.0 * math.pi * G * (rho_fine_com_interior - rho_bar)/a - lapP_full\n",
    "    if not np.isfinite(rhs).all(): raise ValueError(\"rhs contains NaN or Inf\")\n",
    "\n",
    "    # forward DST-I along axes (scipy.fftpack.dst type=1). Ensure contiguous float64 arrays for speed\n",
    "    rhs = np.asarray(rhs, dtype=np.float64, order='C')\n",
    "    fhat = dst(dst(dst(rhs, type=1, axis=0), type=1, axis=1), type=1, axis=2)\n",
    "\n",
    "    # eigenvalues for Dirichlet Laplacian (k=1..Nf)\n",
    "    k = np.arange(1, Nf + 1)\n",
    "    lam1d = 2.0 * (np.cos(np.pi * k / (Nf + 1.0)) - 1.0) / (dx_fine**2)\n",
    "    # lam1d should be strictly negative; form lam3d by broadcasting\n",
    "    lam3d = lam1d[:, None, None] + lam1d[None, :, None] + lam1d[None, None, :]\n",
    "\n",
    "    # safety: check no tiny eigenvalues (shouldn't happen for k=1..Nf)\n",
    "    lam_min = np.abs(lam3d).min()\n",
    "    if lam_min < eps_eig: raise RuntimeError(f\"Very small Laplacian eigenvalue detected (min abs {lam_min:.3e}) - check dx_fine/Nf\")\n",
    "\n",
    "    # solve in spectral space\n",
    "    psihat = fhat / lam3d   # safe because lam3d != 0\n",
    "\n",
    "    # inverse triple DST-I\n",
    "    psi = idst(idst(idst(psihat, type=1, axis=2), type=1, axis=1), type=1, axis=0)\n",
    "\n",
    "    # normalization factor that matches scipy.fftpack.dst/idst (un-normalized DST-I)\n",
    "    norm = (2.0 * (Nf + 1.0))**3\n",
    "    return psi / norm   # shape (Nf,Nf,Nf)\n",
    "\n",
    "def create_subgrid(cube_center, cube_size, r, Lc, Nc, pos_all, baryon_mask, phi_coarse, margin=3.5, use_TSC=False):\n",
    "    dx = Lc/Nc\n",
    "\n",
    "    # define refined grid aligned to coarse cells (choose integer cell indices)\n",
    "    # choose coarse indices that define cube: find range of coarse cells covering cube\n",
    "    i_min = int(((cube_center[0]-cube_size/2.0) / Lc) * Nc+1)\n",
    "    j_min = int(((cube_center[1]-cube_size/2.0) / Lc) * Nc+1)\n",
    "    k_min = int(((cube_center[2]-cube_size/2.0) / Lc) * Nc+1)\n",
    "    n_cells = int((cube_size / Lc) * Nc)  # number of coarse cells per side\n",
    "\n",
    "    # Refine grid\n",
    "    Nf = n_cells * r\n",
    "    box_min_fine = np.array([i_min*dx, j_min*dx, k_min*dx]) # fine box min/max in physical coords\n",
    "    box_max_fine = box_min_fine + n_cells*dx\n",
    "    dx_fine = dx / r\n",
    "    L_fine = Nf * dx_fine\n",
    "\n",
    "    # Mask particles within fine box and deposit to fine rho grid\n",
    "    mask_inside = np.all((pos_all >= box_min_fine) & (pos_all < box_max_fine), axis=1)\n",
    "    mask_interior = np.all((pos_all >= box_min_fine + margin*dx_fine) & (pos_all < box_max_fine - margin*dx_fine), axis=1)\n",
    "\n",
    "    # Mask particles within fine box and deposit to fine rho grid\n",
    "    pos_b = pos_all[baryon_mask]\n",
    "    mask_b_inside = np.all((pos_b >= box_min_fine) & (pos_b < box_max_fine), axis=1)\n",
    "    mask_b_interior = np.all((pos_b >= box_min_fine + margin*dx_fine) & (pos_b < box_max_fine - margin*dx_fine), axis=1)\n",
    "\n",
    "    if mask_inside.sum() == 0:\n",
    "        print(\"No high-res particles found inside cube! adjust cube.\")\n",
    "        return\n",
    "\n",
    "    # --- Interpolate coarse phi onto fine phi (incl ghost) as initial guess ---\n",
    "    # build coordinates of fine interior cell centers (shape Nf)\n",
    "    xs = (np.arange(-1, Nf+1) + offset) * dx_fine + box_min_fine[0]\n",
    "    ys = (np.arange(-1, Nf+1) + offset) * dx_fine + box_min_fine[1]\n",
    "    zs = (np.arange(-1, Nf+1) + offset) * dx_fine + box_min_fine[2]\n",
    "\n",
    "    # create flattened list of points (M = Nf^3, shape (M,3))\n",
    "    X, Y, Z = np.meshgrid(xs, ys, zs, indexing='ij')\n",
    "    pts = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "\n",
    "    # evaluate coarse phi at these fine points using trilinear_interpolate helper\n",
    "    vals = grad_phi5.gather_scalar(grid=phi_coarse, pos_Mpc=pts, Lbox_Mpc=Lc, dx=dx, use_TSC=use_TSC, n_threads=n_threads)\n",
    "    phi_fine_est = vals.reshape((Nf+2, Nf+2, Nf+2)) # Create phi_fine (reshape to grid)\n",
    "\n",
    "    return box_min_fine, box_max_fine, L_fine, dx_fine, Nf, phi_fine_est, mask_inside, mask_interior, mask_b_inside, mask_b_interior\n",
    "\n",
    "def print_subgrid_parameters(cube_size, r, Lc, Nc, margin, file):\n",
    "    if cube_size is None or r is None: return\n",
    "\n",
    "    dx = Lc/Nc\n",
    "    n_cells = int((cube_size / Lc) * Nc)  # number of coarse cells per side\n",
    "    Nf = n_cells * r\n",
    "    dx_fine = dx / r\n",
    "    L_fine = Nf * dx_fine\n",
    "    print(f\"Fine mesh: dx_fine={dx_fine:.3f} Mpc, L_fine={L_fine:.1f} Mpc, Nc_fine={n_cells}, Nf_fine={Nf}, Nf_interior={Nf-2*int(margin)}\", file=file)\n",
    "\n",
    "def create_rho_fine(cube_center, cube_size, r, Lc, Nc, pos_all, masses_all, use_TSC):\n",
    "    if cube_size is None or cube_center is None or r is None: return None\n",
    "\n",
    "    # define refined grid aligned to coarse cells (choose integer cell indices)\n",
    "    i_min = int(((cube_center[0]-cube_size/2.0) / Lc) * Nc+1)\n",
    "    j_min = int(((cube_center[1]-cube_size/2.0) / Lc) * Nc+1)\n",
    "    k_min = int(((cube_center[2]-cube_size/2.0) / Lc) * Nc+1)\n",
    "    n_cells = int((cube_size / Lc) * Nc)  # number of coarse cells per side\n",
    "\n",
    "    # Refine grid\n",
    "    dx = Lc/Nc\n",
    "    Nf = n_cells * r\n",
    "    box_min_fine = np.array([i_min*dx, j_min*dx, k_min*dx]) # fine box min/max in physical coords\n",
    "    box_max_fine = box_min_fine + n_cells*dx\n",
    "    dx_fine = dx / r\n",
    "    L_fine = Nf * dx_fine\n",
    "\n",
    "    mask_inside = np.all((pos_all >= box_min_fine) & (pos_all < box_max_fine), axis=1)\n",
    "    rho_fine_com_interior, _ = grad_phi5.deposit_density(\n",
    "        pos_Mpc = pos_all[mask_inside] - box_min_fine, # moved to origin\n",
    "        masses = masses_all[mask_inside],\n",
    "        Lbox_Mpc = L_fine,\n",
    "        Ng = Nf,\n",
    "        use_TSC = use_TSC\n",
    "    )\n",
    "    return rho_fine_com_interior # Msun/Mpc^3\n",
    "\n",
    "def refine_potential(x_inside_rel, phi_fine_est, dx_fine, Nf, masses_inside, rho_coarse_com_mean, a, G, use_TSC, n_threads):\n",
    "    rho_fine_com_interior, _ = grad_phi5.deposit_density(\n",
    "        pos_Mpc = x_inside_rel, # new positions, moved to origin\n",
    "        masses = masses_inside,\n",
    "        Lbox_Mpc = dx_fine*Nf,\n",
    "        Ng = Nf,\n",
    "        use_TSC = use_TSC\n",
    "    )\n",
    "    phi_local = phi_fine_est.copy()\n",
    "    phi_local[1:-1,1:-1,1:-1] += grad_phi5.refine_subgrid(\n",
    "        phi_fine=phi_local,\n",
    "        rho_fine_com_interior=rho_fine_com_interior,\n",
    "        rho_bar=rho_coarse_com_mean,\n",
    "        Nf=Nf,\n",
    "        dx_fine=dx_fine,\n",
    "        a=a,\n",
    "        G=G,\n",
    "        n_threads=n_threads\n",
    "    )\n",
    "    ax, ay, az = grad_phi5.gradient_central(grid=phi_local, dx=dx_fine)\n",
    "    acc_inside = grad_phi5.gather_vector(ax=-ax[1:-1,1:-1,1:-1], ay=-ay[1:-1,1:-1,1:-1], az=-az[1:-1,1:-1,1:-1], pos_Mpc=x_inside_rel, Ngrid=Nf, Lbox_Mpc=Nf*dx_fine, use_TSC=use_TSC, n_threads=n_threads)\n",
    "    return acc_inside, np.max(rho_fine_com_interior)/rho_coarse_com_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca69467",
   "metadata": {
    "cellView": "form",
    "id": "7ca69467"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Combined step (leapfrog gravity and thermo)\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def combined_step_parallel_py(x, u, g, gP_b, U_b, baryon_mask, masses, total_mass, L, Ng, dt, a, G, eng, use_TSC, n_threads, f_dyn=0.2):\n",
    "    global cube_fine, center_fine, refinement, od_threshold, f_smooth, subcycles, margin\n",
    "\n",
    "    H_n   = H0_cos * E(a) # at a^n\n",
    "    a_half = a + 0.5*dt * a * H_n # predictor for mid-time scale factor\n",
    "    H_half = H0_cos * E(a_half)\n",
    "    u_half = u + 0.5 * dt * (g - 2 * H_half * u)\n",
    "    u_half[baryon_mask] += 0.5 * dt * gP_b\n",
    "    x_new = (x + dt * u_half) % L\n",
    "    a_new = a + dt * a * H_half\n",
    "    rho_b_coarse_com_mean = Î©_b/Î©_m*total_mass/L**3\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        # Run gravity solve and thermo update concurrently (both release the GIL).\n",
    "        future_eng = executor.submit(\n",
    "            eng.step,\n",
    "            pos=x_new,\n",
    "            masses=masses,\n",
    "            total_mass=total_mass,\n",
    "            a=a_new,\n",
    "            G=G\n",
    "        )\n",
    "        future_cooling = executor.submit(\n",
    "            cooling_heating_step_baryons_py, #grad_phi5.cooling_heating_step\n",
    "            pos_baryon=x_new[baryon_mask],\n",
    "            vel_baryon=u_half[baryon_mask],\n",
    "            masses_baryon=masses[baryon_mask],\n",
    "            rho_b_coarse_com_mean=rho_b_coarse_com_mean,\n",
    "            U_baryon=U_b,\n",
    "            Lbox_Mpc=L,\n",
    "            Ng=Ng,\n",
    "            dt_Myr=dt,\n",
    "            a=a_new,\n",
    "            use_TSC=use_TSC,\n",
    "            n_threads=n_threads,\n",
    "            smooth=0 # coarse grid, no smoothing\n",
    "        )\n",
    "\n",
    "        g_new, phi_coarse, PE, diagnosis2 = future_eng.result()\n",
    "        U_b_new, T_b_new, gP_b_new, P_b_new, diagnosis1, epochs, dt_target_new, max_b_od, _, temp_by_b_od, S_max = future_cooling.result()\n",
    "\n",
    "    u_new = u_half + 0.5 * dt * (g_new - 2 * H_half * u_half)\n",
    "    u_new[baryon_mask] += 0.5 * dt * gP_b_new\n",
    "\n",
    "    max_tot_od = diagnosis2.get('max_tot_od', 0.0)\n",
    "    dt_dyn = diagnosis2.get('dt_dyn', 1e100) # Extract dt_dyn from gravity step\n",
    "    dt_target_new = min(dt_target_new, dt_dyn) # determine new dt_target\n",
    "\n",
    "    cube_fine_active = cube_fine if max_tot_od > od_threshold else None # Mpc\n",
    "    if cube_fine_active is not None and center_fine is not None and refinement is not None and subcycles > 0:\n",
    "        rho_coarse_com_mean = total_mass/L**3 # Msun/Mpc^3\n",
    "\n",
    "        box_min_fine, box_max_fine, L_fine, dx_fine, Nf, phi_fine_est, mask_inside, mask_interior, mask_b_inside, mask_b_interior = create_subgrid( # create the subgrid\n",
    "            cube_center = center_fine,\n",
    "            cube_size = cube_fine_active,\n",
    "            r = refinement,\n",
    "            Lc = L,\n",
    "            Nc = Ng,\n",
    "            pos_all = x, # all bodies, before drift\n",
    "            baryon_mask = baryon_mask,\n",
    "            phi_coarse = phi_coarse,\n",
    "            margin = margin,\n",
    "            use_TSC = use_TSC\n",
    "        )\n",
    "\n",
    "        x_inside = x[mask_inside].copy() # pos all bodies inside fine cube\n",
    "        masses_inside = masses[mask_inside].copy() # mass all bodies inside fine cube\n",
    "        u_inside = u[mask_inside].copy() # vel all bodies inside fine cube\n",
    "        g_inside = g[mask_inside].copy() # acc all bodies inside fine cube\n",
    "        U_b_inside = U_b[mask_b_inside].copy() # Energy baryons inside fine cube\n",
    "        gP_b_inside = gP_b[mask_b_inside].copy() # pressure acceleration baryons inside fine cube\n",
    "        a_inside = a # initial scale factor for subcycling\n",
    "        dt_inside = dt / subcycles # time step for subcycling\n",
    "        baryon_mask_inside = baryon_mask[mask_inside]  # apply to baryon\n",
    "        Zsol_max_fine = 0\n",
    "        nH_max_fine = 0\n",
    "\n",
    "        # LOOP SUBCYCLES\n",
    "        for i in range(subcycles):\n",
    "            H_inside   = H0_cos * E(a_inside) # at a^n\n",
    "            a_inside_half = a_inside + 0.5*dt_inside * a_inside * H_inside # predictor for mid-time scale factor\n",
    "            H_inside_half = H0_cos * E(a_inside_half)\n",
    "            u_inside_half = u_inside + 0.5 * dt_inside * (g_inside - 2 * H_inside_half * u_inside)\n",
    "            u_inside_half[baryon_mask_inside] += 0.5 * dt_inside * gP_b_inside\n",
    "            x_inside_new = x_inside + dt_inside * u_inside_half\n",
    "            a_inside_new = a_inside + dt_inside * a_inside * H_inside_half\n",
    "\n",
    "            with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "                # Parallelize fine-grid gravity solve with baryon cooling at this sub-step.\n",
    "                future_phi = executor.submit(\n",
    "                    refine_potential, #grad_phi5.refine_potential\n",
    "                    x_inside_rel = x_inside_new - box_min_fine, # moved to origin\n",
    "                    phi_fine_est = phi_fine_est,\n",
    "                    dx_fine = dx_fine,\n",
    "                    Nf = Nf,\n",
    "                    masses_inside = masses_inside,\n",
    "                    rho_coarse_com_mean = rho_coarse_com_mean,\n",
    "                    a = a_inside_new,\n",
    "                    G = G,\n",
    "                    use_TSC = use_TSC,\n",
    "                    n_threads = n_threads\n",
    "                )\n",
    "                future_cooling = executor.submit(\n",
    "                    cooling_heating_step_baryons_py, #grad_phi5.cooling_heating_step\n",
    "                    pos_baryon=x_inside_new[baryon_mask_inside] - box_min_fine,\n",
    "                    vel_baryon=u_inside_half[baryon_mask_inside],\n",
    "                    masses_baryon=masses_inside[baryon_mask_inside],\n",
    "                    rho_b_coarse_com_mean=rho_b_coarse_com_mean,\n",
    "                    U_baryon=U_b_inside,\n",
    "                    Lbox_Mpc=L_fine,\n",
    "                    Ng=Nf,\n",
    "                    dt_Myr=dt_inside,\n",
    "                    a=a_inside_new,\n",
    "                    use_TSC=use_TSC,\n",
    "                    n_threads=n_threads,\n",
    "                    smooth=f_smooth # smoothing parameter for fine grid\n",
    "                )\n",
    "\n",
    "                acc_in, max_tot_od_fine = future_phi.result()\n",
    "                cooling_results = future_cooling.result()\n",
    "\n",
    "            g_inside_new = acc_in / a_inside_new**2\n",
    "            U_b_inside, T_b_inside, gP_b_inside_new, P_b_inside, diagnosis3, _, dt_target_inside_new, max_b_od_fine, _, temp_by_b_od_fine, S_max_fine = cooling_results\n",
    "            u_inside_new = u_inside_half + 0.5 * dt_inside * (g_inside_new - 2 * H_inside_half * u_inside_half)\n",
    "            u_inside_new[baryon_mask_inside] += 0.5 * dt_inside * gP_b_inside_new\n",
    "            x_inside = x_inside_new\n",
    "            u_inside = u_inside_new\n",
    "            g_inside = g_inside_new\n",
    "            a_inside = a_inside_new\n",
    "            gP_b_inside = gP_b_inside_new\n",
    "            Zsol_max_fine = max(Zsol_max_fine, diagnosis3.get('Zsol_max',0))\n",
    "            nH_max_fine = max(nH_max_fine, diagnosis3.get('nH_max',0))\n",
    "\n",
    "        # END LOOP\n",
    "\n",
    "        dt_dyn_fine = f_dyn / np.sqrt(max(4.0*np.pi*G*max_tot_od_fine*total_mass/(a*L)**3, 1e-40))\n",
    "        dt_target_fine = min(dt_dyn_fine, dt_target_inside_new)\n",
    "        diagnosis2['max_tot_od_fine'] = max_tot_od_fine\n",
    "        diagnosis2['dt_dyn_fine'] = dt_dyn_fine\n",
    "        diagnosis1['max_b_od_fine'] = max_b_od_fine\n",
    "        diagnosis1['Zsol_max_fine'] = Zsol_max_fine\n",
    "        diagnosis1['nH_max_fine'] = nH_max_fine\n",
    "        diagnosis1['dt_cfl_fine'] = dt_target_inside_new\n",
    "        diagnosis1['dt_target_fine'] = dt_target_fine\n",
    "        diagnosis1['infall'] = mask_inside.sum()\n",
    "        diagnosis1['infall_b'] = mask_b_inside.sum()\n",
    "\n",
    "        inside_mask_interior = mask_interior[mask_inside]\n",
    "        inside_b_mask_interior_b = mask_b_interior[mask_b_inside]\n",
    "        u_new[mask_inside & mask_interior] = u_inside_new[inside_mask_interior]\n",
    "        g_new[mask_inside & mask_interior] = g_inside_new[inside_mask_interior]\n",
    "        x_new[mask_inside & mask_interior] = x_inside_new[inside_mask_interior]\n",
    "        U_b_new[mask_b_inside & mask_b_interior] = U_b_inside[inside_b_mask_interior_b] # This allocates only those in mas_interior\n",
    "        T_b_new[mask_b_inside & mask_b_interior] = T_b_inside[inside_b_mask_interior_b]\n",
    "        P_b_new[mask_b_inside & mask_b_interior] = P_b_inside[inside_b_mask_interior_b]\n",
    "        gP_b_new[mask_b_inside & mask_b_interior] = gP_b_inside[inside_b_mask_interior_b]\n",
    "\n",
    "    return x_new, u_new, g_new, a_new, PE, U_b_new, T_b_new, gP_b_new, P_b_new, diagnosis1 | diagnosis2, epochs, dt_target_new, max_b_od, max_tot_od, temp_by_b_od, S_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebfb1e",
   "metadata": {
    "cellView": "form",
    "id": "78ebfb1e"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Simulation loop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import io, sys, subprocess, cProfile\n",
    "import time as tm\n",
    "from datetime import datetime\n",
    "\n",
    "# Define a Tee class to write to multiple streams\n",
    "class Tee:\n",
    "    def __init__(self, *streams):\n",
    "        self.streams = streams\n",
    "    def write(self, text):\n",
    "        for s in self.streams:\n",
    "            s.write(text)\n",
    "            s.flush()\n",
    "    def flush(self):\n",
    "        for s in self.streams:\n",
    "            s.flush()\n",
    "\n",
    "\n",
    "@njit\n",
    "def total_angular_momentum(x, u, masses, a): # x, u: shape (N, 3), masses: shape (N,)\n",
    "    return np.sum(np.cross(x, u) * masses[:, np.newaxis], axis=0) * a**2\n",
    "@njit\n",
    "def measure_flattening(positions):\n",
    "    a = np.std(positions[:,0])\n",
    "    b = np.std(positions[:,1])\n",
    "    c = np.std(positions[:,2])\n",
    "    return a,b,c\n",
    "\n",
    "# Run simulation\n",
    "positions_hist = []\n",
    "scale_hist = []\n",
    "time_hist = []\n",
    "temp_hist = []\n",
    "pressure_hist = []\n",
    "KE_hist = []\n",
    "PE_hist = []\n",
    "TE_hist = []\n",
    "virial_hist = []\n",
    "flat_a_hist = []\n",
    "flat_b_hist = []\n",
    "flat_c_hist = []\n",
    "\n",
    "body_velocities_cos = body_velocities / Mpc_km * Myr_s # turn all velocities into pc/yr\n",
    "center = np.mean(body_positions, axis=0) # center of mass of system\n",
    "body_positions %= L # wrap all particles into the box\n",
    "res = max(steps // 100, 1) # resolution for animation (not for simulation!)\n",
    "scale = a_init\n",
    "time = 0 # Myr\n",
    "dt_target = epsilon / a_init # Myr\n",
    "H_a = H0_cos * E(scale) #1/Myr\n",
    "vel_max = 0.0 # for identification of max speed\n",
    "\n",
    "eng = grad_phi5.PMEngine(Ngrid=Ng, box_size=L, use_TSC=use_TSC, n_threads=n_threads)\n",
    "acc, _, PE, _ = eng.step(pos=body_positions, masses=masses, total_mass=masses.sum(), a=scale, G=G)\n",
    "acc -= 2 * H_a * body_velocities_cos # Slowing required in comoving coordinates\n",
    "L_ang = total_angular_momentum(body_positions, body_velocities_cos, masses, scale)\n",
    "U_b = init_internal_energy(body_positions, baryon_set, masses=masses, Lbox_Mpc=L, Ng=Ng, a_init=a_init, model=\"pre_reion_adiabatic\", T_floor=50.0, n_threads=n_threads)  # neutral gas: muâ‰ˆ1.22\n",
    "grad_phi5.set_cosmology_params(H0_cos=H0_cos, Omega_m=Î©_m, Omega_r=Î©_r, Omega_k=Î©_k, Omega_lambda=Î©_Î›, Omega_b=Î©_b)\n",
    "grad_phi5.set_n_jeans(n = n_jeans)\n",
    "grad_phi5.set_subgrid_config(\n",
    "    cube_fine = cube_fine,\n",
    "    center_fine = center_fine,\n",
    "    refinement = refinement,\n",
    "    od_threshold = od_threshold,\n",
    "    subcycles = subcycles,\n",
    "    f_smooth = f_smooth,\n",
    "    margin = margin\n",
    ")\n",
    "\n",
    "rho_fine_final = None\n",
    "acc_P = np.zeros_like(body_velocities_cos[baryon_set])\n",
    "\n",
    "sim_log = io.StringIO()\n",
    "tee = Tee(sys.stdout, sim_log)\n",
    "print(datetime.now(), file=tee)\n",
    "print(f\"N_bodies: {N_bodies:,}, grid cells: {Ng**3:,}, max particle mass: {masses.max(): .3e} m_sun\", file=tee)\n",
    "print_subgrid_parameters(cube_size=cube_fine, r=refinement, Lc=L, Nc=Ng, margin=margin, file=tee)\n",
    "print(f\"Initial scale factor a: {a_init:.4f}\", file=tee)\n",
    "print(f\"Total system mass: {M_total:.3e} m_sun\", file=tee)\n",
    "print(f\"Initial angular momentum: {np.round(L_ang)} MpcÂ²â‹…m_sun/Myr\", file=tee)\n",
    "\n",
    "def simulation_loop(): # Simulation\n",
    "    global scale, U_b, body_positions, body_velocities_cos, acc, acc_P, vel_max, time, dt_target, T, P, subcycles, rho_fine_final\n",
    "\n",
    "    animation_dt = t_universe / 100\n",
    "    animation_t = 0.0\n",
    "    step = 0\n",
    "    combined_step_fct = combined_step_parallel_py if use_Python else grad_phi5.combined_step\n",
    "    while scale < a_final:\n",
    "        H_a = H0_cos * E(scale) #1/Myr\n",
    "        dt = np.clip(dt_target, epsilon_fine / H_a, epsilon / H_a)  # Myr\n",
    "        time += dt\n",
    "\n",
    "        (body_positions, body_velocities_cos, acc, scale, PE,\n",
    "        U_b, T, acc_P, P, diag, epochs, dt_target_new,\n",
    "        max_b_od, max_tot_od, temp_by_b_od, S_max) = combined_step_fct(\n",
    "            x=body_positions,\n",
    "            u=body_velocities_cos,\n",
    "            g=acc,\n",
    "            gP_b=acc_P,\n",
    "            U_b=U_b,\n",
    "            baryon_mask=baryon_set,\n",
    "            masses=masses,\n",
    "            total_mass=masses.sum(),\n",
    "            L=L,\n",
    "            Ng=Ng,\n",
    "            dt=dt,\n",
    "            a=scale,\n",
    "            G=G,\n",
    "            eng=eng,\n",
    "            use_TSC=use_TSC,\n",
    "            n_threads=n_threads\n",
    "        )\n",
    "\n",
    "        # Unpack diagnosis\n",
    "        max_tot_od = diag.get('max_tot_od', max_tot_od)\n",
    "        max_tot_od_fine = diag.get('max_tot_od_fine', None)\n",
    "        max_b_od_fine = diag.get('max_b_od_fine', None)\n",
    "        cooling_fine_ms = diag.get('cooling_fine_ms', np.nan)\n",
    "        gravity_fine_ms = diag.get('gravity_fine_ms', np.nan)\n",
    "        overlap_fine_ms = diag.get('overlap_fine_ms', np.nan)\n",
    "        cooling_ms = diag.get('cooling_ms', np.nan)\n",
    "        gravity_ms = diag.get('gravity_ms', np.nan)\n",
    "        overlap_ms = diag.get('overlap_ms', np.nan)\n",
    "\n",
    "        if step % 100 == 0 or scale >= a_final:\n",
    "            print(file=tee)\n",
    "            formatted_list = '[' + ', '.join(f\"{t:,.0f}\" for t in temp_by_b_od) + ']'\n",
    "            print(f\"z={1/scale-1:.1f}, step={step:,}, dt/dt_target={dt/dt_target:.3f}, T min/max={np.min(T):,.0f}/{np.max(T):,.0f} K, S_max={S_max:.3f}, max b/tot od={max_b_od:.1f}/{max_tot_od:.1f}\", end='', file=tee)\n",
    "            if max_tot_od_fine is not None and max_b_od_fine is not None:\n",
    "                print(f\", MR: max b/tot od={max_b_od_fine:.1f}/{max_tot_od_fine:.1f}, dt/dt_dyn/cfl={dt/subcycles/diag.get('dt_dyn_fine', np.nan):.3f}/{dt/subcycles/diag.get('dt_cfl_fine', np.nan):.3f}, max nH/Zsol={diag.get('nH_max_fine',np.nan):.3f}/{diag.get('Zsol_max_fine', np.nan):.3f}, infall b/tot={diag.get('infall_b',np.nan):,}/{diag.get('infall',np.nan):,}\", end='', file=tee)\n",
    "            else:\n",
    "                print(f\", no MR\", end='', file=tee)\n",
    "            #print(f\", T_jeans min/mwm/mean/max={diag.get('T_jeans_min', np.nan):.0f}/{diag.get('T_jeans_mwm', np.nan):.0f}/{diag.get('T_jeans_mean', np.nan):.0f}/{diag.get('T_jeans_max', np.nan):.0f}\", end='', file=tee)\n",
    "            #print(f\", f_sh min/mwm/mean/max={diag.get('f_sh_min', np.nan):.3f}/{diag.get('f_sh_mwm', np.nan):.3f}/{diag.get('f_sh_mean', np.nan):.3f}/{diag.get('f_sh_max', np.nan):.3f}\", end='', file=tee)\n",
    "            print(f\", Zsol min/mean/max={diag['Zsol_min']:.3f}/{diag['Zsol_mean']:.3f}/{diag['Zsol_max']:.3f}, temp by od={formatted_list}\", end='', file=tee)\n",
    "            #print(file=tee)\n",
    "            #print(f\"coarse: gravity/thermo/overlap={gravity_ms/1000:.1f}/{cooling_ms/1000:.1f}/{overlap_ms/1000:.1f} s, fine: gravity/thermo/overlap={gravity_fine_ms/1000:.1f}/{cooling_fine_ms/1000:.1f}/{overlap_fine_ms/1000:.1f} s\", end='', file=tee)\n",
    "        if time >= animation_t or scale >= a_final:\n",
    "            animation_t += animation_dt\n",
    "            vel_max = np.fmax(vel_max, grad_phi5.velocity_stat(body_velocities_cos, n_threads) * scale)\n",
    "            KE = 0.5 * scale**2 * np.sum(masses * np.sum(body_velocities_cos**2, axis=1))  # Mâ˜‰â‹…MpcÂ²/MyrÂ²\n",
    "            KE_hist.append(KE.astype(np.float32))\n",
    "            PE_hist.append(PE)\n",
    "            TE_hist.append(np.sum(masses[baryon_set] * U_b) * Myr_to_s**2 / Mpc_to_cm**2) # m_sunâ‹…MpcÂ²/MyrÂ²\n",
    "            virial_hist.append(2*KE.astype(np.float32)/np.abs(PE))\n",
    "            positions_hist.append((body_positions[grid_downsampled]-center).astype(np.float32))\n",
    "            scale_hist.append(scale)\n",
    "            time_hist.append(time)\n",
    "            aa, bb, cc = measure_flattening(body_positions.astype(np.float32))\n",
    "            flat_a_hist.append(aa * scale)\n",
    "            flat_b_hist.append(bb * scale)\n",
    "            flat_c_hist.append(cc * scale)\n",
    "            tmp = np.zeros_like(body_positions[:,0])\n",
    "            tmp[baryon_set] = T\n",
    "            temp_hist.append(tmp[grid_downsampled].astype(np.float32))\n",
    "            tmp = np.zeros_like(body_positions[:,0])\n",
    "            tmp[baryon_set] = P\n",
    "            pressure_hist.append(tmp[grid_downsampled].astype(np.float32))\n",
    "        if step % res == 0:\n",
    "            print('.', end='', flush=True, file=tee)\n",
    "        step += 1\n",
    "        dt_target = dt_target_new\n",
    "\n",
    "    rho_fine_final = create_rho_fine(cube_center=center_fine, cube_size=cube_fine, r=refinement, Lc=L, Nc=Ng, pos_all=body_positions, masses_all=masses, use_TSC=use_TSC)\n",
    "\n",
    "    print(file=tee)\n",
    "    return\n",
    "\n",
    "start_time = tm.time()\n",
    "simulation_loop()\n",
    "end_time = tm.time()\n",
    "elapsed = end_time - start_time\n",
    "\n",
    "L_ang = total_angular_momentum(body_positions, body_velocities_cos, masses, scale)\n",
    "print(file=tee)\n",
    "print(f\"Final angular momentum: {np.round(L_ang)} MpcÂ²â‹…m_sun/Myr\", file=tee)\n",
    "print(f\"Final scale factor a: {scale:.4f}\", file=tee)\n",
    "print(f\"Final scale factor for animation: {scale_hist[-1]:.4f}\", file=tee)\n",
    "print(f\"Highest v_pec: {vel_max/c_cos:.6f} c\", file=tee)\n",
    "print(f\"Simulation took {elapsed:.1f} seconds.\", file=tee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86580fce",
   "metadata": {
    "id": "86580fce"
   },
   "source": [
    "__Visualize Energy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d269b",
   "metadata": {
    "cellView": "form",
    "id": "852d269b"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def create_html(fig):\n",
    "    # Save the figure to a buffer\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Encode the image as base64\n",
    "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    buf.close()\n",
    "\n",
    "    # Create HTML content\n",
    "    return f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head><title>Matplotlib Figure</title></head>\n",
    "    <body>\n",
    "    <img src=\"data:image/png;base64,{img_base64}\" alt=\"Matplotlib Figure\">\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21671fd4",
   "metadata": {
    "cellView": "form",
    "id": "21671fd4"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))  # 1 row, 2 columns\n",
    "# === LEFT PANEL: Energy + virial with twin y-axis ===\n",
    "ax1 = axes[0]\n",
    "ax1.plot(time_hist, KE_hist, label='Kinetic Energy', color='tab:blue')\n",
    "ax1.plot(time_hist, PE_hist, label='Potential Energy', color='tab:orange')\n",
    "ax1.plot(time_hist, TE_hist, label='Thermal Energy')\n",
    "ax1.plot(time_hist, np.array(KE_hist) + np.array(PE_hist) + np.array(TE_hist), label='Total Energy', color='tab:green')\n",
    "ax1.set_xlabel(\"Time [Myr]\")\n",
    "ax1.set_ylabel(\"Energy [M$_\\\\odot$â‹…MpcÂ²â‹…Myrâ»Â²]\")\n",
    "\n",
    "# Twin axis for virial ratio\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(time_hist, virial_hist, label='Virial ratio', color='tab:red', linestyle='--')\n",
    "ax2.set_ylabel(\"Virial ratio\")\n",
    "\n",
    "# Combine legends\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper right\")\n",
    "\n",
    "ax1.set_title(\"Energy Evolution & Virial Balance\")\n",
    "\n",
    "# === RIGHT PANEL: Flattening ===\n",
    "ax_flat = axes[1]\n",
    "ax_flat.plot(time_hist, flat_a_hist, label='$\\\\sigma_x$')\n",
    "ax_flat.plot(time_hist, flat_b_hist, label='$\\\\sigma_y$')\n",
    "ax_flat.plot(time_hist, flat_c_hist, label='$\\\\sigma_z$')\n",
    "ax_flat.set_xlabel(\"Time [Myr]\")\n",
    "ax_flat.set_ylabel(\"Stdev per axis [Mpc]\")\n",
    "ax_flat.set_title(\"System Expansion Over Time\")\n",
    "ax_flat.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "energy_html = create_html(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf4d7a",
   "metadata": {
    "id": "f9bf4d7a"
   },
   "source": [
    "__End of simulation delta field__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8583fca",
   "metadata": {
    "cellView": "form",
    "id": "f8583fca"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import plotly.io as pio\n",
    "delta_end = grad_phi5.deposit_delta(positions=body_positions, masses=masses, Ngrid=Ng, L=L, use_TSC=use_TSC, n_threads=n_threads)\n",
    "slice_index = (Ng // 2)\n",
    "delta_2D_end = delta_end[:, :, slice_index]\n",
    "body_z = body_positions[:, 2]\n",
    "body_mask = (body_z > slice_index/Ng*L - qg*dx_init/2) & (body_z < slice_index/Ng*L + qg*dx_init/2)\n",
    "\n",
    "print(\"Î´ Field today, from n-body simulation:\")\n",
    "print(f\"np.mean(delta) = {np.mean(delta_end):.4f}\")\n",
    "print(f\"np.max(delta) = {np.max(delta_end):.4f}\")\n",
    "print(f\"np.min(delta) = {np.min(delta_end):.4f}\")\n",
    "print(f\"np.std(delta) = {np.std(delta_end):.4f}\")\n",
    "print(f\"delta.shape = {delta_end.shape}\")\n",
    "print(f\"np.std(delta_2D) = {np.std(delta_2D_end):.4f}\")\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4)) # Plot 2D slice of the field\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "max_log = np.percentile(np.log(delta_2D_end.T+1+1e-10), 99.5)\n",
    "helper = np.clip(np.log(delta_2D_end.T+1+1e-10), -max_log, +max_log)\n",
    "im = plt.imshow(helper, origin='lower', extent=[0, L, 0, L], cmap='Blues')\n",
    "plt.colorbar(im, label='ln(Î´) (today)', fraction = 0.026)\n",
    "plt.title(f\"Î´ Field today (slice {slice_index})\") # Labels and title\n",
    "plt.xlabel(\"x [Mpc]\")\n",
    "plt.ylabel(\"y [Mpc]\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(body_positions[body_mask, 0], body_positions[body_mask, 1], s=1, alpha=0.5)\n",
    "plt.title(f\"Particle Distribution (Slice {slice_index})\")\n",
    "plt.xlabel(\"x [Mpc]\")\n",
    "plt.ylabel(\"y [Mpc]\")\n",
    "plt.xlim(0, L)\n",
    "plt.ylim(0, L)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "deltafield_html = create_html(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde2cfd",
   "metadata": {
    "cellView": "form",
    "id": "3dde2cfd"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# rho_fine_com_interior chart\n",
    "from scipy.ndimage import uniform_filter\n",
    "if rho_fine_final is not None:\n",
    "    smoothing = 1 # 1 leaves the field unchanged\n",
    "    rho_com_mean = masses.sum()/L**3\n",
    "    smooth_rho = uniform_filter(rho_fine_final, size=smoothing, mode='reflect')\n",
    "    smooth_rho[smooth_rho < 0] = 0\n",
    "    print(f\"Fine grid overdensity today, smoothed over {smoothing} cells:\")\n",
    "    print(f\"Mean  = {np.mean(smooth_rho)/rho_com_mean:.1f}\")\n",
    "    print(f\"Max   = {np.max(smooth_rho)/rho_com_mean:.3e}\")\n",
    "    print(f\"Min   = {np.min(smooth_rho)/rho_com_mean:.3e}\")\n",
    "    print(f\"Shape = {smooth_rho.shape}\")\n",
    "\n",
    "    slice_index = int(smooth_rho.shape[0]*0.5)\n",
    "    od_2D_end = smooth_rho[:, :, slice_index]/rho_com_mean\n",
    "    fig = plt.figure(figsize=(5,4)) # Plot 2D slice of the field\n",
    "    max_log = np.percentile(od_2D_end.T, 99.5)\n",
    "    helper = np.clip(od_2D_end.T, 0, +max_log)\n",
    "    im = plt.imshow(helper, origin='lower', extent=[0, cube_fine, 0, cube_fine], cmap='plasma')\n",
    "    plt.colorbar(im, label='fine grid overdensity', fraction = 0.026)\n",
    "    plt.title(f\"Fine grid overdensity today (slice {slice_index})\") # Labels and title\n",
    "    plt.xlabel(\"x [Mpc]\")\n",
    "    plt.ylabel(\"y [Mpc]\")\n",
    "    fine_grid_od_html = create_html(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90348fb8",
   "metadata": {
    "id": "90348fb8"
   },
   "source": [
    "__Baryon Temperature Distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da7891",
   "metadata": {
    "cellView": "form",
    "id": "28da7891"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Baryon Temperature Distribution\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "baryon_pos = body_positions[baryon_set]\n",
    "baryon_masses = masses[baryon_set]\n",
    "body_z = baryon_pos[:, 2]\n",
    "body_mask = (body_z > slice_index/Ng*L - qg*dx_init/2) & (body_z < slice_index/Ng*L + qg*dx_init/2)\n",
    "rho_b_com_grid, _dx = grad_phi5.deposit_density(pos_Mpc=baryon_pos, masses=baryon_masses, Lbox_Mpc=L, Ng=Ng, use_TSC=use_TSC)\n",
    "rho_b_com_grid *= Msun_to_g / Mpc_to_cm**3\n",
    "baryon_rho = grad_phi5.gather_scalar(grid=rho_b_com_grid, pos_Mpc=baryon_pos, Lbox_Mpc=L, dx=_dx, use_TSC=use_TSC, n_threads=n_threads)\n",
    "print(f\"Mean baryon density: {np.mean(rho_b_com_grid):.3e} g/cm3\")\n",
    "print(f\"Mean baryon temp: {np.mean(T):.3e} K\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "sc = plt.scatter(\n",
    "    baryon_pos[body_mask, 0],\n",
    "    baryon_pos[body_mask, 1],\n",
    "    c=T[body_mask],\n",
    "    cmap='plasma',    # Or 'viridis', 'inferno', etc.\n",
    "    s=1,\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.title(f\"Baryon Temperature Distribution (Slice {slice_index})\")\n",
    "plt.xlabel(\"x [Mpc]\")\n",
    "plt.ylabel(\"y [Mpc]\")\n",
    "plt.xlim(0, L)\n",
    "plt.ylim(0, L)\n",
    "plt.gca().set_aspect('equal')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label(\"Temperature [K]\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sc = plt.scatter(\n",
    "    baryon_rho/np.mean(rho_b_com_grid),\n",
    "    T,\n",
    "    c=P,\n",
    "    cmap='plasma',\n",
    "    s=1,\n",
    "    alpha=0.2,\n",
    "    norm=colors.LogNorm(vmin=P.min(), vmax=P.max())\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Overdensity\")\n",
    "plt.ylabel(\"Temp (K)\")\n",
    "plt.title(\"Density / Temperature correlation\")\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "cbar = plt.colorbar(sc) # Add colorbar\n",
    "cbar.set_label(\"log10(Pressure) [erg/cmÂ³]\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "thermo_html = create_html(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3593e72c",
   "metadata": {
    "id": "3593e72c"
   },
   "source": [
    "__Animation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633e3d7",
   "metadata": {
    "cellView": "form",
    "id": "f633e3d7"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "R_scale = L/2\n",
    "phys_scale = True\n",
    "menues = [{\n",
    "    \"type\": \"buttons\",\n",
    "    \"buttons\": [\n",
    "        {\n",
    "            \"label\": \"Play\",\n",
    "            \"method\": \"animate\",\n",
    "            \"args\": [None, {\"frame\": {\"duration\": 50, \"redraw\": True}, \"fromcurrent\": True}]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"XY Plane\",\n",
    "            \"method\":\"relayout\",\n",
    "            \"args\": [{\"scene.camera.eye\": {\"x\": 0, \"y\": 0, \"z\": 2},\n",
    "                    \"scene.camera.up\": {\"x\": 0, \"y\": 1, \"z\": 0},\n",
    "                    \"scene.camera.projection.type\": \"orthographic\",\n",
    "                    \"scene.aspectratio\": {\"x\": 1.8, \"y\": 1.8, \"z\": 1.8}\n",
    "            }]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"XZ Plane\",\n",
    "            \"method\": \"relayout\",\n",
    "            \"args\": [{\"scene.camera.eye\": {\"x\": 0, \"y\": -2, \"z\": 0},\n",
    "                    \"scene.camera.up\": {\"x\": 0, \"y\": 0, \"z\": -1},\n",
    "                    \"scene.camera.projection.type\": \"orthographic\",\n",
    "                    \"scene.aspectratio\": {\"x\": 1.8, \"y\": 1.8, \"z\": 1.8}\n",
    "            }]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"YZ Plane\",\n",
    "            \"method\": \"relayout\",\n",
    "            \"args\": [{\"scene.camera.eye\": {\"x\": 2, \"y\": 0, \"z\": 0},\n",
    "                    \"scene.camera.projection.type\": \"orthographic\",\n",
    "                    \"scene.aspectratio\": {\"x\": 1.8, \"y\": 1.8, \"z\": 1.8}\n",
    "            }]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"3D View\",\n",
    "            \"method\": \"relayout\",\n",
    "            \"args\": [{\"scene.camera.eye\": {\"x\": 1.4, \"y\": -1.8, \"z\": 1.3},\n",
    "                    \"scene.camera.up\": {\"x\": 0, \"y\": 0, \"z\": -1},\n",
    "                    \"scene.camera.projection.type\": \"perspective\",\n",
    "                    \"scene.aspectratio\": {\"x\": 1.2, \"y\": 1.2, \"z\": 1.2}\n",
    "            }]\n",
    "        }\n",
    "    ],\n",
    "}]\n",
    "\n",
    "def create_sphere_mesh(center, radius, color='gray', opacity=0.1, resolution=40):\n",
    "    u = np.linspace(0, 2 * np.pi, resolution)\n",
    "    v = np.linspace(0, np.pi, resolution)\n",
    "    x = center[0] + radius * np.outer(np.cos(u), np.sin(v)).flatten()\n",
    "    y = center[1] + radius * np.outer(np.sin(u), np.sin(v)).flatten()\n",
    "    z = center[2] + radius * np.outer(np.ones_like(u), np.cos(v)).flatten()\n",
    "    i, j = np.meshgrid(np.arange(resolution - 1), np.arange(resolution - 1))\n",
    "    i = i.flatten()\n",
    "    j = j.flatten()\n",
    "    faces = []\n",
    "    for k in range(len(i)):\n",
    "        a = i[k] * resolution + j[k]\n",
    "        b = a + 1\n",
    "        c = a + resolution\n",
    "        d = c + 1\n",
    "        faces.append([a, b, d])\n",
    "        faces.append([a, d, c])\n",
    "    i, j, k = np.array(faces).T\n",
    "    return go.Mesh3d(\n",
    "        x=x.astype(np.float16), y=y.astype(np.float16), z=z.astype(np.float16),\n",
    "        i=i, j=j, k=k,\n",
    "        color=color,\n",
    "        opacity=opacity,\n",
    "        name='Expansion Sphere',\n",
    "        showscale=False\n",
    "    )\n",
    "\n",
    "# Create Plotly animation frames\n",
    "frames = []\n",
    "for i, pos in enumerate(positions_hist):\n",
    "    aa = scale_hist[i] if phys_scale else 1.0\n",
    "    pos = pos.astype(np.float16)\n",
    "    ref_sphere = create_sphere_mesh(np.zeros(3), R_scale * scale_hist[i], color='gray')\n",
    "    frames.append(go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(x=pos[~baryon_set[grid_downsampled], 0]*aa, y=pos[~baryon_set[grid_downsampled], 1]*aa, z=pos[~baryon_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='blue', size=1), name='CDM'),\n",
    "            go.Scatter3d(x=pos[baryon_set[grid_downsampled], 0]*aa, y=pos[baryon_set[grid_downsampled], 1]*aa, z=pos[baryon_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='red', size=1), name='Baryon'),\n",
    "            ref_sphere\n",
    "        ],\n",
    "        name=f'frame{i}',\n",
    "        layout=go.Layout(title_text='N-body Simulation')\n",
    "    ))\n",
    "\n",
    "# Initial frame\n",
    "init_pos = positions_hist[0].astype(np.float16)\n",
    "aa = scale_hist[0] if phys_scale else 1.0\n",
    "ref_sphere = create_sphere_mesh(np.zeros(3), R_scale * scale_hist[0], color='gray')\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(x=init_pos[~baryon_set[grid_downsampled], 0]*aa, y=init_pos[~baryon_set[grid_downsampled], 1]*aa, z=init_pos[~baryon_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='blue', size=1), name='CDM'),\n",
    "        go.Scatter3d(x=init_pos[baryon_set[grid_downsampled], 0]*aa, y=init_pos[baryon_set[grid_downsampled], 1]*aa, z=init_pos[baryon_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='red', size=1), name='Baryon'),\n",
    "        ref_sphere\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        title='N-body Simulation',\n",
    "        width = 1000,\n",
    "        height = 800,\n",
    "        scene=dict(\n",
    "            xaxis=dict(title='x [Mpc]', range=[-R_scale, R_scale]),\n",
    "            yaxis=dict(title='y [Mpc]', range=[-R_scale, R_scale]),\n",
    "            zaxis=dict(title='z [Mpc]', range=[-R_scale, R_scale]),\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.4, y=-1.8, z=1.3),\n",
    "                up=dict(x=0, y=0, z=-1),\n",
    "                projection=dict(type='perspective')\n",
    "            ),\n",
    "            aspectratio=dict(x=1.2, y=1.2, z=1.2)\n",
    "        ),\n",
    "        updatemenus=menues,\n",
    "        sliders=[{\n",
    "                    \"steps\": [\n",
    "                        {\"args\": [[f\"frame{i}\"], {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}],\n",
    "                         \"label\": f\"{time_hist[i]:,.0f} Myr\",\n",
    "                         \"method\": \"animate\"\n",
    "                         } for i in range(0,len(positions_hist),1)\n",
    "                    ],\n",
    "                }],\n",
    "    ),\n",
    "    frames=frames\n",
    ")\n",
    "fig.show()\n",
    "#fig.write_html('DFS-v9-comoving.html') # Save to HTML\n",
    "plot_html = pio.to_html(fig, full_html=False, include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3498b",
   "metadata": {
    "id": "92a3498b"
   },
   "source": [
    "__Baryon temperature animation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ea7ef",
   "metadata": {
    "cellView": "form",
    "id": "a14ea7ef"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "R_scale = L/2\n",
    "phys_scale = False\n",
    "body_pos = positions_hist[-1].astype(np.float16)\n",
    "baryon_pos = body_pos[baryon_set[grid_downsampled]]\n",
    "body_temp = temp_hist[-1]\n",
    "baryon_temp = body_temp[baryon_set[grid_downsampled]]\n",
    "#log_temp = np.log10(np.clip(baryon_temp, 1, None))  # avoid log(0)\n",
    "cmin = 0\n",
    "cmax = np.percentile(baryon_temp, 95)\n",
    "\n",
    "# Create Plotly animation frames\n",
    "frames = []\n",
    "for i, pos in enumerate(positions_hist):\n",
    "    aa = scale_hist[i] if phys_scale else 1.0\n",
    "    body_pos = pos.astype(np.float16)\n",
    "    baryon_pos = body_pos[baryon_set[grid_downsampled]]\n",
    "    body_temp = temp_hist[i]\n",
    "    baryon_temp = body_temp[baryon_set[grid_downsampled]]\n",
    "    #log_temp = np.log10(np.clip(baryon_temp, 1, None))  # avoid log(0)\n",
    "    frames.append(go.Frame(\n",
    "            data=[\n",
    "            go.Scatter3d(\n",
    "                x=baryon_pos[:, 0] * aa,\n",
    "                y=baryon_pos[:, 1] * aa,\n",
    "                z=baryon_pos[:, 2] * aa,\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=1,\n",
    "                    color=baryon_temp,\n",
    "                    colorscale='plasma',\n",
    "                    cmin=cmin,\n",
    "                    cmax=cmax,\n",
    "                    colorbar=dict(\n",
    "                        title=\"Temp [K]\",\n",
    "                        #tickvals=[2, 4, 6, 8],     # example ticks\n",
    "                        #ticktext=[\"10Â²\", \"10â´\", \"10â¶\", \"10â¸\"]\n",
    "                    ),\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                name='Baryon'\n",
    "            )\n",
    "        ],\n",
    "        name=f'frame{i}',\n",
    "        layout=go.Layout(title_text='N-body Simulation - Baryon Temperature')\n",
    "    ))\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=baryon_pos[:, 0] * aa,\n",
    "            y=baryon_pos[:, 1] * aa,\n",
    "            z=baryon_pos[:, 2] * aa,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=1,\n",
    "                color=baryon_temp,\n",
    "                colorscale='plasma', # 'Viridis'\n",
    "                cmin=cmin,\n",
    "                cmax=cmax,\n",
    "                colorbar=dict(\n",
    "                    title=\"Temp [K]\",\n",
    "                    #tickvals=[2, 4, 6, 8],     # example ticks\n",
    "                    #ticktext=[\"10Â²\", \"10â´\", \"10â¶\", \"10â¸\"]\n",
    "                ),\n",
    "                opacity=0.8\n",
    "            ),\n",
    "            name='Baryon'\n",
    "        ),\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        title='N-body Simulation - Baryon Temperature',\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        scene=dict(\n",
    "            xaxis=dict(title='x [Mpc]', range=[-R_scale, R_scale]),\n",
    "            yaxis=dict(title='y [Mpc]', range=[-R_scale, R_scale]),\n",
    "            zaxis=dict(title='z [Mpc]', range=[-R_scale, R_scale]),\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.4, y=-1.8, z=1.3),\n",
    "                up=dict(x=0, y=0, z=-1),\n",
    "                projection=dict(type='perspective')\n",
    "            ),\n",
    "            aspectratio=dict(x=1.2, y=1.2, z=1.2)\n",
    "        ),\n",
    "        updatemenus=menues,\n",
    "        sliders=[{\n",
    "            \"steps\": [\n",
    "                {\"args\": [[f\"frame{i}\"], {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}],\n",
    "                    \"label\": f\"{time_hist[i]:,.0f} Myr\",\n",
    "                    \"method\": \"animate\"\n",
    "                    } for i in range(0,len(positions_hist),1)\n",
    "            ],\n",
    "        }],\n",
    "\n",
    "    ),\n",
    "    frames=frames\n",
    ")\n",
    "fig.show()\n",
    "thermo_animation_html = pio.to_html(fig, full_html=False, include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a95bf6",
   "metadata": {
    "id": "68a95bf6"
   },
   "source": [
    "__Halo identification__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25efda2a",
   "metadata": {
    "cellView": "form",
    "id": "25efda2a"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def fof_groups(positions, linking_length):\n",
    "    tree = cKDTree(positions)\n",
    "    N = len(positions)\n",
    "    groups = []\n",
    "    visited = np.zeros(N, dtype=bool)\n",
    "\n",
    "    for i in range(N):\n",
    "        if visited[i]:\n",
    "            continue\n",
    "        group = [i]\n",
    "        queue = [i]\n",
    "        visited[i] = True\n",
    "        while queue:\n",
    "            j = queue.pop()\n",
    "            neighbors = tree.query_ball_point(positions[j], linking_length)\n",
    "            for n in neighbors:\n",
    "                if not visited[n]:\n",
    "                    visited[n] = True\n",
    "                    group.append(n)\n",
    "                    queue.append(n)\n",
    "        groups.append(np.array(group))\n",
    "    result = [g for g in groups if len(g) >= 20]\n",
    "    return sorted(result, key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88aa93",
   "metadata": {
    "cellView": "form",
    "id": "5d88aa93"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Halo analysis function\n",
    "def analyze_halo(pos_halo, vel_halo, masses_halo, a, G_cos):\n",
    "    \"\"\"\n",
    "    Analyze halo properties for a group of particles.\n",
    "\n",
    "    Parameters:\n",
    "        positions : array of all particle positions [Mpc, physical]\n",
    "        velocities: array of all particle velocities [Mpc/Myr]\n",
    "        mass      : mass of a single particle [Msun]\n",
    "        a         : scale factor\n",
    "\n",
    "    Returns:\n",
    "        radius         : max distance from center [Mpc]\n",
    "        L              : angular momentum vector [MsunÂ·MpcÂ²/Myr]\n",
    "        omega          : angular velocity vector [rad/Myr]\n",
    "        overdensity    : (rho_halo / rho_crit(a)) - 1\n",
    "        lambda_bullock : dimensionless spin parameter\n",
    "    \"\"\"\n",
    "    N = len(pos_halo)\n",
    "    halo_mass = masses_halo.sum()\n",
    "\n",
    "    if N == 0: return np.nan, np.full(3, np.nan), np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    # Center of mass\n",
    "    x_cm = np.average(pos_halo, axis=0, weights=masses_halo)\n",
    "    v_cm = np.average(vel_halo, axis=0, weights=masses_halo)\n",
    "\n",
    "    # Relative positions and velocities\n",
    "    x_rel = (pos_halo - x_cm) * a\n",
    "    v_rel = (vel_halo - v_cm) * a\n",
    "\n",
    "    # Radius = max distance from center\n",
    "    radius = np.max(np.linalg.norm(x_rel, axis=1))  # Mpc\n",
    "\n",
    "    # Angular momentum\n",
    "    L_ang = np.sum(np.cross(x_rel, v_rel)*masses_halo[:, np.newaxis], axis=0)  # MsunÂ·MpcÂ²/Myr\n",
    "\n",
    "    # Mean density in halo\n",
    "    V = (4/3) * np.pi * radius**3\n",
    "    rho_halo = halo_mass / V  # Msun / MpcÂ³\n",
    "\n",
    "    # Critical density at scale factor a\n",
    "    rho_mean_matter = Î©_m * rho_crit0 * E(a)**2 # M_sun / MpcÂ³\n",
    "    overdensity = rho_halo / rho_mean_matter - 1\n",
    "\n",
    "    # Bullock spin parameter Î»'\n",
    "    V_circ = np.sqrt(G_cos * halo_mass / radius)  # Mpc/Myr\n",
    "    lambda_bullock = np.linalg.norm(L_ang) / (np.sqrt(2) * halo_mass * V_circ * radius) # dimensionless\n",
    "\n",
    "    # Computes the shape (inertia) tensor of a halo.\n",
    "    xx = x_rel[:, 0]\n",
    "    yy = x_rel[:, 1]\n",
    "    zz = x_rel[:, 2]\n",
    "\n",
    "    I_tensor = np.zeros((3, 3))\n",
    "    I_tensor[0, 0] = np.sum(xx * xx * masses_halo)\n",
    "    I_tensor[0, 1] = np.sum(xx * yy * masses_halo)\n",
    "    I_tensor[0, 2] = np.sum(xx * zz * masses_halo)\n",
    "    I_tensor[1, 0] = I_tensor[0, 1]\n",
    "    I_tensor[1, 1] = np.sum(yy * yy * masses_halo)\n",
    "    I_tensor[1, 2] = np.sum(yy * zz * masses_halo)\n",
    "    I_tensor[2, 0] = I_tensor[0, 2]\n",
    "    I_tensor[2, 1] = I_tensor[1, 2]\n",
    "    I_tensor[2, 2] = np.sum(zz * zz * masses_halo)\n",
    "\n",
    "    #omega_vec = np.linalg.inv(I_tensor) @ L_ang  # rad/Myr\n",
    "    #omega = np.linalg.norm(omega_vec)\n",
    "\n",
    "    try:\n",
    "        omega_vec = np.linalg.inv(I_tensor) @ L_ang\n",
    "        omega = np.linalg.norm(omega_vec)\n",
    "    except np.linalg.LinAlgError:\n",
    "        omega_vec = np.full_like(L_ang, np.nan)\n",
    "        omega = np.nan\n",
    "\n",
    "    eigvals, eigvecs = np.linalg.eigh(I_tensor / halo_mass) # Normalize to halo mass\n",
    "    # Sort eigenvalues: a^2 â‰¥ b^2 â‰¥ c^2\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    a, b, c = np.sqrt(eigvals)\n",
    "    triax = (a**2-b**2)/(a**2-c**2)\n",
    "    return radius, L_ang, omega, overdensity, lambda_bullock, triax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b8814",
   "metadata": {
    "cellView": "form",
    "id": "807b8814"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import io\n",
    "\n",
    "# Halo statistics\n",
    "# Expected values (Tinker)   >1e0    >1e1   >1e2   >1e3   >1e4   >1e5   >1e6    >1e7       >1e8       >1e9       >1e10      >1e11      >1e12      >1e13      >1e14\n",
    "halos_per_Mpc3 = np.array([np.inf, np.inf,np.inf,np.inf,np.inf,np.inf,np.inf, 6.438e+01, 7.658e+00, 9.321e-01, 1.172e-01, 1.530e-02, 2.054e-03, 2.586e-04, 1.972e-05])\n",
    "\n",
    "buffer = io.StringIO()\n",
    "final_pos = body_positions.astype(np.float32)\n",
    "final_vel = body_velocities_cos.astype(np.float32)\n",
    "mean_L = scale * L/Np\n",
    "linking_length = 0.12 * mean_L  # Adjust based on mean interparticle separation\n",
    "#groups = fof_groups(final_pos, linking_length)\n",
    "groups = grad_phi5.fof_groups(final_pos, linking_length)\n",
    "n_weights = len(halos_per_Mpc3)\n",
    "weight_cnt = np.zeros(n_weights)\n",
    "\n",
    "print(f\"N_bodies: {N_bodies:,}, grid cells: {Ng**3:,}, L: {L} Mpc, mean particle sep: {mean_L:.3f} Mpc, linking length: {linking_length:.3f} Mpc\", file=buffer)\n",
    "print(f\"a_init: {a_init:.3f}, a_final: {scale:.3f}, steps: {steps:,}\", file=buffer)\n",
    "print(f\"Max particle mass: {masses.max(): .3e} m_sun, Total system mass: {M_total:.3e} m_sun\", file=buffer)\n",
    "print(f\"Highest v_pec: {vel_max/c_cos:.6f} c\", file=buffer)\n",
    "print(f\"Î´ field today (mean/max/min/std): {np.mean(delta_end):.3f} / {np.max(delta_end):.1f} / {np.min(delta_end):.3f} / {np.std(delta_end):.3f}\", file=buffer)\n",
    "print(f\"Random seed for simulation: {seed}\", file=buffer)\n",
    "print(file=buffer)\n",
    "\n",
    "for i, g in enumerate(groups):\n",
    "    halo_mass = masses[g].sum()\n",
    "    for j in range(n_weights-1,0,-1):\n",
    "        if halo_mass > 10**j:\n",
    "            weight_cnt[j] += 1\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(groups)} halos\", file=buffer)\n",
    "print(f\"Halo statistics for box volume: {L**3} MpcÂ³\", file=buffer)\n",
    "min_mass = masses.min()\n",
    "for i in range(n_weights-1,0,-1): # iterate over weight classes\n",
    "    if 10**i < min_mass: # if weight class < particle mass: break\n",
    "        break\n",
    "    print(f\"> {10**i:.0e}: {weight_cnt[i].astype(int)} halos, expected {halos_per_Mpc3[i]*L**3:.1f}\", file=buffer)\n",
    "print(file=buffer)\n",
    "final_temp = np.zeros_like(body_positions[:,0])\n",
    "final_pressure = np.zeros_like(body_positions[:,0])\n",
    "final_temp[baryon_set] = T\n",
    "final_pressure[baryon_set] = P\n",
    "\n",
    "for i, g in enumerate(groups):\n",
    "    if i>20:\n",
    "        break\n",
    "    halo_pos = final_pos[g]\n",
    "    halo_vel = final_vel[g]\n",
    "    halo_masses = masses[g]\n",
    "    halo_center = np.average(halo_pos, axis=0, weights=halo_masses)\n",
    "    halo_mass = masses[g].sum()\n",
    "    halo_baryons = np.intersect1d(g, baryon_indices)\n",
    "    baryon_count = len(halo_baryons)\n",
    "    av_baryon_temp = np.mean(final_temp[halo_baryons])\n",
    "    radius, L_ang, omega, overdensity, spin, triax = analyze_halo(halo_pos, halo_vel, halo_masses, scale_hist[-1], G) # CDM+baryons\n",
    "    radius_b, L_ang_b, omega_b, overdensity_b, spin_b, triax_b = analyze_halo(final_pos[halo_baryons], final_vel[halo_baryons], masses[halo_baryons], scale_hist[-1], G) # baryons only\n",
    "    overdensity_b *= Î©_m / Î©_b\n",
    "    print(f\"#{i}: Halo with {len(g):,} particles, mass = {halo_mass:.3e} Msun, position = {halo_center[0]:.3f}/{halo_center[1]:.3f}/{halo_center[2]:.3f}, %baryons = {baryon_count/len(g):.4f}\", file=buffer)\n",
    "    print(f\"              CDM+baryons/baryons only\", file=buffer)\n",
    "    print(f\"Radius:       {radius:.2f}/{radius_b:.2f} Mpc\", file=buffer)\n",
    "    print(f\"Temp:         {av_baryon_temp:,.0f} K\", file=buffer)\n",
    "    print(f\"|L|:          {np.linalg.norm(L_ang):.2e}/{np.linalg.norm(L_ang_b):.2e} MsunÂ·MpcÂ²/Myr\", file=buffer)\n",
    "    print(f\"|omega|:      {omega:.3e}/{omega_b:.3e} rad/Myr, {2*np.pi/1000/omega:.1f}/{2*np.pi/1000/omega_b:.1f} Gy per revolution\", file=buffer)\n",
    "    print(f\"Triaxiality:  {triax:.3f}/{triax_b:.3f} (0=oblate, 1=prolate)\", file=buffer)\n",
    "    print(f\"Overdensity:  {overdensity:.2f}/{overdensity_b:.2f}\", file=buffer)\n",
    "    print(f\"Spin Î»':      {spin:.4e}/{spin_b:.4e}\", file=buffer)\n",
    "    print(file=buffer)\n",
    "\n",
    "report_text = buffer.getvalue()\n",
    "print(report_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0671e449",
   "metadata": {
    "id": "0671e449"
   },
   "source": [
    "__Disk-shaped halos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f219994",
   "metadata": {
    "cellView": "form",
    "id": "1f219994"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "for i, g in enumerate(groups):\n",
    "    if i>100:\n",
    "        break\n",
    "    halo_pos = final_pos[g]\n",
    "    halo_vel = final_vel[g]\n",
    "    halo_masses = masses[g]\n",
    "    halo_center = np.mean(final_pos[g], axis=0)\n",
    "    halo_mass = masses[g].sum()\n",
    "    halo_baryons = np.intersect1d(g, baryon_indices)\n",
    "    baryon_count = len(halo_baryons)\n",
    "    if baryon_count < 10: continue\n",
    "    av_baryon_temp = np.mean(final_temp[halo_baryons])\n",
    "    radius, L_ang, omega, overdensity, spin, triax = analyze_halo(halo_pos, halo_vel, halo_masses, scale_hist[-1], G) # CDM+baryons\n",
    "    radius_b, L_ang_b, omega_b, overdensity_b, spin_b, triax_b = analyze_halo(final_pos[halo_baryons], final_vel[halo_baryons], masses[halo_baryons], scale_hist[-1], G) # baryons only\n",
    "    overdensity_b *= Î©_m / Î©_b\n",
    "    if triax_b < 0.3 and radius_b != np.nan:\n",
    "        print(f\"#{i}: Disk-shaped halo with {len(g):,} particles, mass = {halo_mass:.3e} Msun, position = {halo_center[0]:.3f}/{halo_center[1]:.3f}/{halo_center[2]:.3f}, %baryons = {baryon_count/len(g):.4f}\")\n",
    "        print(f\"              CDM+baryons/baryons only\")\n",
    "        print(f\"Radius:       {radius:.2f}/{radius_b:.2f} Mpc\")\n",
    "        print(f\"Temp:         {av_baryon_temp:,.0f} K\")\n",
    "        print(f\"|L|:          {np.linalg.norm(L_ang):.2e}/{np.linalg.norm(L_ang_b):.2e} MsunÂ·MpcÂ²/Myr\")\n",
    "        print(f\"|omega|:      {omega:.3e}/{omega_b:.3e} rad/Myr, {2*np.pi/1000/omega:.1f}/{2*np.pi/1000/omega_b:.1f} Gy per revolution\")\n",
    "        print(f\"Triaxiality:  {triax:.3f}/{triax_b:.3f} (0=oblate, 1=prolate)\")\n",
    "        print(f\"Overdensity:  {overdensity:.2f}/{overdensity_b:.2f}\")\n",
    "        print(f\"Spin Î»':      {spin:.4e}/{spin_b:.4e}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae4fd6",
   "metadata": {
    "id": "0aae4fd6"
   },
   "source": [
    "__Visualize halos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8f3bf",
   "metadata": {
    "cellView": "form",
    "id": "78f8f3bf"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Additional Halo Analysis - Helpers\n",
    "def minimum_image(dx, Lbox=None):\n",
    "    # Apply minimum-image convention along last axis if Lbox is given.\n",
    "    if Lbox is None:\n",
    "        return dx\n",
    "    return (dx + 0.5*Lbox) % Lbox - 0.5*Lbox\n",
    "\n",
    "def shrink_center(x, m=None, Lbox=None, shrink=0.8, tol=1e-4, max_iter=50):\n",
    "    # Iterative shrinking-sphere center finder (comoving).\n",
    "    # Returns center (3,), indices kept.\n",
    "\n",
    "    m = m * np.ones(x.shape[0])\n",
    "\n",
    "    # start from mass-weighted COM\n",
    "    c = (m[:,None] * x).sum(axis=0) / m.sum()\n",
    "    # initial radius: half the max span\n",
    "    dx = minimum_image(x - c, Lbox)\n",
    "    r = np.linalg.norm(dx, axis=1)\n",
    "    R = np.percentile(r, 90.0) if np.any(r>0) else 0.0\n",
    "\n",
    "    keep = np.arange(x.shape[0])\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        if R <= 0:\n",
    "            break\n",
    "        # keep particles within R\n",
    "        sel = r <= R\n",
    "        if sel.sum() < 50:   # avoid pathological small-N\n",
    "            break\n",
    "        keep = keep[sel]\n",
    "        # recompute center in that subset\n",
    "        c_new = (m[keep,None]*x[keep]).sum(axis=0) / m[keep].sum()\n",
    "        if np.linalg.norm(minimum_image(c_new - c, Lbox)) < tol * R:\n",
    "            c = c_new\n",
    "            break\n",
    "        c = c_new\n",
    "        # shrink sphere\n",
    "        dx = minimum_image(x[keep] - c, Lbox)\n",
    "        r = np.linalg.norm(dx, axis=1)\n",
    "        R *= shrink\n",
    "\n",
    "    return c, keep\n",
    "\n",
    "def enclosed_200m(x, m, a, Omega_m, rho_crit0, center, Lbox=None):\n",
    "    # Find R_200m and M_200m. Uses *comoving* positions and the 200Ã—mean-matter threshold.\n",
    "    # In comoving units, the threshold is constant: rho_bar,com = Omega_m * rho_crit0.\n",
    "    # Condition: M(<R_com) / (4/3 Ï€ R_com^3) = 200 * Omega_m * rho_crit0\n",
    "\n",
    "    m = np.asarray(m, dtype=np.float64)\n",
    "    if m.ndim == 0:\n",
    "        m = np.full(x.shape[0], float(m))\n",
    "\n",
    "    rho_bar_com = Omega_m * rho_crit0  # [Msun/Mpc^3], constant in comoving coordinates\n",
    "\n",
    "    # radii from center (comoving)\n",
    "    dx = minimum_image(x - center, Lbox)\n",
    "    r = np.linalg.norm(dx, axis=1)  # comoving Mpc\n",
    "    order = np.argsort(r)\n",
    "    r_sorted = r[order]\n",
    "    m_sorted = m[order]\n",
    "    M_enc = np.cumsum(m_sorted)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        rho_enc_com = M_enc / ((4.0/3.0)*np.pi * np.maximum(r_sorted, 1e-12)**3)\n",
    "\n",
    "    target = 200.0 * rho_bar_com\n",
    "    # first radius where enclosed mean falls below target (profile declines outward)\n",
    "    idx = np.searchsorted(rho_enc_com < target, True)\n",
    "    if idx == r_sorted.size:\n",
    "        # did not drop below target within the sample; take outermost\n",
    "        idx_star = r_sorted.size - 1\n",
    "    else:\n",
    "        idx_star = idx\n",
    "\n",
    "    R200m_com = r_sorted[idx_star]\n",
    "    M200m     = M_enc[idx_star]\n",
    "    R200m_phys = a * R200m_com\n",
    "    return R200m_com, R200m_phys, M200m, order[:idx_star+1]  # indices inside R200m\n",
    "\n",
    "def bullock_spin(x, u, m, a, G, center, indices_R, Lbox=None):\n",
    "    # Bullock spin parameter Î»' inside R200m.\n",
    "    # Inputs: x (comoving), u (comoving peculiar), m, scale a, G in Mpc^3/(Msun Myr^2).\n",
    "\n",
    "    m = np.asarray(m, dtype=np.float64)\n",
    "    if m.ndim == 0:\n",
    "        m = np.full(x.shape[0], float(m))\n",
    "\n",
    "    I = indices_R\n",
    "    mR = m[I]\n",
    "    # relative comoving coords/vels to halo bulk\n",
    "    x_rel = minimum_image(x[I] - center, Lbox)\n",
    "    u_cm  = (mR[:,None] * u[I]).sum(axis=0) / mR.sum()\n",
    "    u_rel = u[I] - u_cm\n",
    "\n",
    "    # J_phys = a^2 * sum m (x Ã— u)   (since r = a x, v_pec = a u)\n",
    "    J_com = np.sum(np.cross(x_rel, u_rel) * mR[:,None], axis=0)\n",
    "    J_phys = (a*a) * J_com\n",
    "    Jnorm = np.linalg.norm(J_phys)\n",
    "\n",
    "    # R and M inside selection\n",
    "    r_phys = a * np.linalg.norm(x_rel, axis=1)\n",
    "    R = r_phys.max()\n",
    "    M = mR.sum()\n",
    "\n",
    "    Vc = np.sqrt(G * M / R)\n",
    "    lambda_bullock = Jnorm / (np.sqrt(2.0) * M * Vc * R)\n",
    "    return lambda_bullock, J_phys, R, M\n",
    "\n",
    "def radial_velocity_profile(x, u, m, a, center, R200m_phys, Lbox=None, edges=None, nbins=10, pct=(16,50,84)):\n",
    "    # Radial velocity stats vs radius (physical). Uses peculiar velocities (no Hubble term).\n",
    "    # Returns: r_bin_centers [Mpc], v_r percentiles [km/s-equivalent if you convert units].\n",
    "    #Here units stay in whatever your u uses (Mpc/Myr).\n",
    "\n",
    "    m = np.asarray(m, dtype=np.float64)\n",
    "    if m.ndim == 0:\n",
    "        m = np.full(x.shape[0], float(m))\n",
    "\n",
    "    x_rel = minimum_image(x - center, Lbox)\n",
    "    r_phys = a * np.linalg.norm(x_rel, axis=1)\n",
    "    # physical peculiar velocities\n",
    "    u_rel = u - (m[:,None]*u).sum(axis=0)/m.sum()  # subtract global CM (or recompute inside R if desired)\n",
    "    v_phys = a * u_rel\n",
    "    # radial component\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        rhat = np.divide(x_rel, np.linalg.norm(x_rel, axis=1)[:,None], where=(r_phys[:,None]>0))\n",
    "    v_r = np.sum(v_phys * rhat, axis=1)\n",
    "\n",
    "    # Binning by spherical radius\n",
    "    if edges is None:\n",
    "        edges = np.linspace(0.0, R200m_phys, nbins+1)\n",
    "    centers = 0.5*(edges[:-1] + edges[1:])\n",
    "\n",
    "    prc = np.empty((len(pct), nbins))\n",
    "    for i in range(nbins):\n",
    "        mask = (r_phys >= edges[i]) & (r_phys < edges[i+1])\n",
    "        if np.any(mask):\n",
    "            prc[:, i] = np.percentile(v_r[mask], pct)\n",
    "        else:\n",
    "            prc[:, i] = np.nan\n",
    "    return centers, prc, edges\n",
    "\n",
    "def rotation_profiles(x, u, t, is_baryon, m, a, center, R200m_phys, G, Lbox=None, edges=None, nbins=10, min_count=20):\n",
    "    # x,u: comoving positions and peculiar velocities\n",
    "    # m  : scalar or array [Msun]\n",
    "    # a  : scale factor\n",
    "    # center: comoving center\n",
    "    # Returns dict with:\n",
    "    #   - r_centers [Mpc]\n",
    "    #   - mean_omega [rad/Myr], mean_vphi [km/s] (mass-weighted, signed)\n",
    "    #   - med_vphi_pro [km/s] (median of prograde-only)\n",
    "    #   - Vc [km/s] (circular velocity from enclosed mass)\n",
    "\n",
    "    if np.ndim(m)==0:\n",
    "        m = np.full(x.shape[0], float(m))\n",
    "    m = m.astype(float)\n",
    "\n",
    "    def mic(dx, L): return (dx + 0.5*L) % L - 0.5*L if L is not None else dx\n",
    "\n",
    "    # Relative (comoving) and physical vectors\n",
    "    dx = mic(x - center, Lbox)\n",
    "    r_phys = a * np.linalg.norm(dx, axis=1)\n",
    "\n",
    "    # Bulk peculiar velocity inside R200m\n",
    "    inside = r_phys <= R200m_phys\n",
    "    u_cm = (m[inside,None]*u[inside]).sum(axis=0)/m[inside].sum()\n",
    "\n",
    "    r_vec = a * dx\n",
    "    v_vec = a * (u - u_cm)\n",
    "\n",
    "    # Spin axis from particles inside R200m\n",
    "    J = np.sum(np.cross(r_vec[inside], v_vec[inside]) * m[inside,None], axis=0)\n",
    "    n_hat = J/np.linalg.norm(J) if np.linalg.norm(J)>0 else np.array([0,0,1.0])\n",
    "\n",
    "    # Cylindrical radius about spin axis and specific ang. mom. component\n",
    "    eps = 1e-12\n",
    "    R_perp = np.linalg.norm(np.cross(r_vec, n_hat), axis=1) # [Mpc]\n",
    "    jz     = np.einsum('ij,j->i', np.cross(r_vec, v_vec), n_hat) # [Mpc^2/Myr]\n",
    "    # component of v along azimuthal direction = jz / R_perp (but be careful at axis)\n",
    "    vphi_signed = jz / np.maximum(R_perp, eps) # [Mpc/Myr]\n",
    "\n",
    "    # Binning by spherical radius\n",
    "    if edges is None:\n",
    "        edges = np.linspace(0.0, R200m_phys, nbins+1)\n",
    "    centers = 0.5*(edges[:-1] + edges[1:])\n",
    "\n",
    "    mean_omega = np.full(len(centers), np.nan)      # [rad/Myr]\n",
    "    mean_vphi  = np.full(len(centers), np.nan)      # [Mpc/Myr]\n",
    "    med_vphi_pro = np.full(len(centers), np.nan)    # [Mpc/Myr]\n",
    "    Vc = np.full(len(centers), np.nan)              # [Mpc/Myr]\n",
    "    prograde_ratio = np.full(len(centers), np.nan)  # 1\n",
    "    krot_b = np.full(len(centers), np.nan)  # 1\n",
    "    mean_temp = np.full(len(centers), np.nan)  # K\n",
    "    n_b = np.full(len(centers), np.nan)  # 1\n",
    "\n",
    "    # Precompute cumulative mass for Vc\n",
    "    order = np.argsort(r_phys)\n",
    "    r_sorted = r_phys[order]\n",
    "    M_cum = np.cumsum(m[order])\n",
    "    # Helper to get enclosed mass at a radius via searchsorted\n",
    "    def enclosed_mass(r):\n",
    "        idx = np.searchsorted(r_sorted, r, side='right')-1\n",
    "        if idx < 0: return 0.0\n",
    "        return M_cum[idx]\n",
    "\n",
    "    for i in range(len(centers)):\n",
    "        mask = (r_phys >= edges[i]) & (r_phys < edges[i+1]) & is_baryon\n",
    "        n_b[i] = mask.sum()\n",
    "        if n_b[i] < min_count: continue\n",
    "\n",
    "        mean_temp[i] = np.sum(m[mask]*t[mask] / np.sum(m[mask]))\n",
    "\n",
    "        # Mass-weighted mean omega: sum(jz)/sum(m R_perp^2)\n",
    "        denom = (m[mask] * np.maximum(R_perp[mask]**2, eps**2)).sum()\n",
    "        num   = jz[mask].sum()\n",
    "        if denom > 0:\n",
    "            mean_omega[i] = num / denom  # [rad/Myr]\n",
    "            mean_vphi[i]  = (mean_omega[i] * (m[mask]*R_perp[mask]).sum()/m[mask].sum()) # [Mpc/Myr]\n",
    "\n",
    "        # kappa_rot for baryons only in this bin\n",
    "        v2_b = np.sum(v_vec[mask]**2, axis=1) # [Mpc^2/Myr^2]\n",
    "        Ktot_b = 0.5 * np.sum(m[mask] * v2_b)\n",
    "        Krot_b = 0.5 * np.sum(m[mask] * (vphi_signed[mask]**2))\n",
    "        krot_b[i] = Krot_b / Ktot_b if Ktot_b > 0 else np.nan\n",
    "\n",
    "        # Prograde-only median azimuthal speed\n",
    "        pro = mask & (jz > 0)\n",
    "        if pro.sum() >= min_count:\n",
    "            med_vphi_pro[i] = np.median(vphi_signed[pro])\n",
    "            prograde_ratio[i] = pro.sum() / mask.sum()\n",
    "\n",
    "        # Circular velocity from enclosed mass at bin center\n",
    "        Menc = enclosed_mass(centers[i])\n",
    "        if Menc > 0 and centers[i] > 0:\n",
    "            Vc[i] = np.sqrt(G * Menc / centers[i]) # [Mpc/Myr]\n",
    "\n",
    "    return centers, mean_omega, mean_vphi, med_vphi_pro, prograde_ratio, krot_b, Vc, n_hat, mean_temp, n_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0852ec5",
   "metadata": {
    "cellView": "form",
    "id": "f0852ec5"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Additional Halo Analysis - Main function\n",
    "def analyze_halo_200m(x, u, t, is_baryon, m, a, Omega_m, rho_crit0, G, Lbox=None, nbins=25):\n",
    "    # Full analysis:\n",
    "    #  - center (shrink sphere)\n",
    "    #  - R200m, M200m\n",
    "    #  - Bullock spin inside R200m\n",
    "    #  - radial velocity profile (to 2*R200m)\n",
    "\n",
    "    center, _ = shrink_center(x, m, Lbox=Lbox) # 1) center\n",
    "    R200m_com, R200m_phys, M200m, idx_in = enclosed_200m(x, m, a, Omega_m, rho_crit0, center, Lbox=Lbox) # 2) R200m, M200m\n",
    "    lam_p, Jvec, Rsel, Msel = bullock_spin(x, u, m, a, G, center, idx_in, Lbox=Lbox) # 3) spin inside R200m\n",
    "    r_centers, v_prc, r_edges = radial_velocity_profile(x, u, m, a, center, 0.3*R200m_phys, edges=None, Lbox=Lbox, nbins=nbins) # 4) radial velocity profile out to 2*R200m\n",
    "    r_centers, mean_omega, mean_vphi, med_vphi_pro, prograde_ratio, k_rot, Vc, n_hat, mean_temp, n_b = rotation_profiles(x, u, t, is_baryon, m, a, center, 0.3*R200m_phys, G, Lbox=None, nbins=nbins, min_count=10, edges=None)\n",
    "    mask = ~np.isnan(med_vphi_pro) & ~np.isnan(Vc)\n",
    "    Vc_sum = np.sum(Vc[mask])\n",
    "    rot_support_ratio = np.sum(med_vphi_pro[mask]) / Vc_sum if Vc_sum != 0.0 else np.nan\n",
    "\n",
    "    out = {\n",
    "        \"center_com\": center,\n",
    "        \"R200m_com\": R200m_com,\n",
    "        \"R200m_phys\": R200m_phys,\n",
    "        \"M200m\": M200m,\n",
    "        \"spin_lambda_prime\": lam_p,\n",
    "        \"J_phys\": Jvec,\n",
    "        \"rv_radii_phys\": r_centers,\n",
    "        \"rv_percentiles\": {\"p16\": v_prc[0], \"p50\": v_prc[1], \"p84\": v_prc[2]},\n",
    "        \"rv_edges_phys\": r_edges,\n",
    "        \"indices_inside_R200m\": idx_in,\n",
    "        \"mean_omega\": mean_omega,\n",
    "        \"mean_vphi\": mean_vphi,\n",
    "        \"med_vphi_pro\": med_vphi_pro,\n",
    "        \"prograde_ratio\": prograde_ratio,\n",
    "        \"k_rot\": k_rot,\n",
    "        \"Vc\": Vc,\n",
    "        \"n_hat\": n_hat,\n",
    "        \"mean_temp\": mean_temp,\n",
    "        \"rot_support_ratio\": rot_support_ratio,\n",
    "        \"n_b\": n_b\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def analyze_disk_region(\n",
    "    x, u, t, is_baryon, m, a, G,\n",
    "    f_spin=0.1,                # inner sphere (in units of R200m) to define spin axis\n",
    "    f_R=0.2,                   # cylinder radius = f_R * R200m (physical)\n",
    "    f_z=0.05,                  # cylinder half-thickness = f_z * R200m (physical)\n",
    "    nbins=8,                   # radial bins within the cylinder\n",
    "    min_count=20               # minimum particles per selection/bin\n",
    "):\n",
    "    \"\"\"\n",
    "    x,u: (N,3) comoving positions [Mpc], peculiar velocities [Mpc/Myr]\n",
    "    m  : scalar or (N,) masses [Msun]\n",
    "    is_baryon: (N,) boolean mask for baryons\n",
    "    a  : scale factor\n",
    "    center: (3,) comoving halo center [Mpc]\n",
    "    R200m_phys: halo radius [Mpc physical]\n",
    "\n",
    "    Returns dict with:\n",
    "      n_hat, disk_masks, kappa_rot_baryon_disk, f_prograde_baryon_disk,\n",
    "      rbin_centers_phys, med_vphi_pro_baryon_kms, Vc_total_kms,\n",
    "      kappa_rot_baryon_bins, f_prograde_baryon_bins\n",
    "    \"\"\"\n",
    "    N = x.shape[0]\n",
    "    if np.ndim(m) == 0:\n",
    "        m = np.full(N, float(m))\n",
    "    m = m.astype(float)\n",
    "\n",
    "    center, _ = shrink_center(x, m, Lbox=None) # center\n",
    "    _, R200m_phys, M200m, _ = enclosed_200m(x, m, a, Î©_m, rho_crit0, center, Lbox=None) # R200m, M200m\n",
    "\n",
    "    # --- relative physical positions & velocities ---\n",
    "    dx = x - center      # comoving\n",
    "    r_phys = a * dx                 # [Mpc]\n",
    "    v_phys = a * u                  # [Mpc/Myr]\n",
    "\n",
    "    # --- robust spin axis from baryons in inner sphere ---\n",
    "    R_spin = max(1e-6, f_spin * R200m_phys)\n",
    "    r_sph = np.linalg.norm(r_phys, axis=1)\n",
    "    sel_spin = is_baryon & (r_sph <= R_spin)\n",
    "    if sel_spin.sum() < 5:\n",
    "        # fallback: use all baryons\n",
    "        sel_spin = is_baryon\n",
    "\n",
    "    L_vec = np.sum(m[sel_spin, None] * np.cross(r_phys[sel_spin], v_phys[sel_spin]), axis=0)\n",
    "    L_norm = np.linalg.norm(L_vec)\n",
    "    n_hat = L_vec / L_norm if L_norm > 0 else np.array([0.0, 0.0, 1.0])\n",
    "\n",
    "    # --- cylindrical coordinates around n_hat ---\n",
    "    z = np.einsum('ij,j->i', r_phys, n_hat)                         # [Mpc]\n",
    "    R_perp = np.linalg.norm(np.cross(r_phys, n_hat), axis=1)        # [Mpc]\n",
    "    jz = np.einsum('ij,j->i', np.cross(r_phys, v_phys), n_hat)      # [Mpc^2/Myr]\n",
    "    vphi = jz / np.maximum(R_perp, 1e-12)                           # [Mpc/Myr]\n",
    "\n",
    "    # --- disk selection (baryons only) ---\n",
    "    R_max = f_R * R200m_phys\n",
    "    z_max = f_z * R200m_phys\n",
    "    disk_mask = (np.abs(z) <= z_max) & (R_perp <= R_max)\n",
    "    disk_baryons = disk_mask & is_baryon\n",
    "\n",
    "    # --- global disk diagnostics (baryons only) ---\n",
    "    out = {\"n_hat\": n_hat, \"disk_mask\": disk_mask, \"disk_baryons\": disk_baryons}\n",
    "\n",
    "    if disk_baryons.sum() >= min_count:\n",
    "        v2_b = np.sum(v_phys[disk_baryons]**2, axis=1)                 # [Mpc^2/Myr^2]\n",
    "        Ktot_b = 0.5 * np.sum(m[disk_baryons] * v2_b)\n",
    "        Krot_b = 0.5 * np.sum(m[disk_baryons] * (vphi[disk_baryons]**2))\n",
    "        kappa_rot_baryon_disk = Krot_b / Ktot_b if Ktot_b > 0 else np.nan\n",
    "        f_prograde_baryon_disk = np.count_nonzero(jz[disk_baryons] > 0) / disk_baryons.sum()\n",
    "    else:\n",
    "        kappa_rot_baryon_disk = np.nan\n",
    "        f_prograde_baryon_disk = np.nan\n",
    "\n",
    "    out[\"kappa_rot_baryon_disk\"] = kappa_rot_baryon_disk\n",
    "    out[\"f_prograde_baryon_disk\"] = f_prograde_baryon_disk\n",
    "\n",
    "    # --- Vc(r): spherical enclosed mass using ALL mass (DM + baryons) ---\n",
    "    r_all = np.linalg.norm(r_phys, axis=1)\n",
    "    order = np.argsort(r_all)\n",
    "    r_sorted = r_all[order]\n",
    "    Mcum = np.cumsum(m[order])\n",
    "\n",
    "    def M_enclosed(r0):\n",
    "        i = np.searchsorted(r_sorted, r0, side='right') - 1\n",
    "        return 0.0 if i < 0 else Mcum[i]\n",
    "\n",
    "    # --- radial bins in the disk (cylindrical radius) ---\n",
    "    if nbins is None or nbins < 1:\n",
    "        return out\n",
    "\n",
    "    # Only consider disk area up to R_max\n",
    "    edges = np.linspace(0.0, R_max, nbins + 1)\n",
    "    centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "\n",
    "    med_vphi_pro = np.full(nbins, np.nan)\n",
    "    Vc_total = np.full(nbins, np.nan)\n",
    "    krot_bins = np.full(nbins, np.nan)\n",
    "    fpro_bins = np.full(nbins, np.nan)\n",
    "    n_bins = np.full(nbins, np.nan)\n",
    "\n",
    "    # Per-bin stats (baryons in disk)\n",
    "    for i in range(nbins):\n",
    "        sel_bin = disk_baryons & (R_perp >= edges[i]) & (R_perp < edges[i+1])\n",
    "        n_bins[i] = sel_bin.sum()\n",
    "\n",
    "        if sel_bin.sum() < min_count: continue\n",
    "\n",
    "        # prograde fraction & median vphi (prograde baryons)\n",
    "        pro = sel_bin & (jz > 0)\n",
    "        fpro_bins[i] = np.count_nonzero(pro) / sel_bin.sum()\n",
    "        if pro.any():\n",
    "            med_vphi_pro[i] = np.median(vphi[pro])\n",
    "\n",
    "        # kappa_rot in this ring (baryons)\n",
    "        v2_b = np.sum(v_phys[sel_bin]**2, axis=1)\n",
    "        Ktot_b = 0.5 * np.sum(m[sel_bin] * v2_b)\n",
    "        Krot_b = 0.5 * np.sum(m[sel_bin] * (vphi[sel_bin]**2))\n",
    "        krot_bins[i] = Krot_b / Ktot_b if Ktot_b > 0 else np.nan\n",
    "\n",
    "        # benchmark circular speed from enclosed TOTAL mass at spherical r = bin center\n",
    "        r0 = centers[i]\n",
    "        if r0 > 0:\n",
    "            Menc = M_enclosed(r0)\n",
    "            if Menc > 0:\n",
    "                Vc_total[i] = np.sqrt(G * Menc / r0)\n",
    "\n",
    "    out.update({\n",
    "        \"rbin_centers_phys\": centers,\n",
    "        \"med_vphi_pro_baryon_kms\": med_vphi_pro,\n",
    "        \"Vc_total_kms\": Vc_total,\n",
    "        \"kappa_rot_baryon_bins\": krot_bins,\n",
    "        \"f_prograde_baryon_bins\": fpro_bins,\n",
    "    })\n",
    "\n",
    "    print(f\"R200m phys:         {R200m_phys:.3f} Mpc (CDM+baryons)\")\n",
    "    print(f\"M200m:              {M200m:.3e} Msun (CDM+baryons)\")\n",
    "    #print(f\"Spin Lambda prime:  {disk_char['spin_lambda_prime']:.3e} (CDM+baryons)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.3f}\" for r in centers) + '\\t]'\n",
    "    print(f\"Radial bin centers: {formatted_list} Mpc\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:,.0f}\" for r in n_bins) + '\\t]'\n",
    "    print(f\"number of baryons:  {formatted_list}\")\n",
    "    #formatted_list = '[ ' + ',\\t'.join(f\"{r:.1f}\" for r in halo_char['mean_temp']/1000) + '\\t]'\n",
    "    #print(f\"Mean temperature:   {formatted_list} kK\")\n",
    "    #formatted_list = '[ ' + ',\\t'.join(f\"{r:.1f}\" for r in halo_char['rv_percentiles']['p50'] * Mpc_km/Myr_s) + '\\t]'\n",
    "    #print(f\"Med radial vel:     {formatted_list} km/s (CDM+baryons)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.3f}\" for r in fpro_bins) + '\\t]'\n",
    "    print(f\"Prograde fraction:  {formatted_list} (baryons only)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.3f}\" for r in krot_bins) + '\\t]'\n",
    "    print(f\"k_rot ratio:        {formatted_list} (baryons only)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.1f}\" for r in med_vphi_pro * Mpc_km/Myr_s) + '\\t]'\n",
    "    print(f\"Med vphi prograde:  {formatted_list} km/s (baryons only)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.1f}\" for r in Vc_total * Mpc_km/Myr_s) + '\\t]'\n",
    "    print(f\"Vc:                 {formatted_list} km/s (benchmark for med vphi prograde)\")\n",
    "    #print(f\"Rot support ratio:  {halo_char['rot_support_ratio']:.3f} (baryons only)\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# if not np.isnan(r)\n",
    "def print_halo_characteristics(halo_char):\n",
    "    print(f\"R200m phys:         {halo_char['R200m_phys']:.3f} Mpc (CDM+baryons)\")\n",
    "    print(f\"M200m:              {halo_char['M200m']:.3e} Msun (CDM+baryons)\")\n",
    "    print(f\"Spin Lambda prime:  {halo_char['spin_lambda_prime']:.3e} (CDM+baryons)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.3f}\" for r in halo_char['rv_radii_phys']) + '\\t]'\n",
    "    print(f\"Radial bin centers: {formatted_list} Mpc\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:,.0f}\" for r in halo_char['n_b']) + '\\t]'\n",
    "    print(f\"number of baryons:  {formatted_list}\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.1f}\" for r in halo_char['mean_temp']/1000) + '\\t]'\n",
    "    print(f\"Mean temperature:   {formatted_list} kK\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.1f}\" for r in halo_char['rv_percentiles']['p50'] * Mpc_km/Myr_s) + '\\t]'\n",
    "    print(f\"Med radial vel:     {formatted_list} km/s (CDM+baryons)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.3f}\" for r in halo_char['prograde_ratio']) + '\\t]'\n",
    "    print(f\"Prograde fraction:  {formatted_list} (baryons only)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.3f}\" for r in halo_char['k_rot']) + '\\t]'\n",
    "    print(f\"k_rot ratio:        {formatted_list} (baryons only)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.1f}\" for r in halo_char['med_vphi_pro'] * Mpc_km/Myr_s) + '\\t]'\n",
    "    print(f\"Med vphi prograde:  {formatted_list} km/s (baryons only)\")\n",
    "    formatted_list = '[ ' + ',\\t'.join(f\"{r:.1f}\" for r in halo_char['Vc'] * Mpc_km/Myr_s) + '\\t]'\n",
    "    print(f\"Vc:                 {formatted_list} km/s (benchmark for med vphi prograde)\")\n",
    "    print(f\"Rot support ratio:  {halo_char['rot_support_ratio']:.3f} (baryons only)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce080a5b",
   "metadata": {
    "cellView": "form",
    "id": "ce080a5b"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Visualize halo\n",
    "halo_idx = 0\n",
    "if len(groups) < halo_idx+1:\n",
    "    print(f\"There are less than {halo_idx} halos\")\n",
    "\n",
    "halo_N_bodies = len(groups[halo_idx])\n",
    "halo_pos = final_pos[groups[halo_idx]]\n",
    "halo_vel = final_vel[groups[halo_idx]]\n",
    "halo_masses = masses[groups[halo_idx]]\n",
    "halo_temp = final_temp[groups[halo_idx]]\n",
    "halo_baryons = np.intersect1d(groups[halo_idx], baryon_indices)\n",
    "\n",
    "halo_radius, L_ang, omega, overdensity, spin, triax = analyze_halo(halo_pos, halo_vel, halo_masses, scale_hist[-1], G)\n",
    "x_cm = np.mean(halo_pos, axis=0)\n",
    "v_cm = np.mean(halo_vel, axis=0)\n",
    "x_rel = (halo_pos - x_cm) * scale\n",
    "halo_baryon_indices = np.intersect1d(baryon_indices, groups[halo_idx])\n",
    "halo_CDM_indices = np.setdiff1d(groups[halo_idx], baryon_indices)\n",
    "x_rel_baryon = (final_pos[halo_baryon_indices] - x_cm) * scale\n",
    "x_rel_CDM = (final_pos[halo_CDM_indices] - x_cm) * scale\n",
    "\n",
    "print(f\"Halo #{halo_idx}: total mass = {halo_masses.sum():.2e} m_sun, position = {x_cm[0]:.3f}/{x_cm[1]:.3f}/{x_cm[2]:.3f}\")\n",
    "\n",
    "halo_char = analyze_halo_200m(halo_pos, halo_vel, halo_temp, baryon_set[groups[halo_idx]], halo_masses, scale, Î©_m, rho_crit0, G, Lbox=None, nbins=5)\n",
    "print_halo_characteristics(halo_char)\n",
    "#print()\n",
    "#analyze_disk_region(halo_pos, halo_vel, halo_temp, baryon_set[groups[halo_idx]], masses[groups[halo_idx]], scale, G, nbins=5)\n",
    "\n",
    "R_scale = halo_radius\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(x=x_rel_CDM[:, 0], y=x_rel_CDM[:, 1], z=x_rel_CDM[:, 2], mode='markers', marker=dict(color='blue', size=1), name='CDM'),\n",
    "        go.Scatter3d(x=x_rel_baryon[:, 0], y=x_rel_baryon[:, 1], z=x_rel_baryon[:, 2], mode='markers', marker=dict(color='red', size=1), name='Baryon'),\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        title=f'Halo plot #{halo_idx} ({halo_N_bodies:,} bodies)',\n",
    "        width = 800,\n",
    "        height = 600,\n",
    "        scene=dict(\n",
    "            xaxis=dict(title='x [Mpc]', range=[-halo_radius, halo_radius]),\n",
    "            yaxis=dict(title='y [Mpc]', range=[-halo_radius, halo_radius]),\n",
    "            zaxis=dict(title='z [Mpc]', range=[-halo_radius, halo_radius]),\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.5, y=-1.5, z=1.5),\n",
    "                up=dict(x=0, y=0, z=-1),\n",
    "                projection=dict(type='perspective')\n",
    "            ),\n",
    "            aspectratio=dict(x=1.2, y=1.2, z=1.2)\n",
    "        ),\n",
    "        updatemenus=menues,\n",
    "    )\n",
    ")\n",
    "fig.show()\n",
    "#fig.write_html('Halo plot.html') # Save to HTML\n",
    "halo_plot_html = pio.to_html(fig, full_html=False, include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cfb3a1",
   "metadata": {
    "cellView": "form",
    "id": "32cfb3a1"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "R_scale = L/2\n",
    "phys_scale = True\n",
    "body_pos = positions_hist[-1].astype(np.float16)\n",
    "baryon_pos = body_pos[baryon_set[grid_downsampled]]\n",
    "body_temp = temp_hist[-1]\n",
    "baryon_temp = body_temp[baryon_set[grid_downsampled]]\n",
    "cmin = 0\n",
    "cmax = np.percentile(baryon_temp, 95)\n",
    "ref_sphere = create_sphere_mesh(x_cm - center, 2*halo_radius, color='black')\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=baryon_pos[:, 0] * aa,\n",
    "            y=baryon_pos[:, 1] * aa,\n",
    "            z=baryon_pos[:, 2] * aa,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "                color=baryon_temp,\n",
    "                colorscale='plasma', # 'Viridis'\n",
    "                cmin=cmin,\n",
    "                cmax=cmax,\n",
    "                colorbar=dict(title=\"Temp [K]\"),\n",
    "                opacity=0.8\n",
    "            ),\n",
    "            name='Baryon'\n",
    "        ),\n",
    "        ref_sphere\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        title=f'Halo #{halo_idx} identified in box',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        scene=dict(\n",
    "            xaxis=dict(title='x [Mpc]', range=[-R_scale, R_scale]),\n",
    "            yaxis=dict(title='y [Mpc]', range=[-R_scale, R_scale]),\n",
    "            zaxis=dict(title='z [Mpc]', range=[-R_scale, R_scale]),\n",
    "            camera=dict(\n",
    "                eye=dict(x=0, y=0, z=2),\n",
    "                up=dict(x=0, y=1, z=-0),\n",
    "                projection=dict(type='orthographic')\n",
    "            ),\n",
    "            aspectratio=dict(x=1.8, y=1.8, z=1.8)\n",
    "        ),\n",
    "        updatemenus=menues,\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8ded1",
   "metadata": {
    "cellView": "form",
    "id": "5ae8ded1"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "halo_set = np.zeros(N_bodies, dtype=bool)\n",
    "halo_set[groups[halo_idx]] = True\n",
    "\n",
    "frames = []\n",
    "for i, pos in enumerate(positions_hist):\n",
    "    aa = scale_hist[-1]\n",
    "    pos = pos.astype(np.float16)\n",
    "    ref_sphere = create_sphere_mesh(np.zeros(3), R_scale * scale_hist[i], color='gray')\n",
    "    frames.append(go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(x=pos[~halo_set[grid_downsampled], 0]*aa, y=pos[~halo_set[grid_downsampled], 1]*aa, z=pos[~halo_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='blue', size=1), name='CDM'),\n",
    "            go.Scatter3d(x=pos[halo_set[grid_downsampled], 0]*aa, y=pos[halo_set[grid_downsampled], 1]*aa, z=pos[halo_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='red', size=2), name='Baryon'),\n",
    "        ],\n",
    "        name=f'frame{i}',\n",
    "        layout=go.Layout(title_text='Evolution of halo')\n",
    "    ))\n",
    "\n",
    "# Initial frame\n",
    "init_pos = positions_hist[0].astype(np.float16)\n",
    "aa = scale_hist[-1]\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(x=init_pos[~halo_set[grid_downsampled], 0]*aa, y=init_pos[~halo_set[grid_downsampled], 1]*aa, z=init_pos[~halo_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='blue', size=1), name='CDM'),\n",
    "        go.Scatter3d(x=init_pos[halo_set[grid_downsampled], 0]*aa, y=init_pos[halo_set[grid_downsampled], 1]*aa, z=init_pos[halo_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='red', size=2), name='Baryon'),\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        title='Evolution of halo',\n",
    "        width = 1000,\n",
    "        height = 800,\n",
    "        scene=dict(\n",
    "            xaxis=dict(title='x [Mpc]', range=[-R_scale, R_scale]),\n",
    "            yaxis=dict(title='y [Mpc]', range=[-R_scale, R_scale]),\n",
    "            zaxis=dict(title='z [Mpc]', range=[-R_scale, R_scale]),\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.4, y=-1.8, z=1.3),\n",
    "                up=dict(x=0, y=0, z=-1),\n",
    "                projection=dict(type='perspective')\n",
    "            ),\n",
    "            aspectratio=dict(x=1.2, y=1.2, z=1.2)\n",
    "        ),\n",
    "        updatemenus=menues,\n",
    "        sliders=[{\n",
    "                    \"steps\": [\n",
    "                        {\"args\": [[f\"frame{i}\"], {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}],\n",
    "                         \"label\": f\"{time_hist[i]:,.0f} Myr\",\n",
    "                         \"method\": \"animate\"\n",
    "                         } for i in range(0,len(positions_hist),1)\n",
    "                    ],\n",
    "                }],\n",
    "    ),\n",
    "    frames=frames\n",
    ")\n",
    "fig.show()\n",
    "#fig.write_html('DFS-v9-comoving.html') # Save to HTML\n",
    "#plot_html = pio.to_html(fig, full_html=False, include_plotlyjs='cdn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32212df",
   "metadata": {
    "id": "c32212df"
   },
   "source": [
    "__Find halos with high rotational support__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7e415",
   "metadata": {
    "cellView": "form",
    "id": "c0c7e415"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "for i, g in enumerate(groups):\n",
    "    if i>100: break\n",
    "    halo_pos = final_pos[g]\n",
    "    halo_vel = final_vel[g]\n",
    "    halo_masses = masses[g]\n",
    "    halo_temp = final_temp[g]\n",
    "    halo_char = analyze_halo_200m(halo_pos, halo_vel, halo_temp, baryon_set[g], halo_masses, scale, Î©_m, rho_crit0, G, Lbox=None, nbins=10)\n",
    "    radius, L_ang, omega, overdensity, spin, triax = analyze_halo(halo_pos, halo_vel, halo_masses, scale_hist[-1], G) # CDM+baryons\n",
    "    if halo_char['rot_support_ratio'] > 0.9:\n",
    "        print(f\"#{i}: Disk-shaped halo with {len(g):,} and triaxiality {triax:.3f}\")\n",
    "        print_halo_characteristics(halo_char)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f921124",
   "metadata": {
    "id": "8f921124"
   },
   "source": [
    "__Layzer-Ervine Energy Equation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d459730",
   "metadata": {
    "cellView": "form",
    "id": "5d459730"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def layzer_irvine(t, a, K, U):\n",
    "    H = np.gradient(a, t) / a\n",
    "    dE_dt = np.gradient(K+U, t)\n",
    "    resid = dE_dt + H*(2*K+U)           # should be ~ 0\n",
    "    return resid, dE_dt, H*(2*K+U)\n",
    "\n",
    "t_array = np.array(time_hist)\n",
    "a_array = np.array(scale_hist)\n",
    "K_array = np.array(KE_hist)\n",
    "U_array = np.array(PE_hist)\n",
    "resid, dE_dt, H2KpU = layzer_irvine(t_array, a_array, K_array, U_array)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))  # no longer (2,1)\n",
    "ax.set_title(\"Layzer-Irvine\")\n",
    "ax.plot(t_array, resid, label=r\"$\\frac{d}{dt}(K+U)+H(2K+U)$\")\n",
    "ax.plot(t_array, dE_dt, label=r\"$\\frac{d}{dt}(K+U)$\")\n",
    "ax.plot(t_array, H2KpU, label=r\"$H(2K+U)$\")\n",
    "ax.axhline(0, color='k', lw=0.7)\n",
    "ax.legend()\n",
    "ax.grid(ls=':')\n",
    "ax.set_xlabel(\"Time [Myr]\")\n",
    "ax.set_ylabel(\"LI residual [M$_\\\\odot$â‹…MpcÂ²/MyrÂ³]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "LI_html = create_html(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f1b5a",
   "metadata": {
    "id": "2c4f1b5a"
   },
   "source": [
    "__Weak-lensing convergence kappa__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6b9d2",
   "metadata": {
    "cellView": "form",
    "id": "34b6b9d2"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# -----------------------------\n",
    "# Cosmology helpers\n",
    "# -----------------------------\n",
    "def E_z(z):\n",
    "    return E(1/(1+z))\n",
    "\n",
    "def comoving_chi_of_z(z, H0=67.5, **cosmo):\n",
    "    \"\"\"\n",
    "    chi(z) in Mpc (comoving), using c/H integral.\n",
    "    \"\"\"\n",
    "    c = 299792.458  # km/s\n",
    "    z_grid = np.linspace(0.0, z, max(2000, int(400*z+200)))  # dense enough\n",
    "    Ez = E_z(z_grid)\n",
    "    chi_grid = cumulative_trapezoid(c / (H0 * Ez), z_grid, initial=0.0)  # Mpc\n",
    "    return z_grid, chi_grid\n",
    "\n",
    "def make_z_of_chi(z_max=10.0, H0=67.5, **cosmo):\n",
    "    z_grid = np.linspace(0.0, z_max, 5000)\n",
    "    c = 299792.458\n",
    "    chi_grid = cumulative_trapezoid(c / (H0 * E_z(z_grid)), z_grid, initial=0.0)\n",
    "    chi_max = chi_grid[-1]\n",
    "    z_of_chi = interp1d(chi_grid, z_grid, kind='linear', bounds_error=False,\n",
    "                        fill_value=(z_grid[0], z_grid[-1]))\n",
    "    return z_of_chi, chi_max\n",
    "\n",
    "# -----------------------------\n",
    "# Kappa from a 3D delta slab\n",
    "# -----------------------------\n",
    "def kappa_from_delta_slab(delta_zyx, Lbox, z_start, z_source,\n",
    "                          H0=67.5, Om=0.315, Ol=0.685, Or=0.0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta_zyx : ndarray, shape (Nz, Ny, Nx)\n",
    "        3D overdensity cube Î´(Ï‡, y, x) at (approximately) the same epoch\n",
    "        across the slab. Periodic boundary not required.\n",
    "    Lbox : float\n",
    "        Comoving box size along each axis, in Mpc units.\n",
    "    z_start : float\n",
    "        Redshift at the *front* face of the slab (closest to observer).\n",
    "    z_source : float\n",
    "        Source redshift for the lensing kernel (all sources at one plane).\n",
    "    H0, Om, Ol, Or : cosmology\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kappa : ndarray, shape (Ny, Nx)\n",
    "        Convergence map (dimensionless).\n",
    "    info  : dict\n",
    "        Useful metadata (chi_s, slice chis, weights, etc.)\n",
    "    \"\"\"\n",
    "    Nz, Ny, Nx = delta_zyx.shape\n",
    "    dchi = Lbox / Nz  # Mpc per slice\n",
    "\n",
    "    # Distances for source and slab\n",
    "    z_of_chi, chi_max = make_z_of_chi(z_max=max(z_source, z_start) + 2.0, H0=H0, Om=Om, Ol=Ol, Or=Or)\n",
    "    # chi at front face:\n",
    "    z_grid_front, chi_front_arr = comoving_chi_of_z(z_start, H0=H0, Om=Om, Ol=Ol, Or=Or)\n",
    "    chi_front = chi_front_arr[-1]\n",
    "    # chi of source:\n",
    "    _, chi_s_arr = comoving_chi_of_z(z_source, H0=H0, Om=Om, Ol=Ol, Or=Or)\n",
    "    chi_s = chi_s_arr[-1]\n",
    "\n",
    "    # LOS comoving coordinate of slice centers\n",
    "    chi_slices = chi_front + (np.arange(Nz) + 0.5) * dchi\n",
    "    # Convert each slice chi -> z_i and a_i\n",
    "    z_slices = z_of_chi(chi_slices)\n",
    "    a_slices = 1.0 / (1.0 + z_slices)\n",
    "\n",
    "    # Lensing kernel per slice (Born approx)\n",
    "    geom = chi_slices * (chi_s - chi_slices) / chi_s\n",
    "    geom = np.clip(geom, 0.0, None)  # zero outside [0, chi_s]\n",
    "\n",
    "    # Prefactor\n",
    "    c = 299792.458  # km/s\n",
    "    pref = 1.5 * Om * (H0 / c)**2  # dimensionless per Mpc factor in integral\n",
    "\n",
    "    # Perform weighted LOS sum: Îº(y,x) = pref * Î£_i [ Î´_i(y,x) * dchi * geom_i / a_i ]\n",
    "    weights = (geom / a_slices) * dchi  # Mpc\n",
    "    # reshape for broadcasting: (Nz,1,1)\n",
    "    w = weights[:, None, None]\n",
    "    kappa = pref * np.sum(delta_zyx * w, axis=0)\n",
    "\n",
    "    info = dict(chi_s=float(chi_s), z_slices=z_slices, chi_slices=chi_slices,\n",
    "                a_slices=a_slices, weights=weights, pref=pref, dchi=dchi)\n",
    "    return kappa, info\n",
    "\n",
    "# Place slab starting at z=0.3, sources at z_s=1.0\n",
    "kappa, info = kappa_from_delta_slab(delta_end.transpose(2,0,1),  # -> (Z,X,Y)\n",
    "                                    Lbox=L,\n",
    "                                    z_start=0.3, z_source=1.0,\n",
    "                                    H0=H0, Om=Î©_m, Ol=Î©_Î›, Or=Î©_r)\n",
    "\n",
    "# Plot Îº-map (single chart, default colors)\n",
    "vmax = np.percentile(kappa, 98)\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "plt.imshow(kappa.T, origin=\"lower\", extent=[-L/2, L/2, -L/2, L/2], vmax=vmax)\n",
    "plt.colorbar(label=\"Îº\")\n",
    "plt.xlabel(\"x [Mpc]\")\n",
    "plt.ylabel(\"y [Mpc]\")\n",
    "plt.title(\"Weak-lensing convergence Îº\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "weaklensing_html = create_html(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eec073",
   "metadata": {
    "id": "99eec073"
   },
   "source": [
    "__Halo development over time__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13619325",
   "metadata": {
    "cellView": "form",
    "id": "13619325"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# define refined grid aligned to coarse cells (choose integer cell indices)\n",
    "# choose coarse indices that define cube: find range of coarse cells covering cube\n",
    "if cube_fine is not None:\n",
    "    dx=L/Ng\n",
    "    i_min = int(((center_fine[0]-cube_fine/2.0) / L) * Ng+1)\n",
    "    j_min = int(((center_fine[1]-cube_fine/2.0) / L) * Ng+1)\n",
    "    k_min = int(((center_fine[2]-cube_fine/2.0) / L) * Ng+1)\n",
    "    n_cells = int((cube_fine / L) * Ng)  # number of coarse cells per side\n",
    "\n",
    "    # Refine grid\n",
    "    Nf = n_cells * refinement\n",
    "    box_min_fine = np.array([i_min*dx, j_min*dx, k_min*dx]) # fine box min/max in physical coords\n",
    "    box_max_fine = box_min_fine + n_cells*dx\n",
    "    dx_fine = dx / refinement\n",
    "\n",
    "    # Mask particles within fine box and deposit to fine rho grid\n",
    "    mask_in_cube = np.all((final_pos >= box_min_fine) & (final_pos < box_max_fine), axis=1)\n",
    "    pos_in = final_pos[mask_in_cube]\n",
    "    pos_in.shape\n",
    "\n",
    "    # Create Plotly animation frames\n",
    "    frames = []\n",
    "    for i, pos in enumerate(positions_hist):\n",
    "        aa = scale_hist[-1]\n",
    "        pos = pos.astype(np.float16)\n",
    "        frames.append(go.Frame(\n",
    "            data=[\n",
    "                go.Scatter3d(x=pos[~baryon_set[grid_downsampled], 0]*aa, y=pos[~baryon_set[grid_downsampled], 1]*aa, z=pos[~baryon_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='blue', size=1), name='CDM'),\n",
    "                go.Scatter3d(x=pos[baryon_set[grid_downsampled], 0]*aa, y=pos[baryon_set[grid_downsampled], 1]*aa, z=pos[baryon_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='red', size=2), name='Baryon'),\n",
    "            ],\n",
    "            name=f'frame{i}',\n",
    "            layout=go.Layout(title_text=f'Halo #{halo_idx} development over time (reduced resolution)')\n",
    "        ))\n",
    "\n",
    "    # Initial frame\n",
    "    init_pos = positions_hist[0].astype(np.float16)\n",
    "    aa = scale_hist[-1]\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter3d(x=init_pos[~baryon_set[grid_downsampled], 0]*aa, y=init_pos[~baryon_set[grid_downsampled], 1]*aa, z=init_pos[~baryon_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='blue', size=1), name='CDM'),\n",
    "            go.Scatter3d(x=init_pos[baryon_set[grid_downsampled], 0]*aa, y=init_pos[baryon_set[grid_downsampled], 1]*aa, z=init_pos[baryon_set[grid_downsampled], 2]*aa, mode='markers', marker=dict(color='red', size=2), name='Baryon'),\n",
    "        ],\n",
    "        layout=go.Layout(\n",
    "            title=f'Halo #{halo_idx} development over time (reduced resolution)',\n",
    "            width = 800,\n",
    "            height = 600,\n",
    "            scene=dict(\n",
    "                xaxis=dict(title='x [Mpc]', range=[box_min_fine[0]-L/2, box_max_fine[0]-L/2]),\n",
    "                yaxis=dict(title='y [Mpc]', range=[box_min_fine[1]-L/2, box_max_fine[1]-L/2]),\n",
    "                zaxis=dict(title='z [Mpc]', range=[box_min_fine[2]-L/2, box_max_fine[2]-L/2]),\n",
    "                camera=dict(\n",
    "                    eye=dict(x=1.4, y=-1.8, z=1.3),\n",
    "                    up=dict(x=0, y=0, z=-1),\n",
    "                    projection=dict(type='perspective')\n",
    "                ),\n",
    "                aspectratio=dict(x=1.2, y=1.2, z=1.2)\n",
    "            ),\n",
    "            updatemenus=menues,\n",
    "            sliders=[{\n",
    "                        \"steps\": [\n",
    "                            {\"args\": [[f\"frame{i}\"], {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}],\n",
    "                            \"label\": f\"{time_hist[i]:,.0f} Myr\",\n",
    "                            \"method\": \"animate\"\n",
    "                            } for i in range(0,len(positions_hist),1)\n",
    "                        ],\n",
    "                    }],\n",
    "        ),\n",
    "        frames=frames\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4a199",
   "metadata": {
    "cellView": "form",
    "id": "35b4a199"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Create Plotly animation frames\n",
    "\n",
    "if \"box_max_fine\" in globals():\n",
    "    init_pos = final_pos.astype(np.float16)\n",
    "    halo_mask = (init_pos[:,0] >= box_min_fine[0]) & (init_pos[:,0] < box_max_fine[0]) & (init_pos[:,1] >= box_min_fine[1]) & (init_pos[:,1] < box_max_fine[1]) & (init_pos[:,2] >= box_min_fine[2]) & (init_pos[:,2] < box_max_fine[2])\n",
    "    init_pos = init_pos[halo_mask]\n",
    "\n",
    "    aa = scale_hist[-1]\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter3d(x=init_pos[~baryon_set[halo_mask], 0]*aa, y=init_pos[~baryon_set[halo_mask], 1]*aa, z=init_pos[~baryon_set[halo_mask], 2]*aa, mode='markers', marker=dict(color='blue', size=1), name='CDM'),\n",
    "            go.Scatter3d(x=init_pos[baryon_set[halo_mask], 0]*aa, y=init_pos[baryon_set[halo_mask], 1]*aa, z=init_pos[baryon_set[halo_mask], 2]*aa, mode='markers', marker=dict(color='red', size=2), name='Baryon'),\n",
    "        ],\n",
    "        layout=go.Layout(\n",
    "            title=f'Neighborhood halo #{halo_idx} ({init_pos.shape[0]:,} bodies)',\n",
    "            width = 800,\n",
    "            height = 600,\n",
    "            scene=dict(\n",
    "                xaxis=dict(title='x [Mpc]', range=[box_min_fine[0], box_max_fine[0]]),\n",
    "                yaxis=dict(title='y [Mpc]', range=[box_min_fine[1], box_max_fine[1]]),\n",
    "                zaxis=dict(title='z [Mpc]', range=[box_min_fine[2], box_max_fine[2]]),\n",
    "                camera=dict(\n",
    "                    eye=dict(x=1.4, y=-1.8, z=1.3),\n",
    "                    up=dict(x=0, y=0, z=-1),\n",
    "                    projection=dict(type='perspective')\n",
    "                ),\n",
    "                aspectratio=dict(x=1.2, y=1.2, z=1.2)\n",
    "            ),\n",
    "            updatemenus=menues,\n",
    "        ),\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efc322",
   "metadata": {
    "id": "e8efc322"
   },
   "source": [
    "__Create summary report__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4cabd",
   "metadata": {
    "cellView": "form",
    "id": "dbb4cabd"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Create summary report\n",
    "import html\n",
    "import zipfile\n",
    "\n",
    "try:\n",
    "    fine_grid_od_html\n",
    "except NameError:\n",
    "    fine_grid_od_html = \"\"\n",
    "\n",
    "escaped_report = html.escape(report_text)\n",
    "report_html = f'<details open><summary><strong>ðŸ“„ Simulation Report (click to collapse)</strong></summary><pre style=\"font-family: monospace; font-size: 12px; background: #f0f0f0; padding: 10px;\">{escaped_report}</pre></details>'\n",
    "full_report = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>Simulation Report</title>\n",
    "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "{plot_html}    <!-- the plotly animation -->\n",
    "{report_html}  <!-- your custom text goes here -->\n",
    "{thermo_animation_html}\n",
    "{halo_plot_html}    <!-- the plotly animation -->\n",
    "{deltafield_html}\n",
    "{thermo_html}\n",
    "{energy_html}\n",
    "{LI_html}\n",
    "{fine_grid_od_html}\n",
    "{weaklensing_html}\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with zipfile.ZipFile(\"DFS-v11-1-summary.zip\", \"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.writestr(\"DFS-v11-1-summary.html\", full_report)\n",
    "\n",
    "\"\"\"\n",
    "with open(\"DFS-v11-1-summary.html\", \"w\") as f:\n",
    "    f.write(minified_report)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211b460",
   "metadata": {
    "id": "0211b460"
   },
   "source": [
    "__Save simulation result to database__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e41efe",
   "metadata": {
    "cellView": "form",
    "id": "64e41efe"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Save simulations reesult to database\n",
    "parameters = {\n",
    "    \"L\": L,\n",
    "    \"N\": N,\n",
    "    \"qp\": qp,\n",
    "    \"qpa\": qpa,\n",
    "    \"q_grid\": qg,\n",
    "    \"steps\": steps,\n",
    "    \"steps_fine\": steps_fine,\n",
    "    \"h\": h,\n",
    "    \"Î©_r\": Î©_r,\n",
    "    \"Î©_Î³\": Î©_Î³,\n",
    "    \"Î©_m\": Î©_m,\n",
    "    \"Î©_b\": Î©_b,\n",
    "    \"Î©_Î›\": Î©_Î›,\n",
    "    \"Î©_k\": Î©_k,\n",
    "    \"a_init\": a_init,\n",
    "    \"a_final\": a_final,\n",
    "    \"seed\": seed,\n",
    "    \"use_TSC\": use_TSC,\n",
    "}\n",
    "\n",
    "np.savez_compressed(\"DFS-v11-1-results.npz\",\n",
    "    parameters=parameters,\n",
    "    sim_log = sim_log.getvalue(),\n",
    "    final_pos=final_pos,\n",
    "    final_vel=final_vel,\n",
    "    final_temp=final_temp,\n",
    "    final_pressure = final_pressure,\n",
    "    masses=masses,\n",
    "    baryon_set=baryon_set,\n",
    "    baryon_indices=baryon_indices,\n",
    "    grid_downsampled = grid_downsampled,\n",
    "    positions_hist = positions_hist,\n",
    "    scale_hist = scale_hist,\n",
    "    time_hist = time_hist,\n",
    "    temp_hist = temp_hist,\n",
    "    pressure_hist = pressure_hist,\n",
    "    KE_hist = KE_hist,\n",
    "    PE_hist = PE_hist,\n",
    "    TE_hist = TE_hist,\n",
    "    virial_hist = virial_hist,\n",
    "    flat_a_hist = flat_a_hist,\n",
    "    flat_b_hist = flat_b_hist,\n",
    "    flat_c_hist = flat_c_hist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444496c9",
   "metadata": {
    "cellView": "form",
    "id": "444496c9"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Call of combined_step_py(..) for debugging purposes\n",
    "\"\"\"\n",
    "H_a = H0_cos * E(scale) #1/Myr\n",
    "dt = np.clip(dt_target, epsilon_fine / H_a, epsilon / H_a)  # Myr\n",
    "\n",
    "(body_positions, body_velocities_cos, acc, scale, PE,\n",
    "u, T, acc_P, P, diag, epochs, dt_target_new,\n",
    "max_b_od, max_tot_od, temp_by_b_od, S_max) = combined_step_subcycle_py(\n",
    "    x=body_positions,\n",
    "    u=body_velocities_cos,\n",
    "    g=acc,\n",
    "    gP_b=acc_P,\n",
    "    U_b=u,\n",
    "    baryon_mask=baryon_set,\n",
    "    mass=mass,\n",
    "    L=L,\n",
    "    Ng=Ng,\n",
    "    dt=dt,\n",
    "    a=scale,\n",
    "    G=G,\n",
    "    eng=eng,\n",
    "    use_TSC=use_TSC,\n",
    "    n_threads=n_threads\n",
    ")\n",
    "\"\"\";"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
